{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f9aebc-eca6-42e9-8647-f8d7ef3dc991",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <H1>Aprendizado de Máquina - Trabalho Final</H1>\n",
    "    <H3>Prof.º Daniel Roberto Cassar</H3> \n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"right\">\n",
    "    <H3>Guilda: Carcajus</H3>\n",
    "    <H4>Aniel Souza Ribeiro Neto</H4>\n",
    "    <H4>Caio Cogo Beriam</H4>\n",
    "    <H4>Joaquim Junior Ferola Fonseca</H4>\n",
    "</div>\n",
    "\n",
    "<br> \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"Imagens/carcajus_bg.png\" width=\"500\"/>\n",
    "    <figcaption><H3><I>\"Mastigar primeiro, digerir depois!\"</I></H3></figcaption>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0ebc27-9179-4a65-8b7f-329e2578963e",
   "metadata": {},
   "source": [
    "# Lore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2e820-7957-4ec0-981c-45941fb11ba0",
   "metadata": {},
   "source": [
    "    \"    Você não ouviria o barulho das engrenagens se não tivessem te contado sobre elas. Você nunca saberia que elas estão rodando, centenas de metros sob seus pés, talvez até quilômetros. Mas elas estão ali, engrenadas e ativas como sempre. Elas são o trunfo do Continente, a ferramenta secreta de todo o povo para responder a Pergunta Final. E mesmo que não possamos ouvi-las com nossa audição, sentimos seu ritmo em nossos corações, pulsando junto conosco.   \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bd158-3de9-45f7-8643-b18a9a8e8643",
   "metadata": {},
   "source": [
    "Os viajantes costumam dizer que o reino de Lumi é pequeno, mas ajeitadinho. É de fato inspirador andar pelos cenários característicos, como as praças, jardins e tavernas, e ver seus simpáticos habitantes recitando encantamentos, feitiços, magias e maldições.\n",
    "\n",
    "O reino também é movido por um grande número de heróis *freelancers*, que recebem quests dos ilustres moradores já bem renomados. Alguns deles se unem em guildas, outros trabalham sozinhos; alguns cumprem missões com maestria, enquanto outros mal saem vivos.\n",
    "\n",
    "Não posso dizer em qual desses grupos os Carcajus se encaixam. A verdade, é que estes são três paranóicos aventureiros que ambicionam moedas, pergaminhos, caixinhas de suco e outras coisinhas, para que depois possam gastar tudo em comida e bebida. Esse habitozinho ignóbil rendeu aos três o apelido de \"glutões\", que eles acolheram com orgulho e de bom-grado.\n",
    "\n",
    "Entretanto, por sugestão de Edna Ensineide, notável conselheira real, os Glutões buscaram um novo nome em algum sinônimo mais respeitável. Assim, ao consultarem a Grande Enciclopédia dos Insultos e Injúrias na Biblioteca Real, verificaram que um dos nomes para um glutão é **Carcaju**, um pequeno e feroz animal que rivaliza com lobos e ursos pelo seu apetite insaciável.\n",
    "\n",
    "Unidos, os Carcajus trabalham sob o lema **\"Mastigar primeiro, digerir depois\"**, que representa a voracidade do grupo de devorar grandes coisas em pequenas mordidas, e confiar piamente na própria capacidade de digestão para cumprir a tarefa.\n",
    "\n",
    "O que eles não esperavam, é que nessa visita à biblioteca eles seriam atraídos para o temido **Pythonomicron**, um compêndio de maldições e informações proibidas do lado mais obscuro da magia. E ali, em uma página secreta, de baixo de um post-it de um estudante dedicado, encontraram rabiscada a lenda do Horripilante Processador Central, um mecanismo milenar que continha poder inimaginável, guardado por um dos mais poderosos magos do continente.\n",
    "\n",
    "Agora, a quest de Milu Iluminarius MLVI era a pista que mais aproximava os Carcajus desse tesouro ancião. Mas para isso, eles teriam que conquistar a simpatia do rei e colecionar suas Coroas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8efdb-3dc4-4b7f-9e7b-738936725685",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introdução\n",
    "\n",
    "A área de nanotoxicologia, que estuda como nanomateriais interagem com sistemas biológicos, tem se tornado cada vez mais importante com os avanços da nanotecnologia, permitindo que esses materiais sejam implementados de maneira segura ao meio ambiente e aos possíveis seres vivos que venham a entrar em contato com esses nanomateriais. Entretanto, como outras características dos nanomateriais, sua toxicidade pode variar muito conforme a morfologia do composto, assim, para ser analisada corretamente uma série de fatores devem ser levados em consideração, o que torna difícil a previsão da toxicidade dos materiais. \n",
    "\n",
    "Sob essa perspectiva, nosso trabalho tem o objetivo de facilitar esse tarefa através do treinamento de um modelo de Aprendizado de Máquina Supervisionado capaz de prever se uma nanopartícula é tóxica com base em características da sua morfologia. Para isso, utilizaremos como fundamento um conjunto de dados contendo as características de diversas nanoparticulas e se elas são ou não tóxicas. O dataset foi elaborado pelo trabalho Subramanian NA, Palaniappan A. NanoTox: Development of a Parsimonious In Silico Model for Toxicity Assessment of Metal-Oxide Nanoparticles Using Physicochemical Features. ACS Omega 2021, 6, 17, 11729–11739 doi:10.1021/acsomega.1c01076, e o obtivemos pela plataforma Kaggle através do endereço https://www.kaggle.com/datasets/apalania/toxicityassessment-meoxnp.\n",
    "\n",
    "Para fins de organização e didática, este trabalho será dividido nas seguintes etapas:\n",
    "1. Preparo dos dados: Nessa seção será feita a obtenção e tratamento dos dados, permitindo que eles sejam posteriormente utilizados sem problemas, além disso, será feita também a divisão dos dados de treino e de teste dos modelos;\n",
    "2. Estudo dos modelos: Nessa etapa faremos o estudo de 5 modelos através do módulo optuna para optimzação de hiperparâmetros e estratégias de normalização de dados e tratamento de atributos, buscando o melhor pipeline encontrado pelo optuna para cada modelo;\n",
    "3. Teste dos modelos: Após definirmos os melhores pipelines encontrados pelo optuna, iremos instânciar, treinar e comparar os 5 pipelines em busca do de melhor desempenho, que, por fim, utilizaremos para prever os dados de teste;\n",
    "4. Resultados e conclusão: Enfim, discutiremos os resultados obtidos pelo trabalho e apresentaremos sua conclusão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30654516",
   "metadata": {},
   "source": [
    "# Módulos utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74068e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Modelos de Aprendizado Supervisionado\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Tratamento\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Normalização\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "\n",
    "# Separação de dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Validação Cruzada\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from optuna import create_study\n",
    "\n",
    "# Visualização dos resultados\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb81756-c4e9-4bdc-8baa-f5dffb85e498",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preparo dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0db95",
   "metadata": {},
   "source": [
    "\n",
    "Nesta seção será realizado o tratamento dos dados, preparando-os para serem usados para treino e subsequente avaliação dos modelos que serão estudados. O processo de tratamento de dados é fundamental para a prática de ciência de dados e aprendizado de máquina, dados bem tratados podem impulsionar fortemente o desempenho de modelos e evitar problemas nos seus treinos, além disso, boas práticas ao lidar com dados permitem evitar o vazamento de dados e facilitam o trabalho. \n",
    "\n",
    "Sobre essa perspectiva, nesta seção será feita a importação dos dados do dataset através do módulo pandas, o tratamento dos dados, removendo dados que sem informação e codificando dados categóricos para que os modelos possam os interpretar, e por fim a divisão dos dados para treino e teste dos modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8cd0f",
   "metadata": {},
   "source": [
    "## Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ee246e-268d-42bc-90a4-d17064d2d62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPs</th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>e</th>\n",
       "      <th>NOxygen</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>25.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>35.6</td>\n",
       "      <td>295.5</td>\n",
       "      <td>-41.6</td>\n",
       "      <td>27.9</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>881 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NPs  coresize  hydrosize  surfcharge  surfarea    Ec  Expotime  \\\n",
       "0    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "1    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "2    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "3    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "4    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "..     ...       ...        ...         ...       ...   ...       ...   \n",
       "876    ZnO      45.3      310.0        32.7      21.3 -3.89        24   \n",
       "877    ZnO      32.0     1093.0        21.6      37.0 -3.89        24   \n",
       "878    ZnO      46.3      239.0        42.8      24.1 -5.17        12   \n",
       "879    ZnO      35.6      295.5       -41.6      27.9 -3.89        24   \n",
       "880    ZnO      46.3      239.0        42.8      24.1 -5.17        24   \n",
       "\n",
       "      dosage     e  NOxygen     class  \n",
       "0      0.001  1.61        3  nonToxic  \n",
       "1      0.010  1.61        3  nonToxic  \n",
       "2      0.100  1.61        3  nonToxic  \n",
       "3      1.000  1.61        3  nonToxic  \n",
       "4      5.000  1.61        3  nonToxic  \n",
       "..       ...   ...      ...       ...  \n",
       "876   20.000  1.65        1     Toxic  \n",
       "877   25.000  1.65        1     Toxic  \n",
       "878  100.000  1.90        1     Toxic  \n",
       "879   10.000  1.65        1     Toxic  \n",
       "880  100.000  1.90        1     Toxic  \n",
       "\n",
       "[881 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"nanotox_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82528fdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tratamento dos dados [ALTERAR]\n",
    "\n",
    "O tratamento de dados deste trabalho consisitirá no seguinte processo: Remoção de dados faltantes, comuns em diversos datasets não tratados e que atrapalham o treino dos modelos; Remoção de linhas duplicadas, que, apesar de não impedirem o funcionamento do modelo, trazem uma redundância nos dados, influênciando a percepção do modelo sobre os dados; Codificação one-hot dos atributos categóricos, permitindo que os modelos interpretem esses dados; Remoção de colunas sem variância, uma vez que colunas sem variância não trazem qualquer informação ao modelo, não há padrões a serem inferidos em algo que não varia; Tranformação do target para forma numérica, permitindo o seu uso sem problemas de alguns modelos e estatíticas de teste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a732cb-78ba-41af-b4dd-f70c74052463",
   "metadata": {},
   "source": [
    "### $\\bullet$ Removendo linhas com dados faltantes ou duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa0f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com valores NaN\n",
    "df = df.dropna()\n",
    "# Removendo linhas duplicadas\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4235b44-75ca-4f9c-b287-c5ac0fefac64",
   "metadata": {},
   "source": [
    "### $\\bullet$ Restringindo dados às nanopartículas de ZnO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd4f65-84fe-4049-96e2-832b91cc2245",
   "metadata": {},
   "source": [
    "* Identificando as linhas com NPs de ZnO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc844d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>e</th>\n",
       "      <th>NOxygen</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coresize  hydrosize  surfcharge  surfarea    Ec  Expotime   dosage     e  \\\n",
       "249      45.3      310.0        32.7      21.3 -3.89        24    0.001  1.65   \n",
       "250      45.3      310.0        32.7      21.3 -3.89        24    0.010  1.65   \n",
       "251      45.3      310.0        32.7      21.3 -3.89        24    0.100  1.65   \n",
       "252      45.3      310.0        32.7      21.3 -3.89        24    1.000  1.65   \n",
       "253      45.3      310.0        32.7      21.3 -3.89        24    5.000  1.65   \n",
       "..        ...        ...         ...       ...   ...       ...      ...   ...   \n",
       "636      46.3      239.0        42.8      24.1 -5.17        12  100.000  1.90   \n",
       "679      46.3      239.0        42.8      24.1 -5.17        24   10.000  1.90   \n",
       "690      46.3      239.0        42.8      24.1 -5.17        12   50.000  1.90   \n",
       "713      46.3      239.0        42.8      24.1 -5.17        24   50.000  1.90   \n",
       "785      46.3      239.0        42.8      24.1 -5.17        24   20.000  1.90   \n",
       "\n",
       "     NOxygen     class  \n",
       "249        1  nonToxic  \n",
       "250        1  nonToxic  \n",
       "251        1  nonToxic  \n",
       "252        1  nonToxic  \n",
       "253        1  nonToxic  \n",
       "..       ...       ...  \n",
       "636        1     Toxic  \n",
       "679        1     Toxic  \n",
       "690        1     Toxic  \n",
       "713        1     Toxic  \n",
       "785        1     Toxic  \n",
       "\n",
       "[198 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrando as linhas com NPs de ZnO\n",
    "logica = df[\"NPs\"] == \"ZnO\"\n",
    "df = df.loc[logica]\n",
    "\n",
    "# Removendo coluna NPs\n",
    "df = df.drop(\"NPs\", axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fa3ba-8329-4a33-ad75-562a6802d492",
   "metadata": {},
   "source": [
    "### $\\bullet$ Removendo colunas com variância 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f33fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>e</th>\n",
       "      <th>NOxygen</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coresize  hydrosize  surfcharge  surfarea    Ec  Expotime   dosage     e  \\\n",
       "249      45.3      310.0        32.7      21.3 -3.89        24    0.001  1.65   \n",
       "250      45.3      310.0        32.7      21.3 -3.89        24    0.010  1.65   \n",
       "251      45.3      310.0        32.7      21.3 -3.89        24    0.100  1.65   \n",
       "252      45.3      310.0        32.7      21.3 -3.89        24    1.000  1.65   \n",
       "253      45.3      310.0        32.7      21.3 -3.89        24    5.000  1.65   \n",
       "..        ...        ...         ...       ...   ...       ...      ...   ...   \n",
       "636      46.3      239.0        42.8      24.1 -5.17        12  100.000  1.90   \n",
       "679      46.3      239.0        42.8      24.1 -5.17        24   10.000  1.90   \n",
       "690      46.3      239.0        42.8      24.1 -5.17        12   50.000  1.90   \n",
       "713      46.3      239.0        42.8      24.1 -5.17        24   50.000  1.90   \n",
       "785      46.3      239.0        42.8      24.1 -5.17        24   20.000  1.90   \n",
       "\n",
       "     NOxygen     class  \n",
       "249        1  nonToxic  \n",
       "250        1  nonToxic  \n",
       "251        1  nonToxic  \n",
       "252        1  nonToxic  \n",
       "253        1  nonToxic  \n",
       "..       ...       ...  \n",
       "636        1     Toxic  \n",
       "679        1     Toxic  \n",
       "690        1     Toxic  \n",
       "713        1     Toxic  \n",
       "785        1     Toxic  \n",
       "\n",
       "[198 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instânciando o VarianceThreshold \n",
    "threshold = VarianceThreshold(threshold=0.0)\n",
    "# Ajustando o modelo e transformando os dados\n",
    "threshold.fit_transform(df.loc[:, df.dtypes != 'object'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89786f5e-959a-4779-adb5-64dd3b584f38",
   "metadata": {},
   "source": [
    "### $\\bullet$ Tranformando o target para a forma numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098a6a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>e</th>\n",
       "      <th>NOxygen</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coresize  hydrosize  surfcharge  surfarea    Ec  Expotime   dosage     e  \\\n",
       "249      45.3      310.0        32.7      21.3 -3.89        24    0.001  1.65   \n",
       "250      45.3      310.0        32.7      21.3 -3.89        24    0.010  1.65   \n",
       "251      45.3      310.0        32.7      21.3 -3.89        24    0.100  1.65   \n",
       "252      45.3      310.0        32.7      21.3 -3.89        24    1.000  1.65   \n",
       "253      45.3      310.0        32.7      21.3 -3.89        24    5.000  1.65   \n",
       "..        ...        ...         ...       ...   ...       ...      ...   ...   \n",
       "636      46.3      239.0        42.8      24.1 -5.17        12  100.000  1.90   \n",
       "679      46.3      239.0        42.8      24.1 -5.17        24   10.000  1.90   \n",
       "690      46.3      239.0        42.8      24.1 -5.17        12   50.000  1.90   \n",
       "713      46.3      239.0        42.8      24.1 -5.17        24   50.000  1.90   \n",
       "785      46.3      239.0        42.8      24.1 -5.17        24   20.000  1.90   \n",
       "\n",
       "     NOxygen  class  \n",
       "249        1      0  \n",
       "250        1      0  \n",
       "251        1      0  \n",
       "252        1      0  \n",
       "253        1      0  \n",
       "..       ...    ...  \n",
       "636        1      1  \n",
       "679        1      1  \n",
       "690        1      1  \n",
       "713        1      1  \n",
       "785        1      1  \n",
       "\n",
       "[198 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"] = df[\"class\"].map({'nonToxic': 0, 'Toxic': 1})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2f738",
   "metadata": {},
   "source": [
    "### $\\bullet$ Definindo labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a03228f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem_labels = [\"Não tóxico\", \"Tóxico\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f467fa64",
   "metadata": {},
   "source": [
    "## Separando os dados para treino e teste\n",
    "\n",
    "A separação de dados em treino e teste é uma forma de avaliar o desempenho dos modelos sem serem necessárias novas observações. Ela consiste em omitir um fração dos dados no treino do modelo, utilizando apenas o restante dos dados para treino do modelo. Os dados de teste devem sempre ser utilizados somente quando todo o processo de treino e otimização dos modelos tiver sido concluído e o modelo final ter sido escolhido, para evitar o vazamento de dados do conjunto de teste, o que traria um enviesamento do modelo e faria com que o teste não fosse uma boa estimativa do desempenho do modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e29e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a semente aleatória\n",
    "semente = 3931421\n",
    "\n",
    "# Definindo a lista de atributos\n",
    "atributos = df.drop(columns=[\"class\"])\n",
    "# Definindo o target\n",
    "target = df[\"class\"]\n",
    "\n",
    "# Realizando a separação dos dados \n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "    atributos,\n",
    "    target,\n",
    "    test_size=0.1,\n",
    "    random_state=semente,\n",
    "    stratify=df[\"class\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a08aae-e31f-45d5-8726-c054271b50e5",
   "metadata": {},
   "source": [
    "# Estudos dos modelos \n",
    "\n",
    "Nessa etapa será utilizada o módulo optuna para optimização de hiperparâmetros e escolha de estratégias de normalização dos dados para 5 modelos: Um KNN, uma SVM, uma Regressão Logística, uma DecisionTree e uma RandomForest, todos de classificação e da biblioteca scikit-learn. Para cada modelo mencionado, o processo realizado seguirá o seguinte fluxo: \n",
    "1. Criar a função para instanciar os modelos: A função que possui os critérios que o optuna testará, retornando o modelo com os parâmetros definidos pelo optuna.\n",
    "2. Criar a função que será otimizada pelo optuna: A função que computará a métrica a ser minimizada ou maximizada pelo optuna.\n",
    "3. Criar um estudo do optuna: Arquivo onde serão salvos os testes e resultados do optuna.\n",
    "4. Indicar testes desejados: Indicar testes com valores específicos que desejamos que o optuna teste.\n",
    "5. Criar a função objetivo parcial: Função que retorna a função a ser otimizada, necessária para o optuna.\n",
    "6. Rodar o optuna e otimizar os parâmetros.\n",
    "\n",
    "Vamos entender um pouco mais a fundo cada uma das etapas, lembrando que serão realizadas para cada um dos modelos: \n",
    "1. A primeira etapa é a criação de uma função que possui em seu corpo opções de escolha que serão testadas pelo optuna. Neste trabalho, cada um dos modelos terá uma função que testa diferentes valores para seus hiperparâmetros, que sejam relevantes, que serão salvos em um dicionário para serem utilizados para instanciar os modelos posteriormente. Depois, o optuna poderá escolher entre normalizar ou não dados, seguindo as normalizações padrão, por mínimos e máximos ou máximo absoluto, e também poderá escolher entre aplicar ou não estratégias de redução de dimensionalidade ou seleção de atributos, adicionando as estratégias escolhidas a uma lista de passos para a criação de um pipeline. Por fim, será instânciado um modelo com os parâmetros definidos e criaremos um pipeline com os passos de tratamento de dados, caso escolhidos pelo optuna, e o modelo instanciado, que será retornado pela função.\n",
    "\n",
    "2. Aqui será criada uma função que chama a função para instanciar o modelo e testa o modelo criado através de uma validação cruzada seguindo uma estratégia de kfold estratificado com 3 folds e métrica f1-score. A função retorna o desempenho médio do modelo.\n",
    "\n",
    "3. Criaremos nessa etapa o estudo do optuna, que gera um arquivo contendo os dados obtidos pela otimização que será feita posterioremente, caso já haja um arquivo do estudo ele será lido ao invés de outro ser criado. Nesse ponto, caso deseje utilizar os resultados já obtidos basta baixar os estudos apresentados no repositório deste trabalho no github. O estudo irá buscar maximizar o valor recebido pela função objetivo ao longo das iterações.\n",
    "\n",
    "4. Agora indicaremos alguns casos particulares que desejamos analisar. Vamos indicar que o optuna teste ao menos uma vez cada caso de normalização e tratamento de dados com os parâmetros base do sklearn.\n",
    "\n",
    "5. O optuna requer que a função objetivo seja chamada por uma outra função, portanto, criamos uma função que retorna a função objetivo com o trial do optuna.\n",
    "\n",
    "6. Por fim, faremos otimização de parâmetros pelo optuna. Note que a linha que faz essa etapa está na forma de comentário por padrão pois considera que os estudos disponibilizados no repositório tenham sido baixados, caso tenha optado por não baixar os estudos ou tenha interesse em fazer mais estudos, basta remover a hashtag `#` no início da linha para realizar a otimização."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f8394-0631-40e8-a827-425f5c8e176b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo K-NearestNeighbors Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61377cc-6cdc-4997-a2a1-a048d7c02436",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce140ba-fbe2-4c40-828a-22e0e16ebc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_knn(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador KNN\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "        \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 1, 200, log=True),\n",
    "        \"p\": trial.suggest_int(\"p\", 1, 2),\n",
    "        \"weights\": trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"])\n",
    "    }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Instânciando o modelo\n",
    "    modelo = KNeighborsClassifier(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d9cd3-a225-43dc-afa2-dc4a268575f0",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4036370-d81a-4983-8ba1-ee3c95921f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_knn(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_knn(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72178c-5da7-4e00-922a-685eaa9fd71b",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um Estudo do Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b95bf20-cdf8-4a67-b7f2-054fcca33b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:45:26,772] A new study created in RDB with name: Estudo KNN\n"
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_knn = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo KNN\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo KNN\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0addb63-3f19-44fa-a97d-ba27e6510d13",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab3c6a8-f33b-4c41-bd6f-3e261ac48f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": None,\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão \n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos \n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"minmax\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto\n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"maxabs\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"pca\",\n",
    "        \"pca_components\": 9\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf8ea14-ee87-4413-8b70-b18842816927",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250d982e-dab1-4547-8fa6-3ce7178ab949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_knn(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_knn(trial, x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de1364a-c029-44ff-babb-a0a7d49508c6",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d65d70-eb86-44ca-b904-759cf10294b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:45:27,135] Trial 0 finished with value: 0.4204404466501241 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.4204404466501241.\n",
      "[I 2025-11-03 03:45:27,340] Trial 1 finished with value: 0.5659090909090909 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 1 with value: 0.5659090909090909.\n",
      "[I 2025-11-03 03:45:27,536] Trial 2 finished with value: 0.5376344086021505 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 1 with value: 0.5659090909090909.\n",
      "[I 2025-11-03 03:45:27,846] Trial 3 finished with value: 0.5146162081645953 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 1 with value: 0.5659090909090909.\n",
      "[I 2025-11-03 03:45:28,080] Trial 4 finished with value: 0.5862955935062196 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 4 with value: 0.5862955935062196.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 132, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 132, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 132, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:28,307] Trial 5 failed with parameters: {'n_neighbors': 132, 'p': 2, 'weights': 'distance', 'normalization': 'maxabs', 'treatment': None} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:28,307] Trial 5 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:28,529] Trial 6 finished with value: 0.3778735632183908 and parameters: {'n_neighbors': 8, 'p': 2, 'weights': 'distance', 'normalization': None, 'treatment': None}. Best is trial 4 with value: 0.5862955935062196.\n",
      "[I 2025-11-03 03:45:31,146] Trial 7 finished with value: 0.23519009725906279 and parameters: {'n_neighbors': 96, 'p': 2, 'weights': 'distance', 'normalization': None, 'treatment': 'pca', 'pca_components': 2}. Best is trial 4 with value: 0.5862955935062196.\n",
      "[I 2025-11-03 03:45:31,373] Trial 8 finished with value: 0.5728585728585729 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 3}. Best is trial 4 with value: 0.5862955935062196.\n",
      "[I 2025-11-03 03:45:31,627] Trial 9 finished with value: 0.44871186976450134 and parameters: {'n_neighbors': 3, 'p': 1, 'weights': 'uniform', 'normalization': None, 'treatment': None}. Best is trial 4 with value: 0.5862955935062196.\n",
      "[I 2025-11-03 03:45:31,897] Trial 10 finished with value: 0.4974987974987975 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'distance', 'normalization': None, 'treatment': 'pca', 'pca_components': 5}. Best is trial 4 with value: 0.5862955935062196.\n",
      "[I 2025-11-03 03:45:32,163] Trial 11 finished with value: 0.08333333333333333 and parameters: {'n_neighbors': 32, 'p': 1, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 4 with value: 0.5862955935062196.\n",
      "[I 2025-11-03 03:45:32,398] Trial 12 finished with value: 0.6070303965040806 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:32,655] Trial 13 finished with value: 0.6070303965040806 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:32,918] Trial 14 finished with value: 0.5956505956505956 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:33,166] Trial 15 finished with value: 0.3070607553366174 and parameters: {'n_neighbors': 20, 'p': 1, 'weights': 'distance', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 7}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:33,409] Trial 16 finished with value: 0.5869925869925869 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 9}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:33,734] Trial 17 finished with value: 0.5956505956505956 and parameters: {'n_neighbors': 2, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 12 with value: 0.6070303965040806.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 182, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 182, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 182, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:34,019] Trial 18 failed with parameters: {'n_neighbors': 182, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:34,020] Trial 18 failed with value np.float64(nan).\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 152, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 152, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 152, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:34,284] Trial 19 failed with parameters: {'n_neighbors': 152, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:34,285] Trial 19 failed with value np.float64(nan).\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 185, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 185, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 185, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:34,577] Trial 20 failed with parameters: {'n_neighbors': 185, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:34,578] Trial 20 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:34,910] Trial 21 finished with value: 0.4965786901270772 and parameters: {'n_neighbors': 19, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 12 with value: 0.6070303965040806.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 161, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 161, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 161, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:35,188] Trial 22 failed with parameters: {'n_neighbors': 161, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:35,189] Trial 22 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:35,473] Trial 23 finished with value: 0.5930555555555556 and parameters: {'n_neighbors': 2, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:35,758] Trial 24 finished with value: 0.0 and parameters: {'n_neighbors': 83, 'p': 1, 'weights': 'distance', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 8}. Best is trial 12 with value: 0.6070303965040806.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 172, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 172, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 172, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:36,028] Trial 25 failed with parameters: {'n_neighbors': 172, 'p': 1, 'weights': 'distance', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:36,029] Trial 25 failed with value np.float64(nan).\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 179, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 179, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 179, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:36,257] Trial 26 failed with parameters: {'n_neighbors': 179, 'p': 1, 'weights': 'distance', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:36,258] Trial 26 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:36,540] Trial 27 finished with value: 0.5869925869925869 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:36,857] Trial 28 finished with value: 0.6070303965040806 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 12 with value: 0.6070303965040806.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 199, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 199, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 199, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:37,106] Trial 29 failed with parameters: {'n_neighbors': 199, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:37,107] Trial 29 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:37,384] Trial 30 finished with value: 0.5956505956505956 and parameters: {'n_neighbors': 2, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:37,660] Trial 31 finished with value: 0.6070303965040806 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:38,010] Trial 32 finished with value: 0.5095238095238095 and parameters: {'n_neighbors': 3, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 12 with value: 0.6070303965040806.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 165, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 165, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 165, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:38,301] Trial 33 failed with parameters: {'n_neighbors': 165, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:38,302] Trial 33 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:38,597] Trial 34 finished with value: 0.5095238095238095 and parameters: {'n_neighbors': 3, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:38,876] Trial 35 finished with value: 0.5563025210084033 and parameters: {'n_neighbors': 12, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 6}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:39,159] Trial 36 finished with value: 0.5956505956505956 and parameters: {'n_neighbors': 2, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:39,473] Trial 37 finished with value: 0.08240431066518022 and parameters: {'n_neighbors': 60, 'p': 1, 'weights': 'distance', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 4}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:39,738] Trial 38 finished with value: 0.4210155857214681 and parameters: {'n_neighbors': 10, 'p': 1, 'weights': 'distance', 'normalization': 'minmax', 'treatment': None}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:40,026] Trial 39 finished with value: 0.5956505956505956 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:40,298] Trial 40 finished with value: 0.6070303965040806 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:40,588] Trial 41 finished with value: 0.5095238095238095 and parameters: {'n_neighbors': 3, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:40,892] Trial 42 finished with value: 0.6070303965040806 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:41,273] Trial 43 finished with value: 0.4559139784946236 and parameters: {'n_neighbors': 2, 'p': 1, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:41,882] Trial 44 finished with value: 0.0 and parameters: {'n_neighbors': 189, 'p': 1, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:42,200] Trial 45 finished with value: 0.5302775655716833 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'distance', 'normalization': 'minmax', 'treatment': None}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:42,575] Trial 46 finished with value: 0.5372549019607843 and parameters: {'n_neighbors': 4, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:42,873] Trial 47 finished with value: 0.45259856630824374 and parameters: {'n_neighbors': 7, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:43,224] Trial 48 finished with value: 0.5047619047619047 and parameters: {'n_neighbors': 4, 'p': 1, 'weights': 'distance', 'normalization': None, 'treatment': 'pca', 'pca_components': 9}. Best is trial 12 with value: 0.6070303965040806.\n",
      "[I 2025-11-03 03:45:43,524] Trial 49 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:43,768] Trial 50 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:44,001] Trial 51 finished with value: 0.5588529706176765 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:44,255] Trial 52 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:44,497] Trial 53 finished with value: 0.4974987974987975 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'distance', 'normalization': None, 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:44,926] Trial 54 finished with value: 0.42314990512333966 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 2}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:45,444] Trial 55 finished with value: 0.5842383737120579 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:45,761] Trial 56 finished with value: 0.5372549019607843 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:46,036] Trial 57 finished with value: 0.42870370370370364 and parameters: {'n_neighbors': 32, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:46,279] Trial 58 finished with value: 0.5518796992481202 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': 'pca', 'pca_components': 7}. Best is trial 49 with value: 0.6072124756335283.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 194, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 194, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 194, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:46,555] Trial 59 failed with parameters: {'n_neighbors': 194, 'p': 2, 'weights': 'distance', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 9} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:46,556] Trial 59 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:46,839] Trial 60 finished with value: 0.58260516155253 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'distance', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:47,116] Trial 61 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:47,426] Trial 62 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:47,669] Trial 63 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:47,925] Trial 64 finished with value: 0.5495495495495496 and parameters: {'n_neighbors': 6, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:48,290] Trial 65 finished with value: 0.5193107546048723 and parameters: {'n_neighbors': 14, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 6}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:48,552] Trial 66 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:48,787] Trial 67 finished with value: 0.28454551526080274 and parameters: {'n_neighbors': 36, 'p': 2, 'weights': 'distance', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:49,020] Trial 68 finished with value: 0.5588529706176765 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:49,258] Trial 69 finished with value: 0.5591630591630592 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:49,479] Trial 70 finished with value: 0.5842383737120579 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:49,735] Trial 71 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:50,070] Trial 72 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 137, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 137, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 137, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:50,382] Trial 73 failed with parameters: {'n_neighbors': 137, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:50,384] Trial 73 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:50,609] Trial 74 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 140, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 140, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 140, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:50,848] Trial 75 failed with parameters: {'n_neighbors': 140, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:50,849] Trial 75 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:51,074] Trial 76 finished with value: 0.5588529706176765 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:51,319] Trial 77 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:51,575] Trial 78 finished with value: 0.08474747474747475 and parameters: {'n_neighbors': 103, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:51,808] Trial 79 finished with value: 0.5588529706176765 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:52,065] Trial 80 finished with value: 0.29221674876847287 and parameters: {'n_neighbors': 27, 'p': 2, 'weights': 'distance', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 7}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:52,352] Trial 81 finished with value: 0.54002574002574 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': None, 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:52,591] Trial 82 finished with value: 0.6070303965040806 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:52,812] Trial 83 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:53,029] Trial 84 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 154, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 154, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 154, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:53,231] Trial 85 failed with parameters: {'n_neighbors': 154, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:53,233] Trial 85 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:53,465] Trial 86 finished with value: 0.4905913978494623 and parameters: {'n_neighbors': 19, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:53,709] Trial 87 finished with value: 0.23823953823953822 and parameters: {'n_neighbors': 51, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:53,938] Trial 88 finished with value: 0.5 and parameters: {'n_neighbors': 8, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:54,187] Trial 89 finished with value: 0.5588529706176765 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:54,434] Trial 90 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:54,643] Trial 91 finished with value: 0.5842383737120579 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:54,846] Trial 92 finished with value: 0.5372549019607843 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:55,020] Trial 93 finished with value: 0.4437927663734116 and parameters: {'n_neighbors': 11, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:55,196] Trial 94 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:55,387] Trial 95 finished with value: 0.4868035190615836 and parameters: {'n_neighbors': 16, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:55,565] Trial 96 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 160, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 160, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 160, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 03:45:55,719] Trial 97 failed with parameters: {'n_neighbors': 160, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 03:45:55,726] Trial 97 failed with value np.float64(nan).\n",
      "[I 2025-11-03 03:45:55,900] Trial 98 finished with value: 0.5588529706176765 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 49 with value: 0.6072124756335283.\n",
      "[I 2025-11-03 03:45:56,069] Trial 99 finished with value: 0.6072124756335283 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 49 with value: 0.6072124756335283.\n"
     ]
    }
   ],
   "source": [
    "study_knn.optimize(parcial_knn, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07227716-336a-4a31-8476-4068c93b40c1",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "205f7562-1bfe-41dc-9b3c-ba714bf8f2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 49\n",
      "Parâmetros do melhor trial: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}\n"
     ]
    }
   ],
   "source": [
    "resultado_knn = study_knn.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_knn.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_knn.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b97c8-4b17-479e-95c4-d7668def0dae",
   "metadata": {},
   "source": [
    "## Otimizando um modelo Support Vector Machine Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d9f4b-c9fb-42cc-b928-25f84d57ce5c",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750a047-ffdb-4071-a382-db842e5c4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_svc(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador SVC\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),  \n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "            \"gamma\": trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]),\n",
    "            \"degree\": trial.suggest_int(\"degree\", 1, 5), \n",
    "            \"coef0\": trial.suggest_float(\"coef0\", 0.0, 1.0), \n",
    "            \"max_iter\": 10000,\n",
    "        }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Instânciando o modelo\n",
    "    modelo = SVC(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db3cd2-dd5b-4d04-b8b4-af0db33116c5",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8490e3c2-09ee-4a2a-8d1a-5e7cac1e26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_svc(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_svc(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afaf93a-ea28-4931-a801-371cc3bd8a94",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ef6ca8-c394-4a91-9d04-fbe5a0315041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:45:56,556] A new study created in RDB with name: Estudo SVC\n"
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_svc = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo SVC\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo SVC\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1fe31-375a-4a90-a15e-b98aa037954d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4fedd73-9c4b-4551-87ac-48452889cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": None,\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos \n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"minmax\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"maxabs\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"pca\",\n",
    "        \"pca_components\": 9\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d0aa5-9182-48ce-b33d-08f1f96d008d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd4c3cf-9799-4ea6-8a95-e4855f2f289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_svc(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_svc(trial, x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53449ffd-1c08-447d-8926-66c2b93e3b06",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4a66071-3bc0-4c6d-882f-53d003097313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:45:56,895] Trial 0 finished with value: 0.0 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-11-03 03:45:57,076] Trial 1 finished with value: 0.6464646464646465 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': 'standard', 'treatment': None}. Best is trial 1 with value: 0.6464646464646465.\n",
      "[I 2025-11-03 03:45:57,313] Trial 2 finished with value: 0.625 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': 'minmax', 'treatment': None}. Best is trial 1 with value: 0.6464646464646465.\n",
      "[I 2025-11-03 03:45:57,506] Trial 3 finished with value: 0.5565476190476191 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': 'maxabs', 'treatment': None}. Best is trial 1 with value: 0.6464646464646465.\n",
      "[I 2025-11-03 03:45:57,706] Trial 4 finished with value: 0.6464646464646465 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 1 with value: 0.6464646464646465.\n",
      "[I 2025-11-03 03:45:57,896] Trial 5 finished with value: 0.0 and parameters: {'C': 0.008799311564803408, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 4, 'coef0': 0.4583054228820381, 'normalization': None, 'treatment': None}. Best is trial 1 with value: 0.6464646464646465.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:45:58,098] Trial 6 finished with value: 0.4612332112332112 and parameters: {'C': 0.12253427525595112, 'kernel': 'linear', 'gamma': 'auto', 'degree': 1, 'coef0': 0.7531009414207831, 'normalization': None, 'treatment': 'pca', 'pca_components': 3}. Best is trial 1 with value: 0.6464646464646465.\n",
      "[I 2025-11-03 03:45:58,276] Trial 7 finished with value: 0.0 and parameters: {'C': 1.2827649490312554, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 1, 'coef0': 0.5351600224588438, 'normalization': None, 'treatment': None}. Best is trial 1 with value: 0.6464646464646465.\n",
      "[I 2025-11-03 03:45:58,481] Trial 8 finished with value: 0.6586038961038961 and parameters: {'C': 8.377683758868354, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.9671843046812459, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 9}. Best is trial 8 with value: 0.6586038961038961.\n",
      "[I 2025-11-03 03:45:58,666] Trial 9 finished with value: 0.5655913978494623 and parameters: {'C': 0.590993944320208, 'kernel': 'linear', 'gamma': 'auto', 'degree': 5, 'coef0': 0.4378144448835888, 'normalization': 'minmax', 'treatment': None}. Best is trial 8 with value: 0.6586038961038961.\n",
      "[I 2025-11-03 03:45:58,907] Trial 10 finished with value: 0.723727000427899 and parameters: {'C': 111.79775690041879, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.9944868095389932, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 9}. Best is trial 10 with value: 0.723727000427899.\n",
      "[I 2025-11-03 03:45:59,156] Trial 11 finished with value: 0.7396184732961161 and parameters: {'C': 205.44893307848713, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.9654630484956012, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 9}. Best is trial 11 with value: 0.7396184732961161.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:45:59,356] Trial 12 finished with value: 0.7287128308115262 and parameters: {'C': 861.225938658861, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.9886615469884897, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 7}. Best is trial 11 with value: 0.7396184732961161.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:45:59,565] Trial 13 finished with value: 0.7132089548425341 and parameters: {'C': 852.552358936232, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.8040418922221615, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 6}. Best is trial 11 with value: 0.7396184732961161.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:45:59,783] Trial 14 finished with value: 0.7353801169590644 and parameters: {'C': 321.25810469329696, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8533598406986471, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 6}. Best is trial 11 with value: 0.7396184732961161.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:45:59,975] Trial 15 finished with value: 0.2832457397674789 and parameters: {'C': 63.79924430295367, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.7902070926820683, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 3}. Best is trial 11 with value: 0.7396184732961161.\n",
      "[I 2025-11-03 03:46:00,204] Trial 16 finished with value: 0.5802806290611168 and parameters: {'C': 70.81436930245665, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 4, 'coef0': 0.6719331435410397, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 5}. Best is trial 11 with value: 0.7396184732961161.\n",
      "[I 2025-11-03 03:46:00,435] Trial 17 finished with value: 0.5930555555555556 and parameters: {'C': 16.555409574010863, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.23489959481009415, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 7}. Best is trial 11 with value: 0.7396184732961161.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:00,674] Trial 18 finished with value: 0.7494845761854748 and parameters: {'C': 223.78266507483713, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8722377886324604, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 18 with value: 0.7494845761854748.\n",
      "[I 2025-11-03 03:46:00,922] Trial 19 finished with value: 0.3878066378066378 and parameters: {'C': 8.697815624730413, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.6338367412052333, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 4}. Best is trial 18 with value: 0.7494845761854748.\n",
      "[I 2025-11-03 03:46:01,154] Trial 20 finished with value: 0.3759780240598655 and parameters: {'C': 27.584648041685487, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 5, 'coef0': 0.8685388398675769, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 2}. Best is trial 18 with value: 0.7494845761854748.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:01,396] Trial 21 finished with value: 0.7494845761854748 and parameters: {'C': 266.2971870108651, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.882246817487865, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 18 with value: 0.7494845761854748.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:01,670] Trial 22 finished with value: 0.7457160342717258 and parameters: {'C': 241.29810344963383, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8803619245679768, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 18 with value: 0.7494845761854748.\n",
      "[I 2025-11-03 03:46:01,936] Trial 23 finished with value: 0.0 and parameters: {'C': 0.0013274569888578897, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.6765418360318862, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 18 with value: 0.7494845761854748.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:02,167] Trial 24 finished with value: 0.7178383548541368 and parameters: {'C': 303.4097277565161, 'kernel': 'linear', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8809869941065529, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 18 with value: 0.7494845761854748.\n",
      "[I 2025-11-03 03:46:02,480] Trial 25 finished with value: 0.7062247121070651 and parameters: {'C': 34.86325945453153, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.5864543224514198, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 18 with value: 0.7494845761854748.\n",
      "[I 2025-11-03 03:46:02,711] Trial 26 finished with value: 0.6532818532818533 and parameters: {'C': 6.267857242247115, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'coef0': 0.32548179657940957, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 8}. Best is trial 18 with value: 0.7494845761854748.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:02,974] Trial 27 finished with value: 0.7555821371610846 and parameters: {'C': 374.1140756907869, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.7160741995470711, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 27 with value: 0.7555821371610846.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:03,206] Trial 28 finished with value: 0.5815210932857992 and parameters: {'C': 954.0884947580287, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.7045620029182826, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 4}. Best is trial 27 with value: 0.7555821371610846.\n",
      "[I 2025-11-03 03:46:03,436] Trial 29 finished with value: 0.28712237583205324 and parameters: {'C': 0.0461114931981015, 'kernel': 'linear', 'gamma': 'scale', 'degree': 2, 'coef0': 0.7561015399573484, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 27 with value: 0.7555821371610846.\n",
      "[I 2025-11-03 03:46:03,665] Trial 30 finished with value: 0.4453526697429136 and parameters: {'C': 134.9723191453407, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 3, 'coef0': 0.904583588238366, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 4}. Best is trial 27 with value: 0.7555821371610846.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:03,914] Trial 31 finished with value: 0.7566051881841357 and parameters: {'C': 411.1995837998602, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8383305210950958, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:04,166] Trial 32 finished with value: 0.7499648520635475 and parameters: {'C': 400.7778037688479, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.7988119653303545, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:04,413] Trial 33 finished with value: 0.7025038976258489 and parameters: {'C': 585.6240038666126, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.8164840890779159, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:04,636] Trial 34 finished with value: 0.7016974433310225 and parameters: {'C': 59.07483455699344, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3, 'coef0': 0.7383472991848072, 'normalization': 'minmax', 'treatment': None}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:04,863] Trial 35 finished with value: 0.5672619047619047 and parameters: {'C': 2.9057228979001177, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 2, 'coef0': 0.6348143458929847, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 4}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:05,099] Trial 36 finished with value: 0.7105820105820105 and parameters: {'C': 106.63621228062773, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.5554688374510073, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:05,316] Trial 37 finished with value: 0.7221477709282588 and parameters: {'C': 368.6861875973732, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.9320638996533328, 'normalization': 'minmax', 'treatment': None}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:05,544] Trial 38 finished with value: 0.5613181312569521 and parameters: {'C': 20.65702554277578, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.8055505631193607, 'normalization': None, 'treatment': None}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:05,831] Trial 39 finished with value: 0.5083934282933033 and parameters: {'C': 456.8264178689643, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 3, 'coef0': 0.7194094629869628, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:06,066] Trial 40 finished with value: 0.11870255348516218 and parameters: {'C': 0.18187681526677518, 'kernel': 'linear', 'gamma': 'auto', 'degree': 2, 'coef0': 0.14636026717837058, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 3}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:06,308] Trial 41 finished with value: 0.7457160342717258 and parameters: {'C': 228.4132801713861, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8403695042657778, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:06,559] Trial 42 finished with value: 0.7457160342717258 and parameters: {'C': 144.87133180085326, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.9200819600716453, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:06,816] Trial 43 finished with value: 0.6882446758607749 and parameters: {'C': 49.09405866704284, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.7686228974323707, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:07,101] Trial 44 finished with value: 0.4690020069330414 and parameters: {'C': 583.6398137539638, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.9396363207805968, 'normalization': None, 'treatment': 'pca', 'pca_components': 4}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:07,360] Trial 45 finished with value: 0.7147917147917148 and parameters: {'C': 193.59463581000736, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.4655458838403336, 'normalization': 'minmax', 'treatment': None}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:07,621] Trial 46 finished with value: 0.7292825559834545 and parameters: {'C': 104.76058528367933, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.824361794164858, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:07,974] Trial 47 finished with value: 0.7275854227073739 and parameters: {'C': 483.8100036832862, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 5, 'coef0': 0.7727960925798172, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:08,240] Trial 48 finished with value: 0.42679305276419593 and parameters: {'C': 998.7862248094976, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.6104173131040725, 'normalization': None, 'treatment': 'pca', 'pca_components': 8}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:08,479] Trial 49 finished with value: 0.7136275031011873 and parameters: {'C': 16.08723383244656, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3, 'coef0': 0.9975663052385766, 'normalization': 'minmax', 'treatment': None}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:08,710] Trial 50 finished with value: 0.618795049639603 and parameters: {'C': 79.99975347012037, 'kernel': 'linear', 'gamma': 'auto', 'degree': 5, 'coef0': 0.6923764927169461, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:08,950] Trial 51 finished with value: 0.7408001711596063 and parameters: {'C': 228.6740761239537, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.848883786265308, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:09,187] Trial 52 finished with value: 0.7404306220095694 and parameters: {'C': 352.4834576122787, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8858657378535424, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:09,426] Trial 53 finished with value: 0.7396184732961161 and parameters: {'C': 191.17256136483078, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.9577033211456972, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:09,665] Trial 54 finished with value: 0.674391862007961 and parameters: {'C': 39.92788581806221, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.9045270951306945, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 8}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:09,904] Trial 55 finished with value: 0.7359731824848105 and parameters: {'C': 536.6766383011587, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8720330528649274, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:10,126] Trial 56 finished with value: 0.7501949317738791 and parameters: {'C': 283.3830940707069, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.8360819072925352, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:10,348] Trial 57 finished with value: 0.6075306075306076 and parameters: {'C': 130.54336460355032, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 5, 'coef0': 0.7289509880776521, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:10,588] Trial 58 finished with value: 0.7350543765177912 and parameters: {'C': 665.2499086702805, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.7757027098259449, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:10,816] Trial 59 finished with value: 0.0 and parameters: {'C': 78.49016545349343, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 5, 'coef0': 0.3847403417821924, 'normalization': None, 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:11,083] Trial 60 finished with value: 0.523423944476576 and parameters: {'C': 306.465227550082, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.8365365931271943, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 4}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:11,319] Trial 61 finished with value: 0.7286324786324786 and parameters: {'C': 236.10833043964908, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8028295066294593, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:11,568] Trial 62 finished with value: 0.0 and parameters: {'C': 0.010716918740458856, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.8712279603999452, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:11,951] Trial 63 finished with value: 0.7292825559834545 and parameters: {'C': 162.7016189021209, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.9513320609680258, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:12,227] Trial 64 finished with value: 0.7456995456995458 and parameters: {'C': 360.21770214239217, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.9059428475547296, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:12,478] Trial 65 finished with value: 0.6684335272570566 and parameters: {'C': 676.2204914997451, 'kernel': 'poly', 'gamma': 'auto', 'degree': 1, 'coef0': 0.6659663358640315, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 8}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:12,728] Trial 66 finished with value: 0.6868686868686869 and parameters: {'C': 25.414035874770175, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.7991186401223416, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:12,975] Trial 67 finished with value: 0.6948625492077145 and parameters: {'C': 100.40271366333371, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'coef0': 0.7470796488780356, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:13,183] Trial 68 finished with value: 0.6288416075650117 and parameters: {'C': 934.0065172670475, 'kernel': 'linear', 'gamma': 'auto', 'degree': 5, 'coef0': 0.9692134833136742, 'normalization': 'standard', 'treatment': None}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:13,416] Trial 69 finished with value: 0.5754385964912281 and parameters: {'C': 270.0611236456042, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 3, 'coef0': 0.8491619660228342, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:13,726] Trial 70 finished with value: 0.7220378273009853 and parameters: {'C': 44.46033852865137, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8953505967848987, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:13,967] Trial 71 finished with value: 0.727954971857411 and parameters: {'C': 158.1714609860284, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8353161895219982, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:14,189] Trial 72 finished with value: 0.7566051881841357 and parameters: {'C': 425.94498684754814, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8169707819355703, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:14,396] Trial 73 finished with value: 0.7494518909153056 and parameters: {'C': 344.67258762103535, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.9255321467120499, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:14,620] Trial 74 finished with value: 0.7501949317738791 and parameters: {'C': 430.35182519769626, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.934083417986894, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:14,858] Trial 75 finished with value: 0.7295249795249795 and parameters: {'C': 467.5850851931614, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8184105772569445, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:15,099] Trial 76 finished with value: 0.0 and parameters: {'C': 2.1617219999442026, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.05659650471073119, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:15,369] Trial 77 finished with value: 0.7016974433310225 and parameters: {'C': 707.8558428787435, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.7925067916427706, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:15,611] Trial 78 finished with value: 0.7275854227073739 and parameters: {'C': 470.2702476814395, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 3, 'coef0': 0.8628532843464839, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:15,837] Trial 79 finished with value: 0.716075483517344 and parameters: {'C': 69.61382988360626, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'coef0': 0.9692302002303524, 'normalization': 'minmax', 'treatment': None}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:16,116] Trial 80 finished with value: 0.4475832266325224 and parameters: {'C': 0.2256333114119061, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.7208098319176444, 'normalization': None, 'treatment': 'pca', 'pca_components': 4}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:16,374] Trial 81 finished with value: 0.7456995456995458 and parameters: {'C': 350.7778839020111, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.9296205670062804, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:16,612] Trial 82 finished with value: 0.7501949317738791 and parameters: {'C': 275.5667938987737, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.9176736799908354, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:16,881] Trial 83 finished with value: 0.7389683959451401 and parameters: {'C': 182.8527797607232, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.889815430077002, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:17,149] Trial 84 finished with value: 0.7314814814814814 and parameters: {'C': 110.73178851345524, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.8597471394778516, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:17,403] Trial 85 finished with value: 0.7501949317738791 and parameters: {'C': 760.9700366198138, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.7617371801412948, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:17,646] Trial 86 finished with value: 0.6308682308682309 and parameters: {'C': 725.9340302394937, 'kernel': 'linear', 'gamma': 'auto', 'degree': 4, 'coef0': 0.7835759616645586, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:17,901] Trial 87 finished with value: 0.6507936507936508 and parameters: {'C': 548.7748803602631, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.7552801461568974, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:18,135] Trial 88 finished with value: 0.7566051881841357 and parameters: {'C': 911.5795286400489, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.8218643233963262, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:18,396] Trial 89 finished with value: 0.754322803103291 and parameters: {'C': 425.4636359014482, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.6896014906517335, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:18,645] Trial 90 finished with value: 0.5284552845528455 and parameters: {'C': 882.9932870671611, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 2, 'coef0': 0.6940911273081556, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:18,898] Trial 91 finished with value: 0.6951714951714951 and parameters: {'C': 426.0602000235594, 'kernel': 'poly', 'gamma': 'auto', 'degree': 1, 'coef0': 0.6607793594032529, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:19,320] Trial 92 finished with value: 0.7488344988344989 and parameters: {'C': 972.1851958970487, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.5414308688838848, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:19,560] Trial 93 finished with value: 0.7298245614035088 and parameters: {'C': 564.9189820118943, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.8239305786692405, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:19,806] Trial 94 finished with value: 0.727954971857411 and parameters: {'C': 290.1589357278387, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.7515792694524411, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:20,104] Trial 95 finished with value: 0.7003663003663004 and parameters: {'C': 418.15729053212664, 'kernel': 'poly', 'gamma': 'auto', 'degree': 1, 'coef0': 0.5831364179034528, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 03:46:20,342] Trial 96 finished with value: 0.6791791791791791 and parameters: {'C': 703.0833990285657, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3, 'coef0': 0.6358232299955788, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:20,603] Trial 97 finished with value: 0.7169793621013133 and parameters: {'C': 262.3365704720797, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.7240095224806737, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 6}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:20,836] Trial 98 finished with value: 0.7332332332332333 and parameters: {'C': 183.01450491240078, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 2, 'coef0': 0.7787278174017614, 'normalization': 'minmax', 'treatment': None}. Best is trial 31 with value: 0.7566051881841357.\n",
      "[I 2025-11-03 03:46:21,078] Trial 99 finished with value: 0.25746031746031744 and parameters: {'C': 0.5571065479567396, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.8075331881276864, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 31 with value: 0.7566051881841357.\n"
     ]
    }
   ],
   "source": [
    "study_svc.optimize(parcial_svc, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77defc-89f8-4790-9e30-93c7d27c01e3",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f3cd1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3849ad86-53d0-44d5-8a09-4b8e2645dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 31\n",
      "Parâmetros do melhor trial: {'C': 411.1995837998602, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.8383305210950958, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}\n"
     ]
    }
   ],
   "source": [
    "resultado_svc = study_svc.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_svc.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_svc.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685e968-3a8e-4710-821f-ad41e0688f46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo de Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab93d6-efb1-4f8f-bbbf-d2982b4864a9",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b40cd75b-8030-40ca-99c5-e52a183a381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_lrc(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador por Regressão Logística\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "        \"C\": trial.suggest_float(\"C\", 0.01, 10.0, log=True),\n",
    "        \"class_weight\": trial.suggest_categorical(\"class_weight\", [\"balanced\", None]),\n",
    "        \"solver\":\"liblinear\",\n",
    "        \"max_iter\":5000,\n",
    "        \"random_state\":semente\n",
    "    }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\", \"rfe\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Adiciona tratamento RFE \n",
    "    elif treatment == \"rfe\": \n",
    "        # Definindo o estimador \n",
    "        estimator = LogisticRegression(**params)\n",
    "        # Definindo o número de atributos a serem mantidos\n",
    "        n_features_to_select = trial.suggest_int(\"rfe_features\", 2, 9)\n",
    "        steps.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "        \n",
    "    # Instânciando o modelo\n",
    "    modelo = LogisticRegression(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624a53c-a08a-4082-a23f-ab641655ba20",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fec90b1-1e1d-4d61-aa8b-c5915e784551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_lrc(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_lrc(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133736b-3e5e-4435-8b09-e23719c5e8b9",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d27304a0-418e-437a-b0a1-b08a2a34e361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:46:21,616] A new study created in RDB with name: Estudo LRC\n"
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_lrc = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo LRC\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo LRC\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748ee444-879e-4583-85a4-25adce2dca42",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd38c992-f6a6-4668-91f7-44f3525a4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "        \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": None,\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Modelo base com normalização padrão\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "        \"penalty\": \"l2\",  \n",
    "        \"C\": 1, \n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos \n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "        \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None, \n",
    "        \"normalization\": \"minmax\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "       \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"maxabs\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "       \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"pca\",\n",
    "        \"pca_components\": 9\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e RFE\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "       \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"rfe\",\n",
    "        \"rfe_features\": 9\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93441716-6195-4888-9fd2-0b9e4ce579eb",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd0ca875-a854-400c-88dd-50e0455744ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_lrc(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_lrc(trial, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c5de3-69b3-4342-9b72-884bd4e6718e",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df458bda-0f0f-47f9-9e62-0fef8830dd45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:46:21,957] Trial 0 finished with value: 0.6846846846846848 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.6846846846846848.\n",
      "[I 2025-11-03 03:46:22,130] Trial 1 finished with value: 0.6608465608465609 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.6846846846846848.\n",
      "[I 2025-11-03 03:46:22,301] Trial 2 finished with value: 0.6142336801238849 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 0 with value: 0.6846846846846848.\n",
      "[I 2025-11-03 03:46:22,469] Trial 3 finished with value: 0.6031746031746033 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'maxabs', 'treatment': None}. Best is trial 0 with value: 0.6846846846846848.\n",
      "[I 2025-11-03 03:46:22,669] Trial 4 finished with value: 0.6608465608465609 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 0 with value: 0.6846846846846848.\n",
      "[I 2025-11-03 03:46:22,866] Trial 5 finished with value: 0.6608465608465609 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 9}. Best is trial 0 with value: 0.6846846846846848.\n",
      "[I 2025-11-03 03:46:23,036] Trial 6 finished with value: 0.3098290598290599 and parameters: {'penalty': 'l2', 'C': 0.2766924931613561, 'class_weight': None, 'normalization': 'maxabs', 'treatment': None}. Best is trial 0 with value: 0.6846846846846848.\n",
      "[I 2025-11-03 03:46:23,207] Trial 7 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.015039489521675376, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:23,385] Trial 8 finished with value: 0.6874026995361676 and parameters: {'penalty': 'l1', 'C': 5.832585479789105, 'class_weight': 'balanced', 'normalization': None, 'treatment': 'pca', 'pca_components': 3}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:23,548] Trial 9 finished with value: 0.7464892830746489 and parameters: {'penalty': 'l2', 'C': 4.867175370057107, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:23,766] Trial 10 finished with value: 0.0 and parameters: {'penalty': 'l1', 'C': 0.012323512825894481, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'rfe', 'rfe_features': 2}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:23,932] Trial 11 finished with value: 0.2074074074074074 and parameters: {'penalty': 'l1', 'C': 0.02655215372225922, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:24,106] Trial 12 finished with value: 0.7463198552251303 and parameters: {'penalty': 'l2', 'C': 0.06904073689852992, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:24,283] Trial 13 finished with value: 0.7464892830746489 and parameters: {'penalty': 'l2', 'C': 6.860319768033246, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:24,479] Trial 14 finished with value: 0.7285490564560332 and parameters: {'penalty': 'l1', 'C': 0.09055732796538074, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:24,677] Trial 15 finished with value: 0.7363530778164925 and parameters: {'penalty': 'l2', 'C': 0.2837252170862072, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:24,828] Trial 16 finished with value: 0.7214470284237726 and parameters: {'penalty': 'l2', 'C': 2.6875010212099815, 'class_weight': 'balanced', 'normalization': None, 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:25,016] Trial 17 finished with value: 0.6815503875968991 and parameters: {'penalty': 'l2', 'C': 0.08766479783306294, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:25,200] Trial 18 finished with value: 0.0 and parameters: {'penalty': 'l1', 'C': 0.032545911592030984, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'rfe', 'rfe_features': 9}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:25,422] Trial 19 finished with value: 0.6753070777461021 and parameters: {'penalty': 'l2', 'C': 2.9043632139354374, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 3}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:25,596] Trial 20 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.010137887013806851, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:25,765] Trial 21 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.012000257250060849, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:25,929] Trial 22 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.010986045241319754, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:26,109] Trial 23 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.023325371730928975, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:26,266] Trial 24 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.016212734220287562, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:26,442] Trial 25 finished with value: 0.740782756664776 and parameters: {'penalty': 'l2', 'C': 0.046722067913656344, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:26,595] Trial 26 finished with value: 0.6025396825396826 and parameters: {'penalty': 'l1', 'C': 0.1441262380450226, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:26,781] Trial 27 finished with value: 0.7204800619434765 and parameters: {'penalty': 'l2', 'C': 0.01768252084512741, 'class_weight': 'balanced', 'normalization': None, 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:26,946] Trial 28 finished with value: 0.6821705426356589 and parameters: {'penalty': 'l2', 'C': 0.04246182558725545, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 6}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:27,152] Trial 29 finished with value: 0.701010101010101 and parameters: {'penalty': 'l2', 'C': 0.010073793372308112, 'class_weight': 'balanced', 'normalization': None, 'treatment': 'rfe', 'rfe_features': 2}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:27,326] Trial 30 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.019759551336307253, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:27,488] Trial 31 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.010278379505777693, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:27,642] Trial 32 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.015195724831917045, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:27,804] Trial 33 finished with value: 0.7354973444026195 and parameters: {'penalty': 'l2', 'C': 0.03528584373173748, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:27,968] Trial 34 finished with value: 0.6735449735449736 and parameters: {'penalty': 'l2', 'C': 0.05802305803244296, 'class_weight': None, 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:28,125] Trial 35 finished with value: 0.65203081232493 and parameters: {'penalty': 'l2', 'C': 0.02516594831436527, 'class_weight': None, 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:28,291] Trial 36 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.014686170199953495, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:28,446] Trial 37 finished with value: 0.252415458937198 and parameters: {'penalty': 'l2', 'C': 0.17088035688541636, 'class_weight': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:28,607] Trial 38 finished with value: 0.730797522260937 and parameters: {'penalty': 'l2', 'C': 0.5717791531696614, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:28,800] Trial 39 finished with value: 0.6937469937469937 and parameters: {'penalty': 'l2', 'C': 0.012810858882406554, 'class_weight': None, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 6}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:28,960] Trial 40 finished with value: 0.2074074074074074 and parameters: {'penalty': 'l1', 'C': 0.02624814983478901, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:29,196] Trial 41 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.019693516993293667, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:29,376] Trial 42 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.010310605108856577, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:29,535] Trial 43 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.023785194333254395, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:29,816] Trial 44 finished with value: 0.7354973444026195 and parameters: {'penalty': 'l2', 'C': 0.037332261145154304, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 7 with value: 0.7475979305247598.\n",
      "[I 2025-11-03 03:46:30,010] Trial 45 finished with value: 0.7541019955654101 and parameters: {'penalty': 'l2', 'C': 0.019953451045824404, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:30,209] Trial 46 finished with value: 0.7481962481962482 and parameters: {'penalty': 'l2', 'C': 0.014723576235318319, 'class_weight': 'balanced', 'normalization': None, 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:30,403] Trial 47 finished with value: 0.6644501644501645 and parameters: {'penalty': 'l1', 'C': 0.052502995079493686, 'class_weight': None, 'normalization': None, 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:30,631] Trial 48 finished with value: 0.7097750047267916 and parameters: {'penalty': 'l2', 'C': 0.4604825563244939, 'class_weight': 'balanced', 'normalization': None, 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:30,823] Trial 49 finished with value: 0.7153121032871459 and parameters: {'penalty': 'l2', 'C': 0.0312157331938661, 'class_weight': 'balanced', 'normalization': None, 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:31,006] Trial 50 finished with value: 0.7367402245451026 and parameters: {'penalty': 'l2', 'C': 0.014858934577374775, 'class_weight': 'balanced', 'normalization': None, 'treatment': 'rfe', 'rfe_features': 7}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:31,202] Trial 51 finished with value: 0.6011077925334486 and parameters: {'penalty': 'l2', 'C': 0.012153306105455904, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:31,395] Trial 52 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.021096036095612863, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 7}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:31,625] Trial 53 finished with value: 0.7474163126337038 and parameters: {'penalty': 'l2', 'C': 0.014058642303260913, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:31,829] Trial 54 finished with value: 0.7475979305247598 and parameters: {'penalty': 'l2', 'C': 0.018610956808723395, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 7}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:32,030] Trial 55 finished with value: 0.7153121032871459 and parameters: {'penalty': 'l2', 'C': 9.79558953412666, 'class_weight': 'balanced', 'normalization': None, 'treatment': 'rfe', 'rfe_features': 8}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:32,206] Trial 56 finished with value: 0.0 and parameters: {'penalty': 'l1', 'C': 0.011827357060354935, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 2}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:32,404] Trial 57 finished with value: 0.7515151515151515 and parameters: {'penalty': 'l2', 'C': 0.07648561540722683, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:32,603] Trial 58 finished with value: 0.7515151515151515 and parameters: {'penalty': 'l2', 'C': 0.13701066858984123, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:32,802] Trial 59 finished with value: 0.7105972000708842 and parameters: {'penalty': 'l2', 'C': 0.11814001006385483, 'class_weight': 'balanced', 'normalization': None, 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:33,048] Trial 60 finished with value: 0.6443768996960486 and parameters: {'penalty': 'l2', 'C': 0.09709179179854803, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': 'rfe', 'rfe_features': 3}. Best is trial 45 with value: 0.7541019955654101.\n",
      "[I 2025-11-03 03:46:33,317] Trial 61 finished with value: 0.7658003747056498 and parameters: {'penalty': 'l2', 'C': 0.205446571591904, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 61 with value: 0.7658003747056498.\n",
      "[I 2025-11-03 03:46:33,531] Trial 62 finished with value: 0.7658003747056498 and parameters: {'penalty': 'l2', 'C': 0.2024648924462035, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 61 with value: 0.7658003747056498.\n",
      "[I 2025-11-03 03:46:33,747] Trial 63 finished with value: 0.7658003747056498 and parameters: {'penalty': 'l2', 'C': 0.21509532627096667, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 61 with value: 0.7658003747056498.\n",
      "[I 2025-11-03 03:46:33,960] Trial 64 finished with value: 0.7723044397463003 and parameters: {'penalty': 'l2', 'C': 0.1932645746859868, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:34,186] Trial 65 finished with value: 0.7723044397463003 and parameters: {'penalty': 'l2', 'C': 0.18713279833287103, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:34,386] Trial 66 finished with value: 0.7658003747056498 and parameters: {'penalty': 'l2', 'C': 0.19857174758450183, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:34,616] Trial 67 finished with value: 0.7521270561542824 and parameters: {'penalty': 'l2', 'C': 0.2267535588091413, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:34,849] Trial 68 finished with value: 0.7448068727138494 and parameters: {'penalty': 'l1', 'C': 0.3691388096547463, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:35,046] Trial 69 finished with value: 0.6793650793650793 and parameters: {'penalty': 'l2', 'C': 0.21191014908120906, 'class_weight': None, 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:35,251] Trial 70 finished with value: 0.7406820821454968 and parameters: {'penalty': 'l2', 'C': 0.604543309701101, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:35,462] Trial 71 finished with value: 0.7521270561542824 and parameters: {'penalty': 'l2', 'C': 0.23801220392808808, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:35,664] Trial 72 finished with value: 0.7463198552251303 and parameters: {'penalty': 'l2', 'C': 0.3465397453977458, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:35,913] Trial 73 finished with value: 0.7623376623376624 and parameters: {'penalty': 'l2', 'C': 0.17468713424151516, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:36,122] Trial 74 finished with value: 0.7723044397463003 and parameters: {'penalty': 'l2', 'C': 0.19038603368211618, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:36,336] Trial 75 finished with value: 0.7623376623376624 and parameters: {'penalty': 'l2', 'C': 0.18210458392559317, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:36,545] Trial 76 finished with value: 0.7483747109385227 and parameters: {'penalty': 'l2', 'C': 0.2815606030627647, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:36,773] Trial 77 finished with value: 0.7623376623376624 and parameters: {'penalty': 'l2', 'C': 0.16949934905558517, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:36,995] Trial 78 finished with value: 0.7515151515151515 and parameters: {'penalty': 'l2', 'C': 0.11601964016539429, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:37,224] Trial 79 finished with value: 0.7463198552251303 and parameters: {'penalty': 'l2', 'C': 0.41415510711957126, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:37,418] Trial 80 finished with value: 0.6866168689698102 and parameters: {'penalty': 'l2', 'C': 0.2865294275202517, 'class_weight': None, 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:37,621] Trial 81 finished with value: 0.7723044397463003 and parameters: {'penalty': 'l2', 'C': 0.18264332049738655, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:37,816] Trial 82 finished with value: 0.7723044397463003 and parameters: {'penalty': 'l2', 'C': 0.1844937611711183, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:38,036] Trial 83 finished with value: 0.7623376623376624 and parameters: {'penalty': 'l2', 'C': 0.13841799561176285, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:38,246] Trial 84 finished with value: 0.7421602787456446 and parameters: {'penalty': 'l2', 'C': 0.24339239102093735, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:38,482] Trial 85 finished with value: 0.7658003747056498 and parameters: {'penalty': 'l2', 'C': 0.19855492117322845, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:38,671] Trial 86 finished with value: 0.7282051282051283 and parameters: {'penalty': 'l1', 'C': 0.11587095682065687, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:38,892] Trial 87 finished with value: 0.7515151515151515 and parameters: {'penalty': 'l2', 'C': 0.1508179452712666, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:39,097] Trial 88 finished with value: 0.7463198552251303 and parameters: {'penalty': 'l2', 'C': 0.31304274657640063, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:39,320] Trial 89 finished with value: 0.7087301587301588 and parameters: {'penalty': 'l2', 'C': 0.5041241333911944, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:39,531] Trial 90 finished with value: 0.7406820821454968 and parameters: {'penalty': 'l2', 'C': 0.7296718528078509, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:39,828] Trial 91 finished with value: 0.7658003747056498 and parameters: {'penalty': 'l2', 'C': 0.20592496011476577, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:40,041] Trial 92 finished with value: 0.7723044397463003 and parameters: {'penalty': 'l2', 'C': 0.19304548084672468, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:40,246] Trial 93 finished with value: 0.7463198552251303 and parameters: {'penalty': 'l2', 'C': 0.2548121647589241, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:40,452] Trial 94 finished with value: 0.7515151515151515 and parameters: {'penalty': 'l2', 'C': 0.09846394069482545, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:40,668] Trial 95 finished with value: 0.7048591416146719 and parameters: {'penalty': 'l2', 'C': 0.15531797948612286, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:40,926] Trial 96 finished with value: 0.7463198552251303 and parameters: {'penalty': 'l2', 'C': 0.3502704853144263, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:41,166] Trial 97 finished with value: 0.6675692499221911 and parameters: {'penalty': 'l2', 'C': 0.12656576641103867, 'class_weight': None, 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:41,370] Trial 98 finished with value: 0.7463198552251303 and parameters: {'penalty': 'l2', 'C': 0.0686162928896008, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 64 with value: 0.7723044397463003.\n",
      "[I 2025-11-03 03:46:41,577] Trial 99 finished with value: 0.7614013893083661 and parameters: {'penalty': 'l1', 'C': 0.185474788238427, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 64 with value: 0.7723044397463003.\n"
     ]
    }
   ],
   "source": [
    "study_lrc.optimize(parcial_lrc, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c68dc-b533-4193-b524-3d11cee31a47",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a745ea7-5274-4bbe-85ba-b79e7e357abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 64\n",
      "Parâmetros do melhor trial: {'penalty': 'l2', 'C': 0.1932645746859868, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}\n"
     ]
    }
   ],
   "source": [
    "resultado_lrc = study_lrc.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_lrc.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_lrc.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab9a40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo de DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c569a36",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09d7cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_DecisionTree(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador por DecisionTree\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\",\"entropy\",\"log_loss\"]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 32),\n",
    "        \"min_samples_split\": trial.suggest_float(\"min_samples_split\", 0.01, 1.0),\n",
    "        \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "        \"random_state\": semente\n",
    "    }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade\n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Adiciona tratamento RFE \n",
    "    elif treatment == \"rfe\": \n",
    "        # Definindo o estimador \n",
    "        estimator = DecisionTreeClassifier(**params)\n",
    "        # Definindo o número de atributos a serem mantidos\n",
    "        n_features_to_select = trial.suggest_int(\"rfe_features\", 2, 9)\n",
    "        steps.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "        \n",
    "    # Instanciando o modelo\n",
    "    modelo = DecisionTreeClassifier(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3534cd1",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28f4799f-c3bd-4308-b4c4-fd3ec9e53bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_DecisionTree(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_DecisionTree(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b681b8d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e00b3e93-1eb6-44b5-8908-c2adc9717ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:46:42,132] A new study created in RDB with name: Estudo DecisionTree\n"
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_DecisionTree = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo DecisionTree\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo DTC\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269fade3",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86da30fc-19cc-45c3-81c8-9eebb38c6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"treatment\": None\n",
    "}\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"normalization\": \"standard\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"normalization\": \"minmax\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"normalization\": \"maxabs\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675329b",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19b9addf-bec2-4bf4-919a-6b3a01ad35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_DecisionTree(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_DecisionTree(trial, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1a913",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75c10ac9-758b-43b8-959f-21d36018f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:46:42,516] Trial 0 finished with value: 0.572086397667793 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'normalization': 'minmax', 'treatment': None}. Best is trial 0 with value: 0.572086397667793.\n",
      "[I 2025-11-03 03:46:42,739] Trial 1 finished with value: 0.5487305487305488 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 0 with value: 0.572086397667793.\n",
      "[I 2025-11-03 03:46:42,955] Trial 2 finished with value: 0.6191990309637369 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 9}. Best is trial 2 with value: 0.6191990309637369.\n",
      "[I 2025-11-03 03:46:43,176] Trial 3 finished with value: 0.6073587774934164 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 9}. Best is trial 2 with value: 0.6191990309637369.\n",
      "[I 2025-11-03 03:46:43,380] Trial 4 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.765005870367743, 'min_samples_leaf': 0.36332264070253617, 'max_features': 'sqrt', 'normalization': 'minmax', 'treatment': None}. Best is trial 2 with value: 0.6191990309637369.\n",
      "[I 2025-11-03 03:46:43,596] Trial 5 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 0.9989329324288794, 'min_samples_leaf': 0.47346437082867704, 'max_features': 'log2', 'normalization': 'minmax', 'treatment': None}. Best is trial 2 with value: 0.6191990309637369.\n",
      "[I 2025-11-03 03:46:43,847] Trial 6 finished with value: 0.7093915343915344 and parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 0.07719670330860548, 'min_samples_leaf': 0.3629746688731952, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 6 with value: 0.7093915343915344.\n",
      "[I 2025-11-03 03:46:44,096] Trial 7 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 0.9053317462672636, 'min_samples_leaf': 0.21043702216247895, 'max_features': 'sqrt', 'normalization': 'minmax', 'treatment': None}. Best is trial 6 with value: 0.7093915343915344.\n",
      "[I 2025-11-03 03:46:44,442] Trial 8 finished with value: 0.3782312925170068 and parameters: {'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 0.853460211100688, 'min_samples_leaf': 0.1960694063765874, 'max_features': None, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 4}. Best is trial 6 with value: 0.7093915343915344.\n",
      "[I 2025-11-03 03:46:44,835] Trial 9 finished with value: 0.42790449513138595 and parameters: {'criterion': 'log_loss', 'max_depth': 28, 'min_samples_split': 0.9460124314279585, 'min_samples_leaf': 0.34579201204415666, 'max_features': None, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 6 with value: 0.7093915343915344.\n",
      "[I 2025-11-03 03:46:45,276] Trial 10 finished with value: 0.2638888888888889 and parameters: {'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 0.40503114814011526, 'min_samples_leaf': 0.488977515025412, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 6 with value: 0.7093915343915344.\n",
      "[I 2025-11-03 03:46:45,590] Trial 11 finished with value: 0.1111111111111111 and parameters: {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 0.34303254736567657, 'min_samples_leaf': 0.3241355177877354, 'max_features': 'log2', 'normalization': None, 'treatment': 'pca', 'pca_components': 6}. Best is trial 6 with value: 0.7093915343915344.\n",
      "[I 2025-11-03 03:46:45,880] Trial 12 finished with value: 0.304383788254756 and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 0.26659256690443944, 'min_samples_leaf': 0.15260872283484672, 'max_features': None, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 2}. Best is trial 6 with value: 0.7093915343915344.\n",
      "[I 2025-11-03 03:46:46,143] Trial 13 finished with value: 0.7252858590244609 and parameters: {'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 0.5617715013125684, 'min_samples_leaf': 0.4092011095750323, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 13 with value: 0.7252858590244609.\n",
      "[I 2025-11-03 03:46:46,409] Trial 14 finished with value: 0.7252858590244609 and parameters: {'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 0.6456185387695199, 'min_samples_leaf': 0.4284518839065458, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 13 with value: 0.7252858590244609.\n",
      "[I 2025-11-03 03:46:46,662] Trial 15 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 19, 'min_samples_split': 0.6598195870953093, 'min_samples_leaf': 0.4239368563130451, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:46,899] Trial 16 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 0.5754141352249996, 'min_samples_leaf': 0.41814209942255187, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:47,146] Trial 17 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 0.6957966114197776, 'min_samples_leaf': 0.2847837222827461, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:47,386] Trial 18 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 0.5370458559628949, 'min_samples_leaf': 0.42311153109674327, 'max_features': 'log2', 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:47,635] Trial 19 finished with value: 0.6941919191919191 and parameters: {'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 0.43713028976785173, 'min_samples_leaf': 0.2992597667701707, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:47,909] Trial 20 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.6627546747581526, 'min_samples_leaf': 0.4536184854512407, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:48,161] Trial 21 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.6569513018148023, 'min_samples_leaf': 0.44821149779095476, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:48,385] Trial 22 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 0.757925195109128, 'min_samples_leaf': 0.3989629158160906, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:48,612] Trial 23 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 0.5846802957949413, 'min_samples_leaf': 0.4987136106734279, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:48,834] Trial 24 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 26, 'min_samples_split': 0.4537208081044263, 'min_samples_leaf': 0.38221070547377267, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:49,116] Trial 25 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.8058179488639212, 'min_samples_leaf': 0.4428483356247009, 'max_features': 'log2', 'normalization': 'maxabs', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:49,368] Trial 26 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 0.6975019875746192, 'min_samples_leaf': 0.46814919276994327, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:49,599] Trial 27 finished with value: 0.7214646464646464 and parameters: {'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.6042678382458908, 'min_samples_leaf': 0.258023577932991, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:49,838] Trial 28 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.49939824848958825, 'min_samples_leaf': 0.33344130913206194, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:50,082] Trial 29 finished with value: 0.3813428401663696 and parameters: {'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 0.33295752502070447, 'min_samples_leaf': 0.11267764701561989, 'max_features': 'log2', 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:50,396] Trial 30 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 0.1866402134494899, 'min_samples_leaf': 0.3884648268850713, 'max_features': None, 'normalization': 'maxabs', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:50,678] Trial 31 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.6732342970617641, 'min_samples_leaf': 0.44763151577041593, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:50,914] Trial 32 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 26, 'min_samples_split': 0.7484142717406195, 'min_samples_leaf': 0.4552524898988519, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:51,143] Trial 33 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 20, 'min_samples_split': 0.6350322689608635, 'min_samples_leaf': 0.4208503922454521, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:51,351] Trial 34 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.47769077455985065, 'min_samples_leaf': 0.4951062476635911, 'max_features': 'sqrt', 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:51,566] Trial 35 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 28, 'min_samples_split': 0.5404654981367958, 'min_samples_leaf': 0.374265217562176, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:51,807] Trial 36 finished with value: 0.6009043576341682 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.8038426823993373, 'min_samples_leaf': 0.4532875879531988, 'max_features': 'sqrt', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 3}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:52,026] Trial 37 finished with value: 0.7127711541645967 and parameters: {'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 0.7198492925296968, 'min_samples_leaf': 0.3083919218395836, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:52,258] Trial 38 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.6112188579690725, 'min_samples_leaf': 0.35371301175075315, 'max_features': 'sqrt', 'normalization': 'minmax', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:52,536] Trial 39 finished with value: 0.6803291946149089 and parameters: {'criterion': 'log_loss', 'max_depth': 19, 'min_samples_split': 0.8502843187188935, 'min_samples_leaf': 0.40346281428739544, 'max_features': None, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 7}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:52,765] Trial 40 finished with value: 0.7209321175278621 and parameters: {'criterion': 'log_loss', 'max_depth': 28, 'min_samples_split': 0.6552390662343789, 'min_samples_leaf': 0.4753768512128202, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:52,988] Trial 41 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 25, 'min_samples_split': 0.7578413194456801, 'min_samples_leaf': 0.4021774862555297, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:53,236] Trial 42 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 22, 'min_samples_split': 0.7964522496155237, 'min_samples_leaf': 0.43150131765990085, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:53,486] Trial 43 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 16, 'min_samples_split': 0.8764589261191448, 'min_samples_leaf': 0.3861753873914247, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:53,716] Trial 44 finished with value: 0.7379018144975591 and parameters: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 0.7297324707925993, 'min_samples_leaf': 0.4692947479912876, 'max_features': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:53,946] Trial 45 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 18, 'min_samples_split': 0.03057582931841968, 'min_samples_leaf': 0.3622949345429198, 'max_features': 'log2', 'normalization': 'standard', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:54,209] Trial 46 finished with value: 0.6729907773386034 and parameters: {'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.979208461162046, 'min_samples_leaf': 0.40468441251262466, 'max_features': None, 'normalization': None, 'treatment': 'pca', 'pca_components': 4}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:54,446] Trial 47 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.5791005415430825, 'min_samples_leaf': 0.22197102111152153, 'max_features': 'sqrt', 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:54,686] Trial 48 finished with value: 0.7252858590244609 and parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 0.5237233031769966, 'min_samples_leaf': 0.44212082486216003, 'max_features': None, 'normalization': 'maxabs', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:54,947] Trial 49 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 0.6318816410463095, 'min_samples_leaf': 0.33712457757402625, 'max_features': None, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 2}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:55,188] Trial 50 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.37628056595409015, 'min_samples_leaf': 0.4164674163756962, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:55,495] Trial 51 finished with value: 0.7209321175278621 and parameters: {'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 0.6799476534768735, 'min_samples_leaf': 0.4753302545975214, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:55,738] Trial 52 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 0.7068807592636194, 'min_samples_leaf': 0.459627608698143, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:56,000] Trial 53 finished with value: 0.7209321175278621 and parameters: {'criterion': 'log_loss', 'max_depth': 25, 'min_samples_split': 0.7843170825298569, 'min_samples_leaf': 0.47503740646706877, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:56,240] Trial 54 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 20, 'min_samples_split': 0.8390004370937756, 'min_samples_leaf': 0.42967683696971426, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:56,458] Trial 55 finished with value: 0.2638888888888889 and parameters: {'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 0.9229252533073411, 'min_samples_leaf': 0.48425217603677884, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:56,672] Trial 56 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 22, 'min_samples_split': 0.6874690091309136, 'min_samples_leaf': 0.4979657580349671, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:56,906] Trial 57 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 27, 'min_samples_split': 0.5771685867947931, 'min_samples_leaf': 0.4391206002772671, 'max_features': 'log2', 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:57,138] Trial 58 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.612503439180482, 'min_samples_leaf': 0.3766885509488544, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:57,382] Trial 59 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 19, 'min_samples_split': 0.746330960112678, 'min_samples_leaf': 0.08398394026674699, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:57,643] Trial 60 finished with value: 0.6677158011307339 and parameters: {'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 0.5535944484771325, 'min_samples_leaf': 0.0138857145896851, 'max_features': None, 'normalization': None, 'treatment': 'pca', 'pca_components': 7}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:57,840] Trial 61 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.6723825881408717, 'min_samples_leaf': 0.45475757840277836, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:58,536] Trial 62 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 25, 'min_samples_split': 0.658500543107406, 'min_samples_leaf': 0.3994468089765974, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:58,743] Trial 63 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.7073755009532523, 'min_samples_leaf': 0.44754891037368383, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:58,938] Trial 64 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 0.6294833016589868, 'min_samples_leaf': 0.42011440602625455, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:59,160] Trial 65 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 18, 'min_samples_split': 0.5090384595102262, 'min_samples_leaf': 0.4697410037958214, 'max_features': 'sqrt', 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:59,374] Trial 66 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 26, 'min_samples_split': 0.7645984029964428, 'min_samples_leaf': 0.4371889836094897, 'max_features': 'log2', 'normalization': 'maxabs', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:59,583] Trial 67 finished with value: 0.7379018144975591 and parameters: {'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 0.6620874451218722, 'min_samples_leaf': 0.457307419982509, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:46:59,811] Trial 68 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 30, 'min_samples_split': 0.5985934848525684, 'min_samples_leaf': 0.41754852202465825, 'max_features': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:00,054] Trial 69 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 20, 'min_samples_split': 0.8222302299013442, 'min_samples_leaf': 0.2668715983836566, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:00,289] Trial 70 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.7165662964591143, 'min_samples_leaf': 0.15856842101592622, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:00,509] Trial 71 finished with value: 0.2638888888888889 and parameters: {'criterion': 'log_loss', 'max_depth': 27, 'min_samples_split': 0.7415288447970874, 'min_samples_leaf': 0.4858738211171261, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:00,723] Trial 72 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 26, 'min_samples_split': 0.6928392703813081, 'min_samples_leaf': 0.4526901119206684, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:01,009] Trial 73 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 25, 'min_samples_split': 0.776207475946425, 'min_samples_leaf': 0.3888720608046701, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:01,241] Trial 74 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 27, 'min_samples_split': 0.8698676636279978, 'min_samples_leaf': 0.42956457188669317, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:01,451] Trial 75 finished with value: 0.2638888888888889 and parameters: {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 0.6347375172244442, 'min_samples_leaf': 0.4858228835227311, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:01,702] Trial 76 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 0.4814249638829061, 'min_samples_leaf': 0.46033106672152063, 'max_features': 'sqrt', 'normalization': None, 'treatment': 'pca', 'pca_components': 4}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:01,903] Trial 77 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 0.7276646648907219, 'min_samples_leaf': 0.4102670348571935, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:02,111] Trial 78 finished with value: 0.7127711541645967 and parameters: {'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 0.5611849305645417, 'min_samples_leaf': 0.368829078327199, 'max_features': None, 'normalization': 'maxabs', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:02,333] Trial 79 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 0.7570008743838631, 'min_samples_leaf': 0.39254674303996995, 'max_features': 'log2', 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:02,571] Trial 80 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.8184712980865746, 'min_samples_leaf': 0.3514839604471898, 'max_features': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:02,869] Trial 81 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 20, 'min_samples_split': 0.6350293026116204, 'min_samples_leaf': 0.44303798458522614, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:03,157] Trial 82 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 17, 'min_samples_split': 0.6000102569515584, 'min_samples_leaf': 0.42143363651850196, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:03,521] Trial 83 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.675115007021261, 'min_samples_leaf': 0.46915494499177557, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:03,791] Trial 84 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 0.6464982973428959, 'min_samples_leaf': 0.43616698149024635, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:04,117] Trial 85 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.6215927526763255, 'min_samples_leaf': 0.46256924767747304, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:04,469] Trial 86 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 16, 'min_samples_split': 0.6970872264473269, 'min_samples_leaf': 0.41338434288486064, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:04,778] Trial 87 finished with value: 0.6545454545454544 and parameters: {'criterion': 'log_loss', 'max_depth': 20, 'min_samples_split': 0.5912327886848652, 'min_samples_leaf': 0.3983024313214984, 'max_features': None, 'normalization': None, 'treatment': 'pca', 'pca_components': 8}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:05,052] Trial 88 finished with value: 0.2695035460992908 and parameters: {'criterion': 'log_loss', 'max_depth': 19, 'min_samples_split': 0.7850630688134553, 'min_samples_leaf': 0.48046537972218295, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:05,481] Trial 89 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 0.7313507280595295, 'min_samples_leaf': 0.4448793450112914, 'max_features': 'sqrt', 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:05,747] Trial 90 finished with value: 0.7379018144975591 and parameters: {'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 0.5407642942023247, 'min_samples_leaf': 0.4235017779278081, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:06,096] Trial 91 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 25, 'min_samples_split': 0.6626674406219015, 'min_samples_leaf': 0.4092563416286205, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:06,344] Trial 92 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 26, 'min_samples_split': 0.7651115069508526, 'min_samples_leaf': 0.4292752175457903, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:06,584] Trial 93 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.7028640567669919, 'min_samples_leaf': 0.31574702885493666, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:06,834] Trial 94 finished with value: 0.7379018144975591 and parameters: {'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.6822857532383972, 'min_samples_leaf': 0.3999093029872047, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:07,084] Trial 95 finished with value: 0.7127711541645967 and parameters: {'criterion': 'log_loss', 'max_depth': 25, 'min_samples_split': 0.5677227937416306, 'min_samples_leaf': 0.359886575273487, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:07,322] Trial 96 finished with value: 0.7196712018140589 and parameters: {'criterion': 'gini', 'max_depth': 28, 'min_samples_split': 0.7434289711329509, 'min_samples_leaf': 0.3782816415476358, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:07,570] Trial 97 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 18, 'min_samples_split': 0.7201535624439546, 'min_samples_leaf': 0.4489127225348516, 'max_features': 'log2', 'normalization': 'maxabs', 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:07,822] Trial 98 finished with value: 0.0 and parameters: {'criterion': 'log_loss', 'max_depth': 19, 'min_samples_split': 0.6468063823472254, 'min_samples_leaf': 0.4921558492887234, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 15 with value: 0.7379018144975591.\n",
      "[I 2025-11-03 03:47:08,154] Trial 99 finished with value: 0.5973262032085561 and parameters: {'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.6139066883360417, 'min_samples_leaf': 0.4345639239600352, 'max_features': None, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 15 with value: 0.7379018144975591.\n"
     ]
    }
   ],
   "source": [
    "study_DecisionTree.optimize(parcial_DecisionTree, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc2e06-cc2d-4de7-aa0f-58081b6c213a",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6346a64c-bd39-4b66-9178-e284977c5f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 15\n",
      "Parâmetros do melhor trial: {'criterion': 'log_loss', 'max_depth': 19, 'min_samples_split': 0.6598195870953093, 'min_samples_leaf': 0.4239368563130451, 'max_features': None, 'normalization': None, 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "resultado_DecisionTree = study_DecisionTree.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_DecisionTree.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_DecisionTree.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01e1bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo de RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b225e9",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb4570-58f0-451d-8cf5-aa42dff162d4",
   "metadata": {},
   "source": [
    "Os parâmetros que precisamos considerar para uma floresta aleatória são muito parecidos com o de uma árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d961337-0e23-4f05-a137-58a2f9dc7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_RandomForest(trial):\n",
    "    \"\"\" Recebe um trial do optuna e retorna uma instância do modelo\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros\n",
    "    params = {\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "    \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"]),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 32),\n",
    "    \"min_samples_split\": trial.suggest_float(\"min_samples_split\", 0.01, 1.0),\n",
    "    \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
    "    \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "    \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "    \"random_state\": semente\n",
    "    }\n",
    "\n",
    "    # Passos a serem seguidos pela pipeline\n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "    \n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade\n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Adiciona tratamento RFE \n",
    "    elif treatment == \"rfe\": \n",
    "        # Definindo o estimador \n",
    "        estimator = RandomForestClassifier(**params)\n",
    "        # Definindo o número de atributos a serem mantidos\n",
    "        n_features_to_select = trial.suggest_int(\"rfe_features\", 2, 9)\n",
    "        steps.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "        \n",
    "    # Instanciando o modelo\n",
    "    modelo = RandomForestClassifier(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e0584",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "538b0e95-afe2-4853-9f99-30453bb31b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_RandomForest(trial, X_treino, Y_treino):\n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    modelo = instanciador_RandomForest(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8916f",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e4875a4-94af-40f0-8825-17f26fcac616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:47:08,757] A new study created in RDB with name: Estudo Random Forest\n"
     ]
    }
   ],
   "source": [
    "study_RandomForest = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"Estudo Random Forest\", \n",
    "    storage=f\"sqlite:///{\"Estudo RFC\"}.db\",\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584d13c",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1031e3b-6cba-47a5-8dbd-e9fac9edb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_RandomForest.enqueue_trial({\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"treatment\": None\n",
    "})\n",
    "\n",
    "# Modelo base com PCA\n",
    "study_RandomForest.enqueue_trial({\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"normalization\": \"standard\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "})\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"normalization\": \"minmax\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"normalization\": \"maxabs\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e3405",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ac05b02-cd55-41c8-9bfd-d80a4237338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_RandomForest(trial):\n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_RandomForest(trial, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a51ad",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f6152f8-8f0c-4297-9f5c-5f4143c08467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 03:47:09,610] Trial 0 finished with value: 0.7347648400279979 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'minmax', 'treatment': None}. Best is trial 0 with value: 0.7347648400279979.\n",
      "[I 2025-11-03 03:47:10,250] Trial 1 finished with value: 0.6542542542542542 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 0 with value: 0.7347648400279979.\n",
      "[I 2025-11-03 03:47:11,169] Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 275, 'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.09988573614850084, 'min_samples_leaf': 0.4963368498950579, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.7347648400279979.\n",
      "[I 2025-11-03 03:47:12,241] Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 271, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 0.7276199720424462, 'min_samples_leaf': 0.13670811351596238, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 8}. Best is trial 0 with value: 0.7347648400279979.\n",
      "[I 2025-11-03 03:47:12,897] Trial 4 finished with value: 0.6180660298307358 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 0.580469060304803, 'min_samples_leaf': 0.3717628256516985, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 4}. Best is trial 0 with value: 0.7347648400279979.\n",
      "[I 2025-11-03 03:47:13,495] Trial 5 finished with value: 0.7507191994996875 and parameters: {'n_estimators': 187, 'criterion': 'log_loss', 'max_depth': 27, 'min_samples_split': 0.3293375666554149, 'min_samples_leaf': 0.1643995358440881, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:14,497] Trial 6 finished with value: 0.2883051907442151 and parameters: {'n_estimators': 283, 'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 0.22442591736121162, 'min_samples_leaf': 0.3323684485394047, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:15,392] Trial 7 finished with value: 0.5696770662287903 and parameters: {'n_estimators': 233, 'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 0.5829467185220167, 'min_samples_leaf': 0.011209191257582104, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 6}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:15,996] Trial 8 finished with value: 0.21052631578947367 and parameters: {'n_estimators': 120, 'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 0.5762856251553077, 'min_samples_leaf': 0.29791731941273153, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:16,887] Trial 9 finished with value: 0.6558618419083536 and parameters: {'n_estimators': 281, 'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.1871716099864984, 'min_samples_leaf': 0.2020487203488021, 'max_features': None, 'bootstrap': False, 'normalization': None, 'treatment': 'pca', 'pca_components': 5}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:17,460] Trial 10 finished with value: 0.7127711541645967 and parameters: {'n_estimators': 159, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.9244064463586649, 'min_samples_leaf': 0.19351117932319056, 'max_features': None, 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:17,883] Trial 11 finished with value: 0.3938461538461538 and parameters: {'n_estimators': 55, 'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.3509687004305193, 'min_samples_leaf': 0.10265151127427949, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:18,548] Trial 12 finished with value: 0.36076604554865427 and parameters: {'n_estimators': 181, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.39337096318166664, 'min_samples_leaf': 0.11499934753555698, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:19,185] Trial 13 finished with value: 0.031746031746031744 and parameters: {'n_estimators': 170, 'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 0.0301535074881063, 'min_samples_leaf': 0.2017837230554543, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:19,653] Trial 14 finished with value: 0.6228413163897035 and parameters: {'n_estimators': 121, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.3472930746452622, 'min_samples_leaf': 0.059581328299151026, 'max_features': None, 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:20,069] Trial 15 finished with value: 0.45098901098901095 and parameters: {'n_estimators': 77, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 0.24545690279386104, 'min_samples_leaf': 0.15555404083780106, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:20,662] Trial 16 finished with value: 0.6236559139784946 and parameters: {'n_estimators': 212, 'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 0.45321018289276, 'min_samples_leaf': 0.25777706837375663, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:21,220] Trial 17 finished with value: 0.7125739184562714 and parameters: {'n_estimators': 135, 'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 0.015628806283491226, 'min_samples_leaf': 0.07006981158279968, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:21,916] Trial 18 finished with value: 0.0 and parameters: {'n_estimators': 200, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.27275349182957, 'min_samples_leaf': 0.46362324153471435, 'max_features': 'log2', 'bootstrap': True, 'normalization': None, 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:22,445] Trial 19 finished with value: 0.7471538123712037 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 0.12828736458559792, 'min_samples_leaf': 0.01224117575310002, 'max_features': None, 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:22,987] Trial 20 finished with value: 0.7127711541645967 and parameters: {'n_estimators': 150, 'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.7532788905787602, 'min_samples_leaf': 0.012910342507801242, 'max_features': None, 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:23,425] Trial 21 finished with value: 0.6970583023214602 and parameters: {'n_estimators': 94, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 0.13473080192215942, 'min_samples_leaf': 0.0859270033594856, 'max_features': None, 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:23,979] Trial 22 finished with value: 0.6771043771043771 and parameters: {'n_estimators': 191, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 0.2956289943749859, 'min_samples_leaf': 0.1614646289155835, 'max_features': None, 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:24,490] Trial 23 finished with value: 0.7009569377990431 and parameters: {'n_estimators': 145, 'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 0.15157328713717638, 'min_samples_leaf': 0.031772462887728115, 'max_features': None, 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:25,149] Trial 24 finished with value: 0.6846801346801347 and parameters: {'n_estimators': 242, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.4817364463326701, 'min_samples_leaf': 0.10154397048535674, 'max_features': None, 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:25,608] Trial 25 finished with value: 0.6945949432404541 and parameters: {'n_estimators': 116, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 0.06661307728010885, 'min_samples_leaf': 0.24006165370439375, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:25,995] Trial 26 finished with value: 0.6851851851851851 and parameters: {'n_estimators': 53, 'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 0.1827516541644604, 'min_samples_leaf': 0.064612416837728, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:26,523] Trial 27 finished with value: 0.7389325500780609 and parameters: {'n_estimators': 166, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 0.4048056396644809, 'min_samples_leaf': 0.13481470602245146, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:27,075] Trial 28 finished with value: 0.666442652329749 and parameters: {'n_estimators': 169, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 0.3895978084796123, 'min_samples_leaf': 0.24522069386284867, 'max_features': 'log2', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:27,629] Trial 29 finished with value: 0.6152037617554859 and parameters: {'n_estimators': 198, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.45068200177027323, 'min_samples_leaf': 0.16985561220457607, 'max_features': None, 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:28,242] Trial 30 finished with value: 0.6396929824561404 and parameters: {'n_estimators': 252, 'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 0.5249228477532671, 'min_samples_leaf': 0.12571525299647812, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:28,608] Trial 31 finished with value: 0.6998156050787628 and parameters: {'n_estimators': 94, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 0.2865956001179071, 'min_samples_leaf': 0.03924506537640965, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:29,181] Trial 32 finished with value: 0.7068654019873533 and parameters: {'n_estimators': 141, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 0.10833143240202253, 'min_samples_leaf': 0.048227138649554704, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:29,866] Trial 33 finished with value: 0.06060606060606061 and parameters: {'n_estimators': 182, 'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 0.07403292577739415, 'min_samples_leaf': 0.1371854896722981, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 2}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:30,218] Trial 34 finished with value: 0.2154882154882155 and parameters: {'n_estimators': 76, 'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 0.7065461132937182, 'min_samples_leaf': 0.08557835239321065, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:30,821] Trial 35 finished with value: 0.3860931899641577 and parameters: {'n_estimators': 210, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 0.21254116387742955, 'min_samples_leaf': 0.03500508313324732, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 2}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:31,346] Trial 36 finished with value: 0.626539408866995 and parameters: {'n_estimators': 156, 'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 0.3180431723707639, 'min_samples_leaf': 0.08402638808418261, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:31,774] Trial 37 finished with value: 0.24089635854341737 and parameters: {'n_estimators': 131, 'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 0.15828754747346188, 'min_samples_leaf': 0.4111962782093639, 'max_features': 'log2', 'bootstrap': False, 'normalization': None, 'treatment': 'pca', 'pca_components': 6}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:32,319] Trial 38 finished with value: 0.7285861713106295 and parameters: {'n_estimators': 218, 'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 0.38511375386202995, 'min_samples_leaf': 0.13187819675754134, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:32,741] Trial 39 finished with value: 0.6290662755779035 and parameters: {'n_estimators': 102, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.24530513853361052, 'min_samples_leaf': 0.014056037943394203, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 4}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:33,554] Trial 40 finished with value: 0.7233017320403339 and parameters: {'n_estimators': 296, 'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.5402069204678882, 'min_samples_leaf': 0.29660075808355923, 'max_features': None, 'bootstrap': True, 'normalization': None, 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:34,084] Trial 41 finished with value: 0.7161084529505581 and parameters: {'n_estimators': 224, 'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 0.4091199349276263, 'min_samples_leaf': 0.18388328732710008, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:34,559] Trial 42 finished with value: 0.37719298245614036 and parameters: {'n_estimators': 163, 'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 0.6249660393598186, 'min_samples_leaf': 0.14934359999762448, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:35,040] Trial 43 finished with value: 0.1111111111111111 and parameters: {'n_estimators': 182, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 0.9885989917262866, 'min_samples_leaf': 0.11698567733999823, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:35,684] Trial 44 finished with value: 0.7403508771929825 and parameters: {'n_estimators': 256, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 0.3469821748652828, 'min_samples_leaf': 0.10751253805762696, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:36,328] Trial 45 finished with value: 0.6835954214805305 and parameters: {'n_estimators': 263, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 0.3371921810234949, 'min_samples_leaf': 0.2230073346602893, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:36,879] Trial 46 finished with value: 0.6443713450292398 and parameters: {'n_estimators': 236, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.09841685548955952, 'min_samples_leaf': 0.10055609593285145, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:37,363] Trial 47 finished with value: 0.6164397480186955 and parameters: {'n_estimators': 106, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 0.20938637710955638, 'min_samples_leaf': 0.060831240284228705, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 7}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:37,717] Trial 48 finished with value: 0.7052028104659683 and parameters: {'n_estimators': 78, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 0.43886811891684296, 'min_samples_leaf': 0.1837766325573733, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:38,329] Trial 49 finished with value: 0.7127711541645967 and parameters: {'n_estimators': 271, 'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.6313908865485875, 'min_samples_leaf': 0.07245704463057931, 'max_features': None, 'bootstrap': False, 'normalization': 'standard', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:38,829] Trial 50 finished with value: 0.6721866096866097 and parameters: {'n_estimators': 126, 'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 0.0472074039567111, 'min_samples_leaf': 0.10611065921351939, 'max_features': 'log2', 'bootstrap': True, 'normalization': None, 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:39,358] Trial 51 finished with value: 0.7403508771929825 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 0.3619629723648274, 'min_samples_leaf': 0.13427188065147538, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:39,925] Trial 52 finished with value: 0.7285861713106295 and parameters: {'n_estimators': 253, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 0.3545071616052798, 'min_samples_leaf': 0.14081257491237123, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:40,449] Trial 53 finished with value: 0.7005696058327637 and parameters: {'n_estimators': 197, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 0.48770689802598066, 'min_samples_leaf': 0.20696086590906798, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 5 with value: 0.7507191994996875.\n",
      "[I 2025-11-03 03:47:40,959] Trial 54 finished with value: 0.7829318829318829 and parameters: {'n_estimators': 207, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 0.23323801042134965, 'min_samples_leaf': 0.027261867668382594, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:41,529] Trial 55 finished with value: 0.6255800792303339 and parameters: {'n_estimators': 243, 'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 0.25375400526887076, 'min_samples_leaf': 0.2737921682148057, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:42,299] Trial 56 finished with value: 0.7692585643805155 and parameters: {'n_estimators': 209, 'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.2999772878844068, 'min_samples_leaf': 0.02162068112761572, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:42,921] Trial 57 finished with value: 0.6565113500597372 and parameters: {'n_estimators': 225, 'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.2752941642458922, 'min_samples_leaf': 0.017257006854763918, 'max_features': None, 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:43,458] Trial 58 finished with value: 0.7566137566137566 and parameters: {'n_estimators': 209, 'criterion': 'log_loss', 'max_depth': 30, 'min_samples_split': 0.33287982740903255, 'min_samples_leaf': 0.02866734232463945, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:43,973] Trial 59 finished with value: 0.7566137566137566 and parameters: {'n_estimators': 190, 'criterion': 'log_loss', 'max_depth': 30, 'min_samples_split': 0.3061438213583891, 'min_samples_leaf': 0.0302628590159638, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:44,536] Trial 60 finished with value: 0.7817663817663818 and parameters: {'n_estimators': 207, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.30963883799407704, 'min_samples_leaf': 0.02496570178439881, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:45,114] Trial 61 finished with value: 0.7566137566137566 and parameters: {'n_estimators': 208, 'criterion': 'log_loss', 'max_depth': 30, 'min_samples_split': 0.31737172390355867, 'min_samples_leaf': 0.03092680766321081, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:45,658] Trial 62 finished with value: 0.7566137566137566 and parameters: {'n_estimators': 188, 'criterion': 'log_loss', 'max_depth': 30, 'min_samples_split': 0.31344019344307733, 'min_samples_leaf': 0.03312877100097916, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:46,219] Trial 63 finished with value: 0.6865610130755685 and parameters: {'n_estimators': 209, 'criterion': 'log_loss', 'max_depth': 30, 'min_samples_split': 0.31066871324520196, 'min_samples_leaf': 0.046802922531089516, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:46,719] Trial 64 finished with value: 0.7587223075027953 and parameters: {'n_estimators': 188, 'criterion': 'log_loss', 'max_depth': 31, 'min_samples_split': 0.22688860463555938, 'min_samples_leaf': 0.029282070242212327, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 54 with value: 0.7829318829318829.\n",
      "[I 2025-11-03 03:47:47,282] Trial 65 finished with value: 0.7856959471850358 and parameters: {'n_estimators': 205, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.17454453522681915, 'min_samples_leaf': 0.026729133704396783, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:47,885] Trial 66 finished with value: 0.768860877684407 and parameters: {'n_estimators': 201, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.19275270084917323, 'min_samples_leaf': 0.051778307374728855, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:48,413] Trial 67 finished with value: 0.7551948051948051 and parameters: {'n_estimators': 203, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.18671508574299453, 'min_samples_leaf': 0.05837140524035793, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:48,969] Trial 68 finished with value: 0.7356870771504918 and parameters: {'n_estimators': 178, 'criterion': 'log_loss', 'max_depth': 28, 'min_samples_split': 0.22931604903870517, 'min_samples_leaf': 0.07630936463999652, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:49,585] Trial 69 finished with value: 0.7626984126984127 and parameters: {'n_estimators': 233, 'criterion': 'log_loss', 'max_depth': 31, 'min_samples_split': 0.16784915461465014, 'min_samples_leaf': 0.051030719601859884, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:50,214] Trial 70 finished with value: 0.3183728192802603 and parameters: {'n_estimators': 216, 'criterion': 'log_loss', 'max_depth': 31, 'min_samples_split': 0.1627092457841621, 'min_samples_leaf': 0.058879457348604496, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 3}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:50,746] Trial 71 finished with value: 0.772810793123411 and parameters: {'n_estimators': 196, 'criterion': 'log_loss', 'max_depth': 31, 'min_samples_split': 0.19543401250242837, 'min_samples_leaf': 0.022259696550407958, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:51,373] Trial 72 finished with value: 0.7748354626403406 and parameters: {'n_estimators': 234, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.12584524575415929, 'min_samples_leaf': 0.04864632206669317, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:52,000] Trial 73 finished with value: 0.7793611793611793 and parameters: {'n_estimators': 234, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.12248548172849073, 'min_samples_leaf': 0.010329893513649716, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:52,649] Trial 74 finished with value: 0.7793611793611793 and parameters: {'n_estimators': 243, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.13130338210035608, 'min_samples_leaf': 0.015294574085609216, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:53,233] Trial 75 finished with value: 0.7793611793611793 and parameters: {'n_estimators': 243, 'criterion': 'log_loss', 'max_depth': 27, 'min_samples_split': 0.12238361502896045, 'min_samples_leaf': 0.013894284627814264, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:53,871] Trial 76 finished with value: 0.7793611793611793 and parameters: {'n_estimators': 241, 'criterion': 'log_loss', 'max_depth': 28, 'min_samples_split': 0.12340396486603646, 'min_samples_leaf': 0.010964116662786566, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:54,449] Trial 77 finished with value: 0.7553688141923436 and parameters: {'n_estimators': 242, 'criterion': 'log_loss', 'max_depth': 28, 'min_samples_split': 0.12170247616139665, 'min_samples_leaf': 0.045447296039058505, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:55,059] Trial 78 finished with value: 0.7613431613431615 and parameters: {'n_estimators': 237, 'criterion': 'log_loss', 'max_depth': 26, 'min_samples_split': 0.06974107045846012, 'min_samples_leaf': 0.012331693817646459, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:55,661] Trial 79 finished with value: 0.7503562828640228 and parameters: {'n_estimators': 248, 'criterion': 'log_loss', 'max_depth': 28, 'min_samples_split': 0.016984660163677404, 'min_samples_leaf': 0.08968986137225371, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:56,281] Trial 80 finished with value: 0.7793611793611793 and parameters: {'n_estimators': 230, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.13492758657861526, 'min_samples_leaf': 0.010563984887469893, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 65 with value: 0.7856959471850358.\n",
      "[I 2025-11-03 03:47:56,871] Trial 81 finished with value: 0.7956263956263956 and parameters: {'n_estimators': 230, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.09276869430434484, 'min_samples_leaf': 0.012484227723652482, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:47:57,442] Trial 82 finished with value: 0.7751877751877752 and parameters: {'n_estimators': 221, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.0920830579571696, 'min_samples_leaf': 0.011776951617483307, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:47:58,076] Trial 83 finished with value: 0.7520812520812522 and parameters: {'n_estimators': 262, 'criterion': 'log_loss', 'max_depth': 27, 'min_samples_split': 0.0469224297278171, 'min_samples_leaf': 0.037859857874397745, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:47:58,701] Trial 84 finished with value: 0.7694950764718206 and parameters: {'n_estimators': 262, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.1294258949018762, 'min_samples_leaf': 0.010483067669353852, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:47:59,279] Trial 85 finished with value: 0.7451096329145109 and parameters: {'n_estimators': 226, 'criterion': 'log_loss', 'max_depth': 26, 'min_samples_split': 0.08758997172492515, 'min_samples_leaf': 0.07022416389504275, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:47:59,877] Trial 86 finished with value: 0.21153846153846154 and parameters: {'n_estimators': 232, 'criterion': 'log_loss', 'max_depth': 25, 'min_samples_split': 0.145584752325433, 'min_samples_leaf': 0.3645775123786915, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:00,595] Trial 87 finished with value: 0.768327796234773 and parameters: {'n_estimators': 275, 'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.052343781555135305, 'min_samples_leaf': 0.04062688148606089, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:01,274] Trial 88 finished with value: 0.7923012659854765 and parameters: {'n_estimators': 248, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.11013094497531677, 'min_samples_leaf': 0.024340110309140465, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:02,259] Trial 89 finished with value: 0.7623827009383924 and parameters: {'n_estimators': 246, 'criterion': 'log_loss', 'max_depth': 28, 'min_samples_split': 0.08507389119183134, 'min_samples_leaf': 0.023931781230687135, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:02,889] Trial 90 finished with value: 0.7753968253968253 and parameters: {'n_estimators': 215, 'criterion': 'log_loss', 'max_depth': 25, 'min_samples_split': 0.16556376147955748, 'min_samples_leaf': 0.06413263935637281, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:03,606] Trial 91 finished with value: 0.7924908424908425 and parameters: {'n_estimators': 257, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.1058740156389275, 'min_samples_leaf': 0.037883942349140054, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:04,345] Trial 92 finished with value: 0.7924908424908425 and parameters: {'n_estimators': 285, 'criterion': 'log_loss', 'max_depth': 31, 'min_samples_split': 0.10781557054002691, 'min_samples_leaf': 0.04144586335790673, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:05,028] Trial 93 finished with value: 0.7748354626403406 and parameters: {'n_estimators': 292, 'criterion': 'log_loss', 'max_depth': 31, 'min_samples_split': 0.11046608541092917, 'min_samples_leaf': 0.04267290806837204, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:05,659] Trial 94 finished with value: 0.0 and parameters: {'n_estimators': 271, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.0318156775043638, 'min_samples_leaf': 0.49203155961938916, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:06,319] Trial 95 finished with value: 0.7496847963132037 and parameters: {'n_estimators': 284, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.15041658557454063, 'min_samples_leaf': 0.07700243434161279, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:06,953] Trial 96 finished with value: 0.7735042735042734 and parameters: {'n_estimators': 256, 'criterion': 'log_loss', 'max_depth': 31, 'min_samples_split': 0.25187233818082216, 'min_samples_leaf': 0.026529460751488564, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:07,567] Trial 97 finished with value: 0.7684862562911343 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 0.06548304758078738, 'min_samples_leaf': 0.05698935414096903, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:08,263] Trial 98 finished with value: 0.6463027487417731 and parameters: {'n_estimators': 268, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.21066471236619477, 'min_samples_leaf': 0.039942551764684635, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 81 with value: 0.7956263956263956.\n",
      "[I 2025-11-03 03:48:08,888] Trial 99 finished with value: 0.32560568086883873 and parameters: {'n_estimators': 281, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.842017586281577, 'min_samples_leaf': 0.0227278852275229, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 81 with value: 0.7956263956263956.\n"
     ]
    }
   ],
   "source": [
    "study_RandomForest.optimize(parcial_RandomForest, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cffa46-c202-487f-8abb-d2a4fbfe6b68",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fddb150a-2aa8-41a9-86a8-c9e2ba5d2664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 81\n",
      "Parâmetros do melhor trial: {'n_estimators': 230, 'criterion': 'log_loss', 'max_depth': 29, 'min_samples_split': 0.09276869430434484, 'min_samples_leaf': 0.012484227723652482, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "resultado_RandomForest = study_RandomForest.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_RandomForest.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_RandomForest.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416e230-69a2-4cd1-af9f-36f15895f0b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Teste dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d26a7",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "565f3884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       0.65      1.00      0.79        13\n",
      "      Tóxico       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.33      0.50      0.39        20\n",
      "weighted avg       0.42      0.65      0.51        20\n",
      "\n",
      "Valor de f1 = 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_baseline = DummyClassifier()\n",
    "modelo_baseline.fit(x_treino, y_treino)\n",
    "y_previsao = modelo_baseline.predict(x_teste)\n",
    "\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "f1_baseline = f1_score(y_teste, y_previsao)\n",
    "\n",
    "print(f\"Valor de f1 = {f1_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b0efd",
   "metadata": {},
   "source": [
    "## Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d62bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1,\n",
      " 'normalization': 'standard',\n",
      " 'p': 2,\n",
      " 'pca_components': 9,\n",
      " 'treatment': 'pca',\n",
      " 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_knn = resultado_knn.params.copy()\n",
    "pprint(parametros_otimizados_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1d5eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_knn = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_knn = parametros_otimizados_knn[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_knn == \"standard\": \n",
    "    steps_knn.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_knn == \"minmax\": \n",
    "    steps_knn.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_knn == \"maxabs\": \n",
    "    steps_knn.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_knn[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_knn.append(PCA(n_components=parametros_otimizados_knn[\"pca_components\"]))\n",
    "\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\"]\n",
    "for param in parametros_remover:\n",
    "    parametros_otimizados_knn.pop(param, None)\n",
    "\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_knn = KNeighborsClassifier(**parametros_otimizados_knn)\n",
    "steps_knn.append(modelo_knn)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_knn = make_pipeline(*steps_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd1e2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de f1 = [0.6        0.63636364 0.69565217 0.4        0.56      ]\n",
      "Valor médio de f1 = 0.5784031620553359\n"
     ]
    }
   ],
   "source": [
    "kf_knn = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "f1_knn = cross_val_score(\n",
    "    pipeline_knn, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"f1\", \n",
    "    cv=kf_knn\n",
    "    )\n",
    "\n",
    "media_f1_knn = f1_knn.mean()\n",
    "\n",
    "print(f\"Valores de f1 = {f1_knn}\")\n",
    "print(f\"Valor médio de f1 = {media_f1_knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8b984df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       0.93      1.00      0.96        13\n",
      "      Tóxico       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.93      0.94        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_knn.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_knn.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd45b7",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6cda8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 411.1995837998602,\n",
      " 'coef0': 0.8383305210950958,\n",
      " 'degree': 4,\n",
      " 'gamma': 'auto',\n",
      " 'kernel': 'poly',\n",
      " 'normalization': 'minmax',\n",
      " 'pca_components': 6,\n",
      " 'treatment': 'pca'}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_svc = resultado_svc.params.copy()\n",
    "pprint(parametros_otimizados_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16e8b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_svc = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_svc = parametros_otimizados_svc[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_svc == \"standard\": \n",
    "    steps_svc.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_svc == \"minmax\": \n",
    "    steps_svc.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_svc == \"maxabs\": \n",
    "    steps_svc.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_svc[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_svc.append(PCA(n_components=parametros_otimizados_svc[\"pca_components\"]))\n",
    "\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\"]\n",
    "for param in parametros_remover:\n",
    "    parametros_otimizados_svc.pop(param, None)\n",
    "\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_svc = SVC(**parametros_otimizados_svc)\n",
    "steps_svc.append(modelo_svc)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_svc = make_pipeline(*steps_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34857eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de f1 = [0.6        0.83333333 0.8        0.76923077 0.76923077]\n",
      "Valor médio de f1 = 0.7543589743589744\n"
     ]
    }
   ],
   "source": [
    "kf_svc = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "f1_svc = cross_val_score(\n",
    "    pipeline_svc, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"f1\", \n",
    "    cv=kf_svc\n",
    "    )\n",
    "\n",
    "media_f1_svc = f1_svc.mean()\n",
    "\n",
    "print(f\"Valores de f1 = {f1_svc}\")\n",
    "print(f\"Valor médio de f1 = {media_f1_svc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "906d81da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       0.87      1.00      0.93        13\n",
      "      Tóxico       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.93      0.86      0.88        20\n",
      "weighted avg       0.91      0.90      0.90        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_svc.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_svc.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b26639b",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d1c0ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1932645746859868,\n",
      " 'class_weight': 'balanced',\n",
      " 'max_iter': 5000,\n",
      " 'normalization': 'standard',\n",
      " 'penalty': 'l2',\n",
      " 'random_state': 3931421,\n",
      " 'rfe_features': 5,\n",
      " 'solver': 'liblinear',\n",
      " 'treatment': 'rfe'}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_lrc = resultado_lrc.params.copy()\n",
    "parametros_otimizados_lrc[\"solver\"] =\"liblinear\"\n",
    "parametros_otimizados_lrc[\"max_iter\"] = 5000\n",
    "parametros_otimizados_lrc[\"random_state\"] = semente\n",
    "\n",
    "pprint(parametros_otimizados_lrc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afb31332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_lrc = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_lrc = parametros_otimizados_lrc[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_lrc == \"standard\": \n",
    "    steps_lrc.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_lrc == \"minmax\": \n",
    "    steps_lrc.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_lrc == \"maxabs\": \n",
    "    steps_lrc.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_lrc[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_lrc.append(PCA(n_components=parametros_otimizados_lrc[\"pca_components\"]))\n",
    "\n",
    "# Adiciona tratamento RFE \n",
    "elif treatment == \"rfe\": \n",
    "\n",
    "    # Definindo o número de atributos a serem mantidos\n",
    "    n_features_to_select = parametros_otimizados_lrc[\"rfe_features\"]\n",
    "\n",
    "    # Tratamento da lista de parametros\n",
    "    parametros_remover = [\"normalization\", \"treatment\", \"pca_components\", \"rfe_features\"]\n",
    "    for param in parametros_remover:\n",
    "        parametros_otimizados_lrc.pop(param, None)\n",
    "\n",
    "    # Definindo o estimador \n",
    "    estimator = LogisticRegression(**parametros_otimizados_lrc)\n",
    "    \n",
    "    steps_lrc.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\", \"rfe_features\"]\n",
    "for param in parametros_remover:\n",
    "    parametros_otimizados_lrc.pop(param, None)\n",
    "\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_lrc = LogisticRegression(**parametros_otimizados_lrc)\n",
    "steps_lrc.append(modelo_lrc)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_lrc = make_pipeline(*steps_lrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "036160ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de f1 = [0.69565217 0.72727273 0.85714286 0.74074074 0.75      ]\n",
      "Valor médio de f1 = 0.7541616998138737\n"
     ]
    }
   ],
   "source": [
    "kf_lrc = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "f1_lrc = cross_val_score(\n",
    "    pipeline_lrc, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"f1\", \n",
    "    cv=kf_lrc\n",
    "    )\n",
    "\n",
    "media_f1_lrc = f1_lrc.mean()\n",
    "\n",
    "print(f\"Valores de f1 = {f1_lrc}\")\n",
    "print(f\"Valor médio de f1 = {media_f1_lrc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44d028c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       1.00      0.92      0.96        13\n",
      "      Tóxico       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.94      0.96      0.95        20\n",
      "weighted avg       0.96      0.95      0.95        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_lrc.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_lrc.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6838c",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1c270dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'log_loss',\n",
      " 'max_depth': 19,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 0.4239368563130451,\n",
      " 'min_samples_split': 0.6598195870953093,\n",
      " 'normalization': None,\n",
      " 'random_state': 3931421,\n",
      " 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_dtc = resultado_DecisionTree.params.copy()\n",
    "parametros_otimizados_dtc[\"random_state\"] = semente\n",
    "\n",
    "pprint(parametros_otimizados_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8169b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_dtc = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_dtc = parametros_otimizados_dtc[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_dtc == \"standard\": \n",
    "    steps_dtc.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_dtc == \"minmax\": \n",
    "    steps_dtc.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_dtc == \"maxabs\": \n",
    "    steps_dtc.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_dtc[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_dtc.append(PCA(n_components=parametros_otimizados_dtc[\"pca_components\"]))\n",
    "\n",
    "# Adiciona tratamento RFE \n",
    "elif treatment == \"rfe\": \n",
    "\n",
    "    # Definindo o número de atributos a serem mantidos\n",
    "    n_features_to_select = parametros_otimizados_lrc[\"rfe_features\"]\n",
    "\n",
    "    # Tratamento da lista de parametros\n",
    "    parametros_remover = [\"normalization\", \"treatment\", \"pca_components\", \"rfe_features\"]\n",
    "    for param in parametros_remover:\n",
    "        parametros_otimizados_lrc.pop(param, None)\n",
    "\n",
    "    # Definindo o estimador \n",
    "    estimator = DecisionTreeClassifier(**parametros_otimizados_dtc)\n",
    "    \n",
    "    steps_lrc.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\"]\n",
    "for param in parametros_remover:\n",
    "    parametros_otimizados_dtc.pop(param, None)\n",
    "\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_dtc = DecisionTreeClassifier(**parametros_otimizados_dtc)\n",
    "steps_dtc.append(modelo_dtc)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_dtc = make_pipeline(*steps_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "927860c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de f1 = [0.81481481 0.73333333 0.76470588 0.66666667 0.70967742]\n",
      "Valor médio de f1 = 0.7378396233045189\n"
     ]
    }
   ],
   "source": [
    "kf_dtc = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "f1_dtc = cross_val_score(\n",
    "    pipeline_dtc, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"f1\", \n",
    "    cv=kf_dtc\n",
    "    )\n",
    "\n",
    "media_f1_dtc = f1_dtc.mean()\n",
    "\n",
    "print(f\"Valores de f1 = {f1_dtc}\")\n",
    "print(f\"Valor médio de f1 = {media_f1_dtc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "654704f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       1.00      0.77      0.87        13\n",
      "      Tóxico       0.70      1.00      0.82         7\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.85      0.88      0.85        20\n",
      "weighted avg       0.89      0.85      0.85        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_dtc.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_dtc.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8db49",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a198e8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'log_loss',\n",
      " 'max_depth': 19,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 0.4239368563130451,\n",
      " 'min_samples_split': 0.6598195870953093,\n",
      " 'normalization': None,\n",
      " 'random_state': 3931421,\n",
      " 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_rfc = resultado_DecisionTree.params.copy()\n",
    "parametros_otimizados_rfc[\"random_state\"] = semente\n",
    "\n",
    "pprint(parametros_otimizados_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21d72111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_rfc = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_rfc = parametros_otimizados_rfc[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_rfc == \"standard\": \n",
    "    steps_rfc.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_rfc == \"minmax\": \n",
    "    steps_rfc.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_rfc == \"maxabs\": \n",
    "    steps_rfc.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_rfc[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_rfc.append(PCA(n_components=parametros_otimizados_rfc[\"pca_components\"]))\n",
    "\n",
    "# Adiciona tratamento RFE \n",
    "elif treatment == \"rfe\": \n",
    "\n",
    "    # Definindo o número de atributos a serem mantidos\n",
    "    n_features_to_select = parametros_otimizados_lrc[\"rfe_features\"]\n",
    "\n",
    "    # Tratamento da lista de parametros\n",
    "    parametros_remover = [\"normalization\", \"treatment\", \"pca_components\", \"rfe_features\"]\n",
    "    for param in parametros_remover:\n",
    "        parametros_otimizados_lrc.pop(param, None)\n",
    "\n",
    "    # Definindo o estimador \n",
    "    estimator = RandomForestClassifier(**parametros_otimizados_rfc)\n",
    "    \n",
    "    steps_lrc.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\"]\n",
    "for param in parametros_remover:\n",
    "    parametros_otimizados_rfc.pop(param, None)\n",
    "\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_rfc = RandomForestClassifier(**parametros_otimizados_rfc)\n",
    "steps_rfc.append(modelo_rfc)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_rfc = make_pipeline(*steps_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bff70d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de f1 = [0. 0. 0. 0. 0.]\n",
      "Valor médio de f1 = 0.0\n"
     ]
    }
   ],
   "source": [
    "kf_rfc = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "f1_rfc = cross_val_score(\n",
    "    pipeline_rfc, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"f1\", \n",
    "    cv=kf_rfc\n",
    "    )\n",
    "\n",
    "media_f1_rfc = f1_rfc.mean()\n",
    "\n",
    "print(f\"Valores de f1 = {f1_rfc}\")\n",
    "print(f\"Valor médio de f1 = {media_f1_rfc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7efac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       0.65      1.00      0.79        13\n",
      "      Tóxico       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.33      0.50      0.39        20\n",
      "weighted avg       0.42      0.65      0.51        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_rfc.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_rfc.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a2a10-e951-4514-abfe-0f183729fea4",
   "metadata": {},
   "source": [
    "# Resultados e Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82707f99-8633-4b32-bdb5-0bdaf8fc946c",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952381c-4759-4dc4-90be-758fd40cc3c6",
   "metadata": {},
   "source": [
    "- Documentação DecisionTree:https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "- Documentação RandomForest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
