{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f9aebc-eca6-42e9-8647-f8d7ef3dc991",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <H1>Aprendizado de Máquina - Trabalho Final</H1>\n",
    "    <H3>Prof.º Daniel Roberto Cassar</H3> \n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"right\">\n",
    "    <H3>Guilda: Carcajus</H3>\n",
    "    <H4>Aniel Souza Ribeiro Neto</H4>\n",
    "    <H4>Caio Cogo Beriam</H4>\n",
    "    <H4>Joaquim Junior Ferola Fonseca</H4>\n",
    "</div>\n",
    "\n",
    "<br> \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"Imagens/carcajus_bg.png\" width=\"500\"/>\n",
    "    <figcaption><H3><I>\"Mastigar primeiro, digerir depois!\"</I></H3></figcaption>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0ebc27-9179-4a65-8b7f-329e2578963e",
   "metadata": {},
   "source": [
    "# Lore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2e820-7957-4ec0-981c-45941fb11ba0",
   "metadata": {},
   "source": [
    "    \"    Você não ouviria o barulho das engrenagens se não tivessem te contado sobre elas. Você nunca saberia que elas estão rodando, centenas de metros sob seus pés, talvez até quilômetros. Mas elas estão ali, engrenadas e ativas como sempre. Elas são o trunfo do Continente, a ferramenta secreta de todo o povo para responder a Pergunta Final. E mesmo que não possamos ouvi-las com nossa audição, sentimos seu ritmo em nossos corações, pulsando junto conosco.   \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bd158-3de9-45f7-8643-b18a9a8e8643",
   "metadata": {},
   "source": [
    "Os viajantes costumam dizer que o reino de Lumi é pequeno, mas ajeitadinho. É de fato inspirador andar pelos cenários característicos, como as praças, jardins e tavernas, e ver seus simpáticos habitantes recitando encantamentos, feitiços, magias e maldições.\n",
    "\n",
    "O reino também é movido por um grande número de heróis *freelancers*, que recebem quests dos ilustres moradores já bem renomados. Alguns deles se unem em guildas, outros trabalham sozinhos; alguns cumprem missões com maestria, enquanto outros mal saem vivos.\n",
    "\n",
    "Não posso dizer em qual desses grupos os Carcajus se encaixam. A verdade, é que estes são três paranóicos aventureiros que ambicionam moedas, pergaminhos, caixinhas de suco e outras coisinhas, para que depois possam gastar tudo em comida e bebida. Esse habitozinho ignóbil rendeu aos três o apelido de \"glutões\", que eles acolheram com orgulho e de bom-grado.\n",
    "\n",
    "Entretanto, por sugestão de Edna Ensineide, notável conselheira real, os Glutões buscaram um novo nome em algum sinônimo mais respeitável. Assim, ao consultarem a Grande Enciclopédia dos Insultos e Injúrias na Biblioteca Real, verificaram que um dos nomes para um glutão é **Carcaju**, um pequeno e feroz animal que rivaliza com lobos e ursos pelo seu apetite insaciável.\n",
    "\n",
    "Unidos, os Carcajus trabalham sob o lema **\"Mastigar primeiro, digerir depois\"**, que representa a voracidade do grupo de devorar grandes coisas em pequenas mordidas, e confiar piamente na própria capacidade de digestão para cumprir a tarefa.\n",
    "\n",
    "O que eles não esperavam, é que nessa visita à biblioteca eles seriam atraídos para o temido **Pythonomicron**, um compêndio de maldições e informações proibidas do lado mais obscuro da magia. E ali, em uma página secreta, de baixo de um post-it de um estudante dedicado, encontraram rabiscada a lenda do Horripilante Processador Central, um mecanismo milenar que continha poder inimaginável, guardado por um dos mais poderosos magos do continente.\n",
    "\n",
    "Agora, a quest de Milu Iluminarius MLVI era a pista que mais aproximava os Carcajus desse tesouro ancião. Mas para isso, eles teriam que conquistar a simpatia do rei e colecionar suas Coroas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8efdb-3dc4-4b7f-9e7b-738936725685",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introdução\n",
    "\n",
    "A área de nanotoxicologia, que estuda como nanomateriais interagem com sistemas biológicos, tem se tornado cada vez mais importante com os avanços da nanotecnologia, permitindo que esses materiais sejam implementados de maneira segura ao meio ambiente e aos possíveis seres vivos que venham a entrar em contato com esses nanomateriais. Entretanto, como outras características dos nanomateriais, sua toxicidade pode variar muito conforme a morfologia do composto, assim, para ser analisada corretamente uma série de fatores devem ser levados em consideração, o que torna difícil a previsão da toxicidade dos materiais. \n",
    "\n",
    "Sob essa perspectiva, nosso trabalho tem o objetivo de facilitar esse tarefa através do treinamento de um modelo de Aprendizado de Máquina Supervisionado capaz de prever se uma nanopartícula é tóxica com base em características da sua morfologia. Para isso, utilizaremos como fundamento um conjunto de dados contendo as características de diversas nanoparticulas e se elas são ou não tóxicas. O dataset foi elaborado pelo trabalho Subramanian NA, Palaniappan A. NanoTox: Development of a Parsimonious In Silico Model for Toxicity Assessment of Metal-Oxide Nanoparticles Using Physicochemical Features. ACS Omega 2021, 6, 17, 11729–11739 doi:10.1021/acsomega.1c01076, e o obtivemos pela plataforma Kaggle através do endereço https://www.kaggle.com/datasets/apalania/toxicityassessment-meoxnp.\n",
    "\n",
    "Para fins de organização e didática, este trabalho será dividido nas seguintes etapas:\n",
    "1. Preparo dos dados: Nessa seção será feita a obtenção e tratamento dos dados, permitindo que eles sejam posteriormente utilizados sem problemas, além disso, será feita também a divisão dos dados de treino e de teste dos modelos;\n",
    "2. Estudo dos modelos: Nessa etapa faremos o estudo de 5 modelos através do módulo optuna para optimzação de hiperparâmetros e estratégias de normalização de dados e tratamento de atributos, buscando o melhor pipeline encontrado pelo optuna para cada modelo;\n",
    "3. Teste dos modelos: Após definirmos os melhores pipelines encontrados pelo optuna, iremos instânciar, treinar e comparar os 5 pipelines em busca do de melhor desempenho, que, por fim, utilizaremos para prever os dados de teste;\n",
    "4. Resultados e conclusão: Enfim, discutiremos os resultados obtidos pelo trabalho e apresentaremos sua conclusão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30654516",
   "metadata": {},
   "source": [
    "# Módulos utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74068e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Modelos de Aprendizado Supervisionado\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Tratamento\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Normalização\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "\n",
    "# Separação de dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Validação Cruzada\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from optuna import create_study\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb81756-c4e9-4bdc-8baa-f5dffb85e498",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preparo dos dados\n",
    "\n",
    "Nesta seção será realizado o tratamento dos dados, preparando-os para serem usados para treino e subsequente avaliação dos modelos que serão estudados. O processo de tratamento de dados é fundamental para a prática de ciência de dados e aprendizado de máquina, dados bem tratados podem impulsionar fortemente o desempenho de modelos e evitar problemas nos seus treinos, além disso, boas práticas ao lidar com dados permitem evitar o vazamento de dados e facilitam o trabalho. \n",
    "\n",
    "Sobre essa perspectiva, nesta seção será feita a importação dos dados do dataset através do módulo pandas, o tratamento dos dados, removendo dados que sem informação e codificando dados categóricos para que os modelos possam os interpretar, e por fim a divisão dos dados para treino e teste dos modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8cd0f",
   "metadata": {},
   "source": [
    "## Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ee246e-268d-42bc-90a4-d17064d2d62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPs</th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Hsf</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Ev</th>\n",
       "      <th>MeO</th>\n",
       "      <th>Cellline</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio</th>\n",
       "      <th>e</th>\n",
       "      <th>esum</th>\n",
       "      <th>esumbyo</th>\n",
       "      <th>MW</th>\n",
       "      <th>NMetal</th>\n",
       "      <th>NOxygen</th>\n",
       "      <th>ox</th>\n",
       "      <th>viability</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>...</td>\n",
       "      <td>5.556</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.073</td>\n",
       "      <td>101.96</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>92.5258</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>...</td>\n",
       "      <td>5.556</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.073</td>\n",
       "      <td>101.96</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>96.1340</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>...</td>\n",
       "      <td>5.556</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.073</td>\n",
       "      <td>101.96</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>93.5567</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>...</td>\n",
       "      <td>5.556</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.073</td>\n",
       "      <td>101.96</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>97.6804</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>...</td>\n",
       "      <td>5.556</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.073</td>\n",
       "      <td>101.96</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>94.8454</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NPs  coresize  hydrosize  surfcharge  surfarea     Hsf    Ec    Ev   MeO  \\\n",
       "0  Al2O3      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "1  Al2O3      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "2  Al2O3      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "3  Al2O3      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "4  Al2O3      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "\n",
       "  Cellline  ...  ratio     e  esum  esumbyo      MW  NMetal  NOxygen  ox  \\\n",
       "0    HCMEC  ...  5.556  1.61  3.22    1.073  101.96       2        3   3   \n",
       "1    HCMEC  ...  5.556  1.61  3.22    1.073  101.96       2        3   3   \n",
       "2    HCMEC  ...  5.556  1.61  3.22    1.073  101.96       2        3   3   \n",
       "3    HCMEC  ...  5.556  1.61  3.22    1.073  101.96       2        3   3   \n",
       "4    HCMEC  ...  5.556  1.61  3.22    1.073  101.96       2        3   3   \n",
       "\n",
       "   viability     class  \n",
       "0    92.5258  nonToxic  \n",
       "1    96.1340  nonToxic  \n",
       "2    93.5567  nonToxic  \n",
       "3    97.6804  nonToxic  \n",
       "4    94.8454  nonToxic  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"nanotox_dataset.tsv\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82528fdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tratamento dos dados\n",
    "\n",
    "O tratamento de dados deste trabalho consisitirá no seguinte processo: Remoção de dados faltantes, comuns em diversos datasets não tratados e que atrapalham o treino dos modelos; Remoção de linhas duplicadas, que, apesar de não impedirem o funcionamento do modelo, trazem uma redundância nos dados, influênciando a percepção do modelo sobre os dados; Codificação one-hot dos atributos categóricos, permitindo que os modelos interpretem esses dados; Remoção de colunas sem variância, uma vez que colunas sem variância não trazem qualquer informação ao modelo, não há padrões a serem inferidos em algo que não varia; Tranformação do target para forma numérica, permitindo o seu uso sem problemas de alguns modelos e estatíticas de teste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a732cb-78ba-41af-b4dd-f70c74052463",
   "metadata": {},
   "source": [
    "### $\\bullet$ Removendo linhas com dados faltantes ou duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa0f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com valores NaN\n",
    "df = df.dropna()\n",
    "# Removendo linhas duplicadas\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4235b44-75ca-4f9c-b287-c5ac0fefac64",
   "metadata": {},
   "source": [
    "### $\\bullet$ Tranformando atributos categóricos em numéricos através da codificação one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd4f65-84fe-4049-96e2-832b91cc2245",
   "metadata": {},
   "source": [
    "* Identificando as colunas categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc844d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NPs', 'Cellline', 'Celltype', 'class']\n"
     ]
    }
   ],
   "source": [
    "# Encontrando as colunas categóricas do dataset\n",
    "colunas_categoricas = list(df.columns[df.dtypes == 'object'])\n",
    "print(colunas_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800a5c2-1dc1-4bde-a673-4fb81036a223",
   "metadata": {},
   "source": [
    "* Aplicando a codificação one-hot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d15755e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Hsf</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Ev</th>\n",
       "      <th>MeO</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>...</th>\n",
       "      <th>Cellline_ChangLiv</th>\n",
       "      <th>Cellline_HCMEC</th>\n",
       "      <th>Cellline_HONDC</th>\n",
       "      <th>Cellline_L02</th>\n",
       "      <th>Cellline_MCF10A</th>\n",
       "      <th>Cellline_SHSY5Y</th>\n",
       "      <th>Cellline_SW480</th>\n",
       "      <th>Cellline_WI38</th>\n",
       "      <th>Celltype_Cancer</th>\n",
       "      <th>Celltype_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   coresize  hydrosize  surfcharge  surfarea     Hsf    Ec    Ev   MeO  \\\n",
       "0      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "1      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "2      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "3      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "4      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "\n",
       "   Expotime  dosage  ...  Cellline_ChangLiv  Cellline_HCMEC  Cellline_HONDC  \\\n",
       "0        24   0.001  ...                  0               1               0   \n",
       "1        24   0.010  ...                  0               1               0   \n",
       "2        24   0.100  ...                  0               1               0   \n",
       "3        24   1.000  ...                  0               1               0   \n",
       "4        24   5.000  ...                  0               1               0   \n",
       "\n",
       "   Cellline_L02  Cellline_MCF10A  Cellline_SHSY5Y  Cellline_SW480  \\\n",
       "0             0                0                0               0   \n",
       "1             0                0                0               0   \n",
       "2             0                0                0               0   \n",
       "3             0                0                0               0   \n",
       "4             0                0                0               0   \n",
       "\n",
       "   Cellline_WI38  Celltype_Cancer  Celltype_Normal  \n",
       "0              0                0                1  \n",
       "1              0                0                1  \n",
       "2              0                0                1  \n",
       "3              0                0                1  \n",
       "4              0                0                1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando o one-hot encoding nas colunas categóricas\n",
    "df = pd.get_dummies(df,\n",
    "                    columns=colunas_categoricas[:-1],\n",
    "                    dtype=\"int\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fa3ba-8329-4a33-ad75-562a6802d492",
   "metadata": {},
   "source": [
    "### $\\bullet$ Removendo colunas com variância 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f33fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Hsf</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Ev</th>\n",
       "      <th>MeO</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>...</th>\n",
       "      <th>Cellline_ChangLiv</th>\n",
       "      <th>Cellline_HCMEC</th>\n",
       "      <th>Cellline_HONDC</th>\n",
       "      <th>Cellline_L02</th>\n",
       "      <th>Cellline_MCF10A</th>\n",
       "      <th>Cellline_SHSY5Y</th>\n",
       "      <th>Cellline_SW480</th>\n",
       "      <th>Cellline_WI38</th>\n",
       "      <th>Celltype_Cancer</th>\n",
       "      <th>Celltype_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   coresize  hydrosize  surfcharge  surfarea     Hsf    Ec    Ev   MeO  \\\n",
       "0      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "1      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "2      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "3      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "4      39.7      267.0        36.3      64.7 -17.345 -1.51 -9.81  5.67   \n",
       "\n",
       "   Expotime  dosage  ...  Cellline_ChangLiv  Cellline_HCMEC  Cellline_HONDC  \\\n",
       "0        24   0.001  ...                  0               1               0   \n",
       "1        24   0.010  ...                  0               1               0   \n",
       "2        24   0.100  ...                  0               1               0   \n",
       "3        24   1.000  ...                  0               1               0   \n",
       "4        24   5.000  ...                  0               1               0   \n",
       "\n",
       "   Cellline_L02  Cellline_MCF10A  Cellline_SHSY5Y  Cellline_SW480  \\\n",
       "0             0                0                0               0   \n",
       "1             0                0                0               0   \n",
       "2             0                0                0               0   \n",
       "3             0                0                0               0   \n",
       "4             0                0                0               0   \n",
       "\n",
       "   Cellline_WI38  Celltype_Cancer  Celltype_Normal  \n",
       "0              0                0                1  \n",
       "1              0                0                1  \n",
       "2              0                0                1  \n",
       "3              0                0                1  \n",
       "4              0                0                1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instânciando o VarianceThreshold \n",
    "threshold = VarianceThreshold(threshold=0.0)\n",
    "# Ajustando o modelo e transformando os dados\n",
    "threshold.fit_transform(df.loc[:, df.dtypes != 'object'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89786f5e-959a-4779-adb5-64dd3b584f38",
   "metadata": {},
   "source": [
    "### $\\bullet$ Tranformando o target para a forma numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "098a6a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "478    0\n",
       "479    0\n",
       "480    1\n",
       "481    0\n",
       "482    0\n",
       "Name: class, Length: 477, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"] = df[\"class\"].map({'nonToxic': 0, 'Toxic': 1})\n",
    "\n",
    "df[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f467fa64",
   "metadata": {},
   "source": [
    "## Separando os dados para treino e teste\n",
    "\n",
    "A separação de dados em treino e teste é uma forma de avaliar o desempenho dos modelos sem serem necessárias novas observações. Ela consiste em omitir um fração dos dados no treino do modelo, utilizando apenas o restante dos dados para treino do modelo. Os dados de teste devem sempre ser utilizados somente quando todo o processo de treino e otimização dos modelos tiver sido concluído e o modelo final ter sido escolhido, para evitar o vazamento de dados do conjunto de teste, o que traria um enviesamento do modelo e faria com que o teste não fosse uma boa estimativa do desempenho do modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e29e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a semente aleatória\n",
    "semente = 3931421\n",
    "\n",
    "# Definindo a lista de atributos\n",
    "atributos = df.drop(columns=[\"class\"])\n",
    "# Definindo o target\n",
    "target = df[\"class\"]\n",
    "\n",
    "# Realizando a separação dos dados \n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "    atributos,\n",
    "    target,\n",
    "    test_size=0.1,\n",
    "    random_state=semente,\n",
    "    stratify=df[\"class\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a08aae-e31f-45d5-8726-c054271b50e5",
   "metadata": {},
   "source": [
    "# Estudos dos modelos \n",
    "\n",
    "Nessa etapa será utilizada o módulo optuna para optimização de hiperparâmetros e escolha de estratégias de normalização dos dados para 5 modelos: Um KNN, uma SVM, uma Regressão Logística, uma DecisionTree e uma RandomForest, todos de classificação e da biblioteca scikit-learn. Para cada modelo mencionado, o processo realizado seguirá o seguinte fluxo: \n",
    "1. Criar a função para instanciar os modelos: A função que possui os critérios que o optuna testará, retornando o modelo com os parâmetros definidos pelo optuna.\n",
    "2. Criar a função que será otimizada pelo optuna: A função que computará a métrica a ser minimizada ou maximizada pelo optuna.\n",
    "3. Criar um estudo do optuna: Arquivo onde serão salvos os testes e resultados do optuna.\n",
    "4. Indicar testes desejados: Indicar testes com valores específicos que desejamos que o optuna teste.\n",
    "5. Criar a função objetivo parcial: Função que retorna a função a ser otimizada, necessária para o optuna.\n",
    "6. Rodar o optuna e otimizar os parâmetros.\n",
    "\n",
    "Vamos entender um pouco mais a fundo cada uma das etapas, lembrando que serão realizadas para cada um dos modelos: \n",
    "1. A primeira etapa é a criação de uma função que possui em seu corpo opções de escolha que serão testadas pelo optuna. Neste trabalho, cada um dos modelos terá uma função que testa diferentes valores para seus hiperparâmetros, que sejam relevantes, que serão salvos em um dicionário para serem utilizados para instanciar os modelos posteriormente. Depois, o optuna poderá escolher entre normalizar ou não dados, seguindo as normalizações padrão, por mínimos e máximos ou máximo absoluto, e também poderá escolher entre aplicar ou não estratégias de redução de dimensionalidade ou seleção de atributos, adicionando as estratégias escolhidas a uma lista de passos para a criação de um pipeline. Por fim, será instânciado um modelo com os parâmetros definidos e criaremos um pipeline com os passos de tratamento de dados, caso escolhidos pelo optuna, e o modelo instanciado, que será retornado pela função.\n",
    "\n",
    "2. Aqui será criada uma função que chama a função para instanciar o modelo e testa o modelo criado através de uma validação cruzada seguindo uma estratégia de kfold estratificado com 3 folds e métrica f1-score. A função retorna o desempenho médio do modelo.\n",
    "\n",
    "3. Criaremos nessa etapa o estudo do optuna, que gera um arquivo contendo os dados obtidos pela otimização que será feita posterioremente, caso já haja um arquivo do estudo ele será lido ao invés de outro ser criado. Nesse ponto, caso deseje utilizar os resultados já obtidos basta baixar os estudos apresentados no repositório deste trabalho no github. O estudo irá buscar maximizar o valor recebido pela função objetivo ao longo das iterações.\n",
    "\n",
    "4. Agora indicaremos alguns casos particulares que desejamos analisar. Vamos indicar que o optuna teste ao menos uma vez cada caso de normalização e tratamento de dados com os parâmetros base do sklearn.\n",
    "\n",
    "5. O optuna requer que a função objetivo seja chamada por uma outra função, portanto, criamos uma função que retorna a função objetivo com o trial do optuna.\n",
    "\n",
    "6. Por fim, faremos otimização de parâmetros pelo optuna. Note que a linha que faz essa etapa está na forma de comentário por padrão pois considera que os estudos disponibilizados no repositório tenham sido baixados, caso tenha optado por não baixar os estudos ou tenha interesse em fazer mais estudos, basta remover a hashtag `#` no início da linha para realizar a otimização."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f8394-0631-40e8-a827-425f5c8e176b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo K-NearestNeighbors Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61377cc-6cdc-4997-a2a1-a048d7c02436",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce140ba-fbe2-4c40-828a-22e0e16ebc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_knn(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador KNN\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "        \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 1, 200, log=True),\n",
    "        \"p\": trial.suggest_int(\"p\", 1, 2),\n",
    "        \"weights\": trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"])\n",
    "    }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 38)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Instânciando o modelo\n",
    "    modelo = KNeighborsClassifier(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d9cd3-a225-43dc-afa2-dc4a268575f0",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4036370-d81a-4983-8ba1-ee3c95921f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_knn(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_knn(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72178c-5da7-4e00-922a-685eaa9fd71b",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um Estudo do Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b95bf20-cdf8-4a67-b7f2-054fcca33b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[I 2025-11-01 15:29:42,277] Using an existing study with name 'Estudo KNN' instead of creating a new one.\n"
=======
      "[I 2025-11-01 22:02:51,625] Using an existing study with name 'Estudo KNN' instead of creating a new one.\n"
>>>>>>> cef9044831e90c9d5968087939d7084443eb87b7
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_knn = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo KNN\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo KNN\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0addb63-3f19-44fa-a97d-ba27e6510d13",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab3c6a8-f33b-4c41-bd6f-3e261ac48f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": None,\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão \n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos \n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"minmax\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto\n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"maxabs\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"pca\",\n",
    "        \"pca_components\": 38\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf8ea14-ee87-4413-8b70-b18842816927",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250d982e-dab1-4547-8fa6-3ce7178ab949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_knn(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_knn(trial, x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de1364a-c029-44ff-babb-a0a7d49508c6",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d65d70-eb86-44ca-b904-759cf10294b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# study_knn.optimize(parcial_knn, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07227716-336a-4a31-8476-4068c93b40c1",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "205f7562-1bfe-41dc-9b3c-ba714bf8f2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 61\n",
      "Parâmetros do melhor trial: {'n_neighbors': 1, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 14}\n"
     ]
    }
   ],
   "source": [
    "resultado_knn = study_knn.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_knn.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_knn.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b97c8-4b17-479e-95c4-d7668def0dae",
   "metadata": {},
   "source": [
    "## Otimizando um modelo Support Vector Machine Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d9f4b-c9fb-42cc-b928-25f84d57ce5c",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7750a047-ffdb-4071-a382-db842e5c4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_svc(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador SVC\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),  \n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "            \"gamma\": trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]),\n",
    "            \"degree\": trial.suggest_int(\"degree\", 1, 5), \n",
    "            \"coef0\": trial.suggest_float(\"coef0\", 0.0, 1.0), \n",
    "        }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 38)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Instânciando o modelo\n",
    "    modelo = SVC(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db3cd2-dd5b-4d04-b8b4-af0db33116c5",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8490e3c2-09ee-4a2a-8d1a-5e7cac1e26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_svc(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_svc(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afaf93a-ea28-4931-a801-371cc3bd8a94",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ef6ca8-c394-4a91-9d04-fbe5a0315041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[I 2025-11-01 15:29:42,803] Using an existing study with name 'Estudo SVC' instead of creating a new one.\n"
=======
      "[I 2025-11-01 22:02:52,092] Using an existing study with name 'Estudo SVC' instead of creating a new one.\n"
>>>>>>> cef9044831e90c9d5968087939d7084443eb87b7
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_svc = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo SVC\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo SVC\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1fe31-375a-4a90-a15e-b98aa037954d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4fedd73-9c4b-4551-87ac-48452889cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": None,\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos \n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"minmax\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"maxabs\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"pca\",\n",
    "        \"pca_components\": 38\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d0aa5-9182-48ce-b33d-08f1f96d008d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd4c3cf-9799-4ea6-8a95-e4855f2f289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_svc(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_svc(trial, x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53449ffd-1c08-447d-8926-66c2b93e3b06",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4a66071-3bc0-4c6d-882f-53d003097313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# study_svc.optimize(parcial_svc, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77defc-89f8-4790-9e30-93c7d27c01e3",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3849ad86-53d0-44d5-8a09-4b8e2645dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 28\n",
      "Parâmetros do melhor trial: {'C': 8.069114099798579, 'kernel': 'linear', 'gamma': 'auto', 'degree': 1, 'coef0': 0.7363079808351389, 'normalization': 'minmax', 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "resultado_svc = study_svc.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_svc.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_svc.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685e968-3a8e-4710-821f-ad41e0688f46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo de Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab93d6-efb1-4f8f-bbbf-d2982b4864a9",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b40cd75b-8030-40ca-99c5-e52a183a381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_lrc(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador por Regressão Logística\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "        \"C\": trial.suggest_float(\"C\", 0.01, 10.0, log=True),\n",
    "        \"class_weight\": trial.suggest_categorical(\"class_weight\", [\"balanced\", None]),\n",
    "        \"solver\":\"liblinear\",\n",
    "        \"max_iter\":5000,\n",
    "        \"random_state\":semente\n",
    "    }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\", \"rfe\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 38)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Adiciona tratamento RFE \n",
    "    elif treatment == \"rfe\": \n",
    "        # Definindo o estimador \n",
    "        estimator = LogisticRegression(**params)\n",
    "        # Definindo o número de atributos a serem mantidos\n",
    "        n_features_to_select = trial.suggest_int(\"rfe_features\", 2, 38)\n",
    "        steps.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "        \n",
    "    # Instânciando o modelo\n",
    "    modelo = LogisticRegression(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624a53c-a08a-4082-a23f-ab641655ba20",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fec90b1-1e1d-4d61-aa8b-c5915e784551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_lrc(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_lrc(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133736b-3e5e-4435-8b09-e23719c5e8b9",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d27304a0-418e-437a-b0a1-b08a2a34e361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[I 2025-11-01 15:29:43,253] Using an existing study with name 'Estudo LRC' instead of creating a new one.\n"
=======
      "[I 2025-11-01 22:02:52,515] Using an existing study with name 'Estudo LRC' instead of creating a new one.\n"
>>>>>>> cef9044831e90c9d5968087939d7084443eb87b7
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_lrc = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo LRC\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo LRC\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748ee444-879e-4583-85a4-25adce2dca42",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd38c992-f6a6-4668-91f7-44f3525a4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "        \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": None,\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Modelo base com normalização padrão\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "        \"penalty\": \"l2\",  \n",
    "        \"C\": 1, \n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos \n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "        \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None, \n",
    "        \"normalization\": \"minmax\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "       \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"maxabs\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "       \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"pca\",\n",
    "        \"pca_components\": 38\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e RFE\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "       \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"rfe\",\n",
    "        \"rfe_features\": 19\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93441716-6195-4888-9fd2-0b9e4ce579eb",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd0ca875-a854-400c-88dd-50e0455744ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_lrc(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_lrc(trial, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c5de3-69b3-4342-9b72-884bd4e6718e",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df458bda-0f0f-47f9-9e62-0fef8830dd45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# study_lrc.optimize(parcial_lrc, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c68dc-b533-4193-b524-3d11cee31a47",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a745ea7-5274-4bbe-85ba-b79e7e357abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 94\n",
      "Parâmetros do melhor trial: {'penalty': 'l2', 'C': 2.7595008656881284, 'class_weight': None, 'normalization': None, 'treatment': 'pca', 'pca_components': 35}\n"
     ]
    }
   ],
   "source": [
    "resultado_lrc = study_lrc.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_lrc.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_lrc.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab9a40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Otimizando um modelo de DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c569a36",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09d7cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_DecisionTree(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador por DecisionTree\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\",\"entropy\",\"log_loss\"]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 32),\n",
    "        \"min_samples_split\": trial.suggest_float(\"min_samples_split\", 0.01, 1.0),\n",
    "        \"min_samples_leaf\": trial.suggest_float(\"max_samples_leaf\", 0.01, 0.5),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "        \"random_state\": semente\n",
    "    }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
<<<<<<< HEAD
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "\n",
=======
>>>>>>> cef9044831e90c9d5968087939d7084443eb87b7
    "    # Definindo estratégia de redução de dimensionalidade\n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 38)\n",
    "        steps.append(PCA(n_components=components))\n",
    "        \n",
    "    # Instanciando o modelo\n",
    "    modelo = DecisionTreeClassifier(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3534cd1",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28f4799f-c3bd-4308-b4c4-fd3ec9e53bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_DecisionTree(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_DecisionTree(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b681b8d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e00b3e93-1eb6-44b5-8908-c2adc9717ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[I 2025-11-01 23:16:09,867] Using an existing study with name 'Estudo DecisionTree' instead of creating a new one.\n"
=======
      "[I 2025-11-01 22:02:53,537] A new study created in RDB with name: Estudo DecisionTree\n"
>>>>>>> cef9044831e90c9d5968087939d7084443eb87b7
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_DecisionTree = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo DecisionTree\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo DTC\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269fade3",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86da30fc-19cc-45c3-81c8-9eebb38c6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"treatment\": None\n",
    "}\n",
    ")\n",
    "\n",
<<<<<<< HEAD
    "# Modelos base com PCA\n",
=======
    "# Modelo base com PCA\n",
>>>>>>> cef9044831e90c9d5968087939d7084443eb87b7
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"normalization\": \"standard\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 38\n",
    "}\n",
    ")\n",
    "\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"normalization\": \"minmax\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 38\n",
    "}\n",
    ")\n",
    "\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"normalization\": \"maxabs\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 38\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675329b",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19b9addf-bec2-4bf4-919a-6b3a01ad35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_DecisionTree(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_DecisionTree(trial, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1a913",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75c10ac9-758b-43b8-959f-21d36018f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_DecisionTree.optimize(parcial_DecisionTree, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc2e06-cc2d-4de7-aa0f-58081b6c213a",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6346a64c-bd39-4b66-9178-e284977c5f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Record does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m resultado_DecisionTree = \u001b[43mstudy_DecisionTree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_trial\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNúmero do melhor trial: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresultado_DecisionTree.number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParâmetros do melhor trial: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresultado_DecisionTree.params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\venvs\\ilumpy\\Lib\\site-packages\\optuna\\study\\study.py:162\u001b[39m, in \u001b[36mStudy.best_trial\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_multi_objective():\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m best_trial = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_storage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# trials. Note that the behavior is undefined when constrained optimization without the\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# violation value in the best-valued trial.\u001b[39;00m\n\u001b[32m    167\u001b[39m constraints = best_trial.system_attrs.get(_CONSTRAINTS_KEY)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\venvs\\ilumpy\\Lib\\site-packages\\optuna\\storages\\_cached_storage.py:182\u001b[39m, in \u001b[36m_CachedStorage.get_best_trial\u001b[39m\u001b[34m(self, study_id)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_best_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, study_id: \u001b[38;5;28mint\u001b[39m) -> FrozenTrial:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\venvs\\ilumpy\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:934\u001b[39m, in \u001b[36mRDBStorage.get_best_trial\u001b[39m\u001b[34m(self, study_id)\u001b[39m\n\u001b[32m    931\u001b[39m direction = _directions[\u001b[32m0\u001b[39m]\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m direction == StudyDirection.MAXIMIZE:\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m     trial_id = \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrialModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_max_value_trial_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    936\u001b[39m     trial_id = models.TrialModel.find_min_value_trial_id(study_id, \u001b[32m0\u001b[39m, session)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\venvs\\ilumpy\\Lib\\site-packages\\optuna\\storages\\_rdb\\models.py:211\u001b[39m, in \u001b[36mTrialModel.find_max_value_trial_id\u001b[39m\u001b[34m(cls, study_id, objective, session)\u001b[39m\n\u001b[32m    191\u001b[39m trial = (\n\u001b[32m    192\u001b[39m     session.query(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    193\u001b[39m     .with_entities(\u001b[38;5;28mcls\u001b[39m.trial_id)\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m     .one_or_none()\n\u001b[32m    209\u001b[39m )\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(NOT_FOUND_MSG)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Record does not exist."
     ]
    }
   ],
   "source": [
    "resultado_DecisionTree = study_DecisionTree.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_DecisionTree.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_DecisionTree.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01e1bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Otimizando um modelo de RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b225e9",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb4570-58f0-451d-8cf5-aa42dff162d4",
   "metadata": {},
   "source": [
    "Os parâmetros que precisamos considerar para uma floresta aleatória são muito parecidos com o de uma árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d961337-0e23-4f05-a137-58a2f9dc7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_RandomForest(trial):\n",
    "    \"\"\" Recebe um trial do optuna e retorna uma instância do modelo\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros\n",
    "    params = {\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "    \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"]),\n",
    "    \"max_depth\" trial.suggest_int(\"max_depth\", 2, 32),\n",
    "    \"min_sample_split\": trial.suggest_float(\"min_samples_split\", 0.01, 1.0),\n",
    "    \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
    "    \"max_features\": trial.suggest_float(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "    \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "    \"random_state\": semente\n",
    "    }\n",
    "\n",
    "    # Passos a serem seguidos pela pipeline\n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "        normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "    \n",
    "        # Adiciona normalização padrão\n",
    "        if normalization == \"standard\": \n",
    "            steps.append(StandardScaler())\n",
    "        # Adiciona normalização por máximos e mínimos\n",
    "        elif normalization == \"minmax\": \n",
    "            steps.append(MinMaxScaler())\n",
    "        # Adiciona normalização por máximo absoluto\n",
    "        elif normalization == \"maxabs\": \n",
    "            steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade\n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 38)\n",
    "        steps.append(PCA(n_components=components))\n",
    "        \n",
    "    # Instanciando o modelo\n",
    "    modelo = RandomForestClassifier(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e0584",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b0e95-afe2-4853-9f99-30453bb31b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_RandomForest(trial, X_treino, Y_treino):\n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    modelo = instanciador_RandomForest(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"f1\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8916f",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e4875a4-94af-40f0-8825-17f26fcac616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 23:08:37,272] A new study created in RDB with name: Estudo Random Forest\n"
     ]
    }
   ],
   "source": [
    "study_RandomForest = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"Estudo Random Forest\", \n",
    "    storage=f\"sqlite:///{\"Estudo RFC\"}.db\",\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584d13c",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1031e3b-6cba-47a5-8dbd-e9fac9edb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_RandomForest.enqueue_trial({\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"treatment\": None\n",
    "})\n",
    "\n",
    "# Modelo base com PCA\n",
    "study_RandomForest.enqueue_trial({\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"normalization\": \"standard\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 38\n",
    "})\n",
    "\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"normalization\": \"minmax\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 38\n",
    "}\n",
    ")\n",
    "\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"normalization\": \"maxabs\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 38\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e3405",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac05b02-cd55-41c8-9bfd-d80a4237338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_RandomForest(trial):\n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_RandomForest(trial, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a51ad",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6152f8-8f0c-4297-9f5c-5f4143c08467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_RandomForest.optimize(parcial_RandomForest, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb150a-2aa8-41a9-86a8-c9e2ba5d2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_RandomForest = study_RandomForest.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_RandomForest.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_RandomForest.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416e230-69a2-4cd1-af9f-36f15895f0b7",
   "metadata": {},
   "source": [
    "# Teste dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "a6005d9e-6d73-4538-b13b-767744ea63d2",
   "metadata": {},
   "source": [
    "# Conclusão"
=======
   "id": "2d4a2a10-e951-4514-abfe-0f183729fea4",
   "metadata": {},
   "source": [
    "# Resultados e Conclusões"
>>>>>>> cef9044831e90c9d5968087939d7084443eb87b7
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82707f99-8633-4b32-bdb5-0bdaf8fc946c",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952381c-4759-4dc4-90be-758fd40cc3c6",
   "metadata": {},
   "source": [
    "- Documentação DecisionTree:https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "- Documentação RandomForest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
