{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f9aebc-eca6-42e9-8647-f8d7ef3dc991",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <H1>Aprendizado de Máquina - Trabalho Final</H1>\n",
    "    <H3>Prof.º Daniel Roberto Cassar</H3> \n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"right\">\n",
    "    <H3>Guilda: Carcajus</H3>\n",
    "    <H4>Aniel Souza Ribeiro Neto</H4>\n",
    "    <H4>Caio Cogo Beriam</H4>\n",
    "    <H4>Joaquim Junior Ferola Fonseca</H4>\n",
    "</div>\n",
    "\n",
    "<br> \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"Imagens/carcajus_bg.png\" width=\"500\"/>\n",
    "    <figcaption><H3><I>\"Mastigar primeiro, digerir depois!\"</I></H3></figcaption>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0ebc27-9179-4a65-8b7f-329e2578963e",
   "metadata": {},
   "source": [
    "# Lore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2e820-7957-4ec0-981c-45941fb11ba0",
   "metadata": {},
   "source": [
    "    \"    Você não ouviria o barulho das engrenagens se não tivessem te contado sobre elas. Você nunca saberia que elas estão rodando, centenas de metros sob seus pés, talvez até quilômetros. Mas elas estão ali, engrenadas e ativas como sempre. Elas são o trunfo do Continente, a ferramenta secreta de todo o povo para responder a Pergunta Final. E mesmo que não possamos ouvi-las com nossa audição, sentimos seu ritmo em nossos corações, pulsando junto conosco.   \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bd158-3de9-45f7-8643-b18a9a8e8643",
   "metadata": {},
   "source": [
    "Os viajantes costumam dizer que o reino de Lumi é pequeno, mas ajeitadinho. É de fato inspirador andar pelos cenários característicos, como as praças, jardins e tavernas, e ver seus simpáticos habitantes recitando encantamentos, feitiços, magias e maldições.\n",
    "\n",
    "O reino também é movido por um grande número de heróis *freelancers*, que recebem quests dos ilustres moradores já bem renomados. Alguns deles se unem em guildas, outros trabalham sozinhos; alguns cumprem missões com maestria, enquanto outros mal saem vivos.\n",
    "\n",
    "Não posso dizer em qual desses grupos os Carcajus se encaixam. A verdade, é que estes são três paranóicos aventureiros que ambicionam moedas, pergaminhos, caixinhas de suco e outras coisinhas, para que depois possam gastar tudo em comida e bebida. Esse habitozinho ignóbil rendeu aos três o apelido de \"glutões\", que eles acolheram com orgulho e de bom-grado.\n",
    "\n",
    "Entretanto, por sugestão de Edna Ensineide, notável conselheira real, os Glutões buscaram um novo nome em algum sinônimo mais respeitável. Assim, ao consultarem a Grande Enciclopédia dos Insultos e Injúrias na Biblioteca Real, verificaram que um dos nomes para um glutão é **Carcaju**, um pequeno e feroz animal que rivaliza com lobos e ursos pelo seu apetite insaciável.\n",
    "\n",
    "Unidos, os Carcajus trabalham sob o lema **\"Mastigar primeiro, digerir depois\"**, que representa a voracidade do grupo de devorar grandes coisas em pequenas mordidas, e confiar piamente na própria capacidade de digestão para cumprir a tarefa.\n",
    "\n",
    "O que eles não esperavam, é que nessa visita à biblioteca eles seriam atraídos para o temido **Pythonomicron**, um compêndio de maldições e informações proibidas do lado mais obscuro da magia. E ali, em uma página secreta, de baixo de um post-it de um estudante dedicado, encontraram rabiscada a lenda do Horripilante Processador Central, um mecanismo milenar que continha poder inimaginável, guardado por um dos mais poderosos magos do continente.\n",
    "\n",
    "Agora, a quest de Milu Iluminarius MLVI era a pista que mais aproximava os Carcajus desse tesouro ancião. Mas para isso, eles teriam que conquistar a simpatia do rei e colecionar suas Coroas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8efdb-3dc4-4b7f-9e7b-738936725685",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introdução\n",
    "\n",
    "A área de nanotoxicologia, que estuda como nanomateriais interagem com sistemas biológicos, tem se tornado cada vez mais importante com os avanços da nanotecnologia, permitindo que esses materiais sejam implementados de maneira segura ao meio ambiente e aos possíveis seres vivos que venham a entrar em contato com esses nanomateriais. Entretanto, como outras características dos nanomateriais, sua toxicidade pode variar muito conforme a morfologia do composto, assim, para ser analisada corretamente uma série de fatores devem ser levados em consideração, o que torna difícil a previsão da toxicidade dos materiais. \n",
    "\n",
    "Sob essa perspectiva, nosso trabalho tem o objetivo de facilitar esse tarefa através do treinamento de um modelo de Aprendizado de Máquina Supervisionado capaz de prever se uma nanopartícula é tóxica com base em características da sua morfologia. Para isso, utilizaremos como fundamento um conjunto de dados contendo as características de diversas nanoparticulas e se elas são ou não tóxicas. O dataset foi elaborado pelo trabalho Subramanian NA, Palaniappan A. NanoTox: Development of a Parsimonious In Silico Model for Toxicity Assessment of Metal-Oxide Nanoparticles Using Physicochemical Features. ACS Omega 2021, 6, 17, 11729–11739 doi:10.1021/acsomega.1c01076, e o obtivemos pela plataforma Kaggle através do endereço https://www.kaggle.com/datasets/apalania/toxicityassessment-meoxnp.\n",
    "\n",
    "Para fins de organização e didática, este trabalho será dividido nas seguintes etapas:\n",
    "1. Preparo dos dados: Nessa seção será feita a obtenção e tratamento dos dados, permitindo que eles sejam posteriormente utilizados sem problemas, além disso, será feita também a divisão dos dados de treino e de teste dos modelos;\n",
    "2. Estudo dos modelos: Nessa etapa faremos o estudo de 5 modelos através do módulo optuna para optimzação de hiperparâmetros e estratégias de normalização de dados e tratamento de atributos, buscando o melhor pipeline encontrado pelo optuna para cada modelo;\n",
    "3. Teste dos modelos: Após definirmos os melhores pipelines encontrados pelo optuna, iremos instânciar, treinar e comparar os 5 pipelines em busca do de melhor desempenho, que, por fim, utilizaremos para prever os dados de teste;\n",
    "4. Resultados e conclusão: Enfim, discutiremos os resultados obtidos pelo trabalho e apresentaremos sua conclusão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30654516",
   "metadata": {},
   "source": [
    "# Módulos utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74068e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Modelos de Aprendizado Supervisionado\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Tratamento\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Normalização\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "\n",
    "# Separação de dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Validação Cruzada\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from optuna import create_study\n",
    "\n",
    "# Visualização dos resultados\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb81756-c4e9-4bdc-8baa-f5dffb85e498",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preparo dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0db95",
   "metadata": {},
   "source": [
    "\n",
    "Nesta seção será realizado o tratamento dos dados, preparando-os para serem usados para treino e subsequente avaliação dos modelos que serão estudados. O processo de tratamento de dados é fundamental para a prática de ciência de dados e aprendizado de máquina, dados bem tratados podem impulsionar fortemente o desempenho de modelos e evitar problemas nos seus treinos, além disso, boas práticas ao lidar com dados permitem evitar o vazamento de dados e facilitam o trabalho. \n",
    "\n",
    "Sobre essa perspectiva, nesta seção será feita a importação dos dados do dataset através do módulo pandas, o tratamento dos dados, removendo dados que sem informação e codificando dados categóricos para que os modelos possam os interpretar, e por fim a divisão dos dados para treino e teste dos modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8cd0f",
   "metadata": {},
   "source": [
    "## Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ee246e-268d-42bc-90a4-d17064d2d62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPs</th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>e</th>\n",
       "      <th>NOxygen</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>25.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>35.6</td>\n",
       "      <td>295.5</td>\n",
       "      <td>-41.6</td>\n",
       "      <td>27.9</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>ZnO</td>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>881 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NPs  coresize  hydrosize  surfcharge  surfarea    Ec  Expotime  \\\n",
       "0    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "1    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "2    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "3    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "4    Al2O3      39.7      267.0        36.3      64.7 -1.51        24   \n",
       "..     ...       ...        ...         ...       ...   ...       ...   \n",
       "876    ZnO      45.3      310.0        32.7      21.3 -3.89        24   \n",
       "877    ZnO      32.0     1093.0        21.6      37.0 -3.89        24   \n",
       "878    ZnO      46.3      239.0        42.8      24.1 -5.17        12   \n",
       "879    ZnO      35.6      295.5       -41.6      27.9 -3.89        24   \n",
       "880    ZnO      46.3      239.0        42.8      24.1 -5.17        24   \n",
       "\n",
       "      dosage     e  NOxygen     class  \n",
       "0      0.001  1.61        3  nonToxic  \n",
       "1      0.010  1.61        3  nonToxic  \n",
       "2      0.100  1.61        3  nonToxic  \n",
       "3      1.000  1.61        3  nonToxic  \n",
       "4      5.000  1.61        3  nonToxic  \n",
       "..       ...   ...      ...       ...  \n",
       "876   20.000  1.65        1     Toxic  \n",
       "877   25.000  1.65        1     Toxic  \n",
       "878  100.000  1.90        1     Toxic  \n",
       "879   10.000  1.65        1     Toxic  \n",
       "880  100.000  1.90        1     Toxic  \n",
       "\n",
       "[881 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"nanotox_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82528fdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tratamento dos dados [ALTERAR]\n",
    "\n",
    "O tratamento de dados deste trabalho consisitirá no seguinte processo: Remoção de dados faltantes, comuns em diversos datasets não tratados e que atrapalham o treino dos modelos; Remoção de linhas duplicadas, que, apesar de não impedirem o funcionamento do modelo, trazem uma redundância nos dados, influênciando a percepção do modelo sobre os dados; Codificação one-hot dos atributos categóricos, permitindo que os modelos interpretem esses dados; Remoção de colunas sem variância, uma vez que colunas sem variância não trazem qualquer informação ao modelo, não há padrões a serem inferidos em algo que não varia; Tranformação do target para forma numérica, permitindo o seu uso sem problemas de alguns modelos e estatíticas de teste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a732cb-78ba-41af-b4dd-f70c74052463",
   "metadata": {},
   "source": [
    "### $\\bullet$ Removendo linhas com dados faltantes ou duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa0f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com valores NaN\n",
    "df = df.dropna()\n",
    "# Removendo linhas duplicadas\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4235b44-75ca-4f9c-b287-c5ac0fefac64",
   "metadata": {},
   "source": [
    "### $\\bullet$ Restringindo dados às nanopartículas de ZnO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd4f65-84fe-4049-96e2-832b91cc2245",
   "metadata": {},
   "source": [
    "* Identificando as linhas com NPs de ZnO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc844d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>e</th>\n",
       "      <th>NOxygen</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coresize  hydrosize  surfcharge  surfarea    Ec  Expotime   dosage     e  \\\n",
       "249      45.3      310.0        32.7      21.3 -3.89        24    0.001  1.65   \n",
       "250      45.3      310.0        32.7      21.3 -3.89        24    0.010  1.65   \n",
       "251      45.3      310.0        32.7      21.3 -3.89        24    0.100  1.65   \n",
       "252      45.3      310.0        32.7      21.3 -3.89        24    1.000  1.65   \n",
       "253      45.3      310.0        32.7      21.3 -3.89        24    5.000  1.65   \n",
       "..        ...        ...         ...       ...   ...       ...      ...   ...   \n",
       "636      46.3      239.0        42.8      24.1 -5.17        12  100.000  1.90   \n",
       "679      46.3      239.0        42.8      24.1 -5.17        24   10.000  1.90   \n",
       "690      46.3      239.0        42.8      24.1 -5.17        12   50.000  1.90   \n",
       "713      46.3      239.0        42.8      24.1 -5.17        24   50.000  1.90   \n",
       "785      46.3      239.0        42.8      24.1 -5.17        24   20.000  1.90   \n",
       "\n",
       "     NOxygen     class  \n",
       "249        1  nonToxic  \n",
       "250        1  nonToxic  \n",
       "251        1  nonToxic  \n",
       "252        1  nonToxic  \n",
       "253        1  nonToxic  \n",
       "..       ...       ...  \n",
       "636        1     Toxic  \n",
       "679        1     Toxic  \n",
       "690        1     Toxic  \n",
       "713        1     Toxic  \n",
       "785        1     Toxic  \n",
       "\n",
       "[198 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrando as linhas com NPs de ZnO\n",
    "logica = df[\"NPs\"] == \"ZnO\"\n",
    "df = df.loc[logica]\n",
    "\n",
    "# Removendo coluna NPs\n",
    "df = df.drop(\"NPs\", axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fa3ba-8329-4a33-ad75-562a6802d492",
   "metadata": {},
   "source": [
    "### $\\bullet$ Removendo colunas com variância 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f33fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>e</th>\n",
       "      <th>NOxygen</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>nonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coresize  hydrosize  surfcharge  surfarea    Ec  Expotime   dosage     e  \\\n",
       "249      45.3      310.0        32.7      21.3 -3.89        24    0.001  1.65   \n",
       "250      45.3      310.0        32.7      21.3 -3.89        24    0.010  1.65   \n",
       "251      45.3      310.0        32.7      21.3 -3.89        24    0.100  1.65   \n",
       "252      45.3      310.0        32.7      21.3 -3.89        24    1.000  1.65   \n",
       "253      45.3      310.0        32.7      21.3 -3.89        24    5.000  1.65   \n",
       "..        ...        ...         ...       ...   ...       ...      ...   ...   \n",
       "636      46.3      239.0        42.8      24.1 -5.17        12  100.000  1.90   \n",
       "679      46.3      239.0        42.8      24.1 -5.17        24   10.000  1.90   \n",
       "690      46.3      239.0        42.8      24.1 -5.17        12   50.000  1.90   \n",
       "713      46.3      239.0        42.8      24.1 -5.17        24   50.000  1.90   \n",
       "785      46.3      239.0        42.8      24.1 -5.17        24   20.000  1.90   \n",
       "\n",
       "     NOxygen     class  \n",
       "249        1  nonToxic  \n",
       "250        1  nonToxic  \n",
       "251        1  nonToxic  \n",
       "252        1  nonToxic  \n",
       "253        1  nonToxic  \n",
       "..       ...       ...  \n",
       "636        1     Toxic  \n",
       "679        1     Toxic  \n",
       "690        1     Toxic  \n",
       "713        1     Toxic  \n",
       "785        1     Toxic  \n",
       "\n",
       "[198 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instânciando o VarianceThreshold \n",
    "threshold = VarianceThreshold(threshold=0.0)\n",
    "# Ajustando o modelo e transformando os dados\n",
    "threshold.fit_transform(df.loc[:, df.dtypes != 'object'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89786f5e-959a-4779-adb5-64dd3b584f38",
   "metadata": {},
   "source": [
    "### $\\bullet$ Tranformando o target para a forma numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098a6a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coresize</th>\n",
       "      <th>hydrosize</th>\n",
       "      <th>surfcharge</th>\n",
       "      <th>surfarea</th>\n",
       "      <th>Ec</th>\n",
       "      <th>Expotime</th>\n",
       "      <th>dosage</th>\n",
       "      <th>e</th>\n",
       "      <th>NOxygen</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>45.3</td>\n",
       "      <td>310.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>12</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>46.3</td>\n",
       "      <td>239.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>24</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coresize  hydrosize  surfcharge  surfarea    Ec  Expotime   dosage     e  \\\n",
       "249      45.3      310.0        32.7      21.3 -3.89        24    0.001  1.65   \n",
       "250      45.3      310.0        32.7      21.3 -3.89        24    0.010  1.65   \n",
       "251      45.3      310.0        32.7      21.3 -3.89        24    0.100  1.65   \n",
       "252      45.3      310.0        32.7      21.3 -3.89        24    1.000  1.65   \n",
       "253      45.3      310.0        32.7      21.3 -3.89        24    5.000  1.65   \n",
       "..        ...        ...         ...       ...   ...       ...      ...   ...   \n",
       "636      46.3      239.0        42.8      24.1 -5.17        12  100.000  1.90   \n",
       "679      46.3      239.0        42.8      24.1 -5.17        24   10.000  1.90   \n",
       "690      46.3      239.0        42.8      24.1 -5.17        12   50.000  1.90   \n",
       "713      46.3      239.0        42.8      24.1 -5.17        24   50.000  1.90   \n",
       "785      46.3      239.0        42.8      24.1 -5.17        24   20.000  1.90   \n",
       "\n",
       "     NOxygen  class  \n",
       "249        1      0  \n",
       "250        1      0  \n",
       "251        1      0  \n",
       "252        1      0  \n",
       "253        1      0  \n",
       "..       ...    ...  \n",
       "636        1      1  \n",
       "679        1      1  \n",
       "690        1      1  \n",
       "713        1      1  \n",
       "785        1      1  \n",
       "\n",
       "[198 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"] = df[\"class\"].map({'nonToxic': 0, 'Toxic': 1})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2f738",
   "metadata": {},
   "source": [
    "### $\\bullet$ Definindo labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a03228f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem_labels = [\"Não tóxico\", \"Tóxico\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f467fa64",
   "metadata": {},
   "source": [
    "## Separando os dados para treino e teste\n",
    "\n",
    "A separação de dados em treino e teste é uma forma de avaliar o desempenho dos modelos sem serem necessárias novas observações. Ela consiste em omitir um fração dos dados no treino do modelo, utilizando apenas o restante dos dados para treino do modelo. Os dados de teste devem sempre ser utilizados somente quando todo o processo de treino e otimização dos modelos tiver sido concluído e o modelo final ter sido escolhido, para evitar o vazamento de dados do conjunto de teste, o que traria um enviesamento do modelo e faria com que o teste não fosse uma boa estimativa do desempenho do modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e29e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a semente aleatória\n",
    "semente = 3931421\n",
    "\n",
    "# Definindo a lista de atributos\n",
    "atributos = df.drop(columns=[\"class\"])\n",
    "# Definindo o target\n",
    "target = df[\"class\"]\n",
    "\n",
    "# Realizando a separação dos dados \n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "    atributos,\n",
    "    target,\n",
    "    test_size=0.1,\n",
    "    random_state=semente,\n",
    "    stratify=df[\"class\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a08aae-e31f-45d5-8726-c054271b50e5",
   "metadata": {},
   "source": [
    "# Estudos dos modelos \n",
    "\n",
    "Nessa etapa será utilizada o módulo optuna para optimização de hiperparâmetros e escolha de estratégias de normalização dos dados para 5 modelos: Um KNN, uma SVM, uma Regressão Logística, uma DecisionTree e uma RandomForest, todos de classificação e da biblioteca scikit-learn. Para cada modelo mencionado, o processo realizado seguirá o seguinte fluxo: \n",
    "1. Criar a função para instanciar os modelos: A função que possui os critérios que o optuna testará, retornando o modelo com os parâmetros definidos pelo optuna.\n",
    "2. Criar a função que será otimizada pelo optuna: A função que computará a métrica a ser minimizada ou maximizada pelo optuna.\n",
    "3. Criar um estudo do optuna: Arquivo onde serão salvos os testes e resultados do optuna.\n",
    "4. Indicar testes desejados: Indicar testes com valores específicos que desejamos que o optuna teste.\n",
    "5. Criar a função objetivo parcial: Função que retorna a função a ser otimizada, necessária para o optuna.\n",
    "6. Rodar o optuna e otimizar os parâmetros.\n",
    "\n",
    "Vamos entender um pouco mais a fundo cada uma das etapas, lembrando que serão realizadas para cada um dos modelos: \n",
    "1. A primeira etapa é a criação de uma função que possui em seu corpo opções de escolha que serão testadas pelo optuna. Neste trabalho, cada um dos modelos terá uma função que testa diferentes valores para seus hiperparâmetros, que sejam relevantes, que serão salvos em um dicionário para serem utilizados para instanciar os modelos posteriormente. Depois, o optuna poderá escolher entre normalizar ou não dados, seguindo as normalizações padrão, por mínimos e máximos ou máximo absoluto, e também poderá escolher entre aplicar ou não estratégias de redução de dimensionalidade ou seleção de atributos, adicionando as estratégias escolhidas a uma lista de passos para a criação de um pipeline. Por fim, será instânciado um modelo com os parâmetros definidos e criaremos um pipeline com os passos de tratamento de dados, caso escolhidos pelo optuna, e o modelo instanciado, que será retornado pela função.\n",
    "\n",
    "2. Aqui será criada uma função que chama a função para instanciar o modelo e testa o modelo criado através de uma validação cruzada seguindo uma estratégia de kfold estratificado com 3 folds e métrica accuracy. A função retorna o desempenho médio do modelo.\n",
    "\n",
    "3. Criaremos nessa etapa o estudo do optuna, que gera um arquivo contendo os dados obtidos pela otimização que será feita posterioremente, caso já haja um arquivo do estudo ele será lido ao invés de outro ser criado. Nesse ponto, caso deseje utilizar os resultados já obtidos basta baixar os estudos apresentados no repositório deste trabalho no github. O estudo irá buscar maximizar o valor recebido pela função objetivo ao longo das iterações.\n",
    "\n",
    "4. Agora indicaremos alguns casos particulares que desejamos analisar. Vamos indicar que o optuna teste ao menos uma vez cada caso de normalização e tratamento de dados com os parâmetros base do sklearn.\n",
    "\n",
    "5. O optuna requer que a função objetivo seja chamada por uma outra função, portanto, criamos uma função que retorna a função objetivo com o trial do optuna.\n",
    "\n",
    "6. Por fim, faremos otimização de parâmetros pelo optuna. Note que a linha que faz essa etapa está na forma de comentário por padrão pois considera que os estudos disponibilizados no repositório tenham sido baixados, caso tenha optado por não baixar os estudos ou tenha interesse em fazer mais estudos, basta remover a hashtag `#` no início da linha para realizar a otimização."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f8394-0631-40e8-a827-425f5c8e176b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo K-NearestNeighbors Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61377cc-6cdc-4997-a2a1-a048d7c02436",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce140ba-fbe2-4c40-828a-22e0e16ebc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_knn(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador KNN\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "        \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 1, 200, log=True),\n",
    "        \"p\": trial.suggest_int(\"p\", 1, 2),\n",
    "        \"weights\": trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"])\n",
    "    }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Instânciando o modelo\n",
    "    modelo = KNeighborsClassifier(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d9cd3-a225-43dc-afa2-dc4a268575f0",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4036370-d81a-4983-8ba1-ee3c95921f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_knn(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_knn(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"accuracy\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72178c-5da7-4e00-922a-685eaa9fd71b",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um Estudo do Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b95bf20-cdf8-4a67-b7f2-054fcca33b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:36:07,354] A new study created in RDB with name: Estudo KNN\n"
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_knn = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo KNN\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo KNN\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0addb63-3f19-44fa-a97d-ba27e6510d13",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab3c6a8-f33b-4c41-bd6f-3e261ac48f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": None,\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão \n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos \n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"minmax\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto\n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"maxabs\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_knn.enqueue_trial(\n",
    "    {\n",
    "        \"n_neighbors\": 5, \n",
    "        \"p\": 2, \n",
    "        \"weights\": \"uniform\", \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"pca\",\n",
    "        \"pca_components\": 9\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf8ea14-ee87-4413-8b70-b18842816927",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250d982e-dab1-4547-8fa6-3ce7178ab949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_knn(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_knn(trial, x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de1364a-c029-44ff-babb-a0a7d49508c6",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d65d70-eb86-44ca-b904-759cf10294b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:36:07,628] Trial 0 finished with value: 0.713276836158192 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.713276836158192.\n",
      "[I 2025-11-03 08:36:07,756] Trial 1 finished with value: 0.7695856873822975 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 1 with value: 0.7695856873822975.\n",
      "[I 2025-11-03 08:36:07,977] Trial 2 finished with value: 0.7584745762711865 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 1 with value: 0.7695856873822975.\n",
      "[I 2025-11-03 08:36:08,103] Trial 3 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 1 with value: 0.7695856873822975.\n",
      "[I 2025-11-03 08:36:08,242] Trial 4 finished with value: 0.7807909604519775 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:08,388] Trial 5 finished with value: 0.6854048964218457 and parameters: {'n_neighbors': 21, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': 'pca', 'pca_components': 7}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:08,521] Trial 6 finished with value: 0.6852165725047081 and parameters: {'n_neighbors': 6, 'p': 2, 'weights': 'distance', 'normalization': None, 'treatment': 'pca', 'pca_components': 3}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:08,672] Trial 7 finished with value: 0.7134651600753296 and parameters: {'n_neighbors': 8, 'p': 1, 'weights': 'uniform', 'normalization': None, 'treatment': 'pca', 'pca_components': 6}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:08,805] Trial 8 finished with value: 0.7243879472693031 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': 'pca', 'pca_components': 5}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:08,954] Trial 9 finished with value: 0.7355932203389831 and parameters: {'n_neighbors': 1, 'p': 1, 'weights': 'distance', 'normalization': None, 'treatment': 'pca', 'pca_components': 6}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:15,885] Trial 10 finished with value: 0.617984934086629 and parameters: {'n_neighbors': 111, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:16,017] Trial 11 finished with value: 0.6966101694915254 and parameters: {'n_neighbors': 24, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:16,144] Trial 12 finished with value: 0.7245762711864406 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:16,271] Trial 13 finished with value: 0.702165725047081 and parameters: {'n_neighbors': 16, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:16,434] Trial 14 finished with value: 0.6346516007532956 and parameters: {'n_neighbors': 72, 'p': 1, 'weights': 'distance', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:16,549] Trial 15 finished with value: 0.7246704331450093 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:16,672] Trial 16 finished with value: 0.7302259887005649 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:16,802] Trial 17 finished with value: 0.6684557438794728 and parameters: {'n_neighbors': 55, 'p': 1, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:16,933] Trial 18 finished with value: 0.7020715630885123 and parameters: {'n_neighbors': 12, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:17,073] Trial 19 finished with value: 0.7078154425612052 and parameters: {'n_neighbors': 27, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 3}. Best is trial 4 with value: 0.7807909604519775.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 187, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 187, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 187, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:17,215] Trial 20 failed with parameters: {'n_neighbors': 187, 'p': 1, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:17,215] Trial 20 failed with value np.float64(nan).\n",
      "[I 2025-11-03 08:36:17,350] Trial 21 finished with value: 0.724482109227872 and parameters: {'n_neighbors': 3, 'p': 1, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 4}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:17,469] Trial 22 finished with value: 0.7303201506591336 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:17,616] Trial 23 finished with value: 0.7134651600753296 and parameters: {'n_neighbors': 10, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:17,746] Trial 24 finished with value: 0.7415254237288136 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:17,876] Trial 25 finished with value: 0.7189265536723163 and parameters: {'n_neighbors': 11, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:18,010] Trial 26 finished with value: 0.7078154425612052 and parameters: {'n_neighbors': 7, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:18,140] Trial 27 finished with value: 0.7301318267419963 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:18,271] Trial 28 finished with value: 0.6740112994350281 and parameters: {'n_neighbors': 40, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 199, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 199, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 199, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:18,452] Trial 29 failed with parameters: {'n_neighbors': 199, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 2} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:18,453] Trial 29 failed with value np.float64(nan).\n",
      "[I 2025-11-03 08:36:18,624] Trial 30 finished with value: 0.7241996233521658 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 2}. Best is trial 4 with value: 0.7807909604519775.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 189, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 189, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 189, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:18,752] Trial 31 failed with parameters: {'n_neighbors': 189, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:18,752] Trial 31 failed with value np.float64(nan).\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 194, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 194, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 194, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:18,888] Trial 32 failed with parameters: {'n_neighbors': 194, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:18,888] Trial 32 failed with value np.float64(nan).\n",
      "[I 2025-11-03 08:36:19,024] Trial 33 finished with value: 0.7302259887005649 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:19,165] Trial 34 finished with value: 0.702165725047081 and parameters: {'n_neighbors': 16, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:19,305] Trial 35 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:19,453] Trial 36 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:19,593] Trial 37 finished with value: 0.6965160075329567 and parameters: {'n_neighbors': 8, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:19,718] Trial 38 finished with value: 0.7302259887005649 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:19,855] Trial 39 finished with value: 0.7134651600753296 and parameters: {'n_neighbors': 6, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': 'pca', 'pca_components': 8}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:19,993] Trial 40 finished with value: 0.7300376647834276 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'distance', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:20,108] Trial 41 finished with value: 0.7134651600753296 and parameters: {'n_neighbors': 8, 'p': 1, 'weights': 'uniform', 'normalization': None, 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:20,242] Trial 42 finished with value: 0.718738229755179 and parameters: {'n_neighbors': 17, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 5}. Best is trial 4 with value: 0.7807909604519775.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 187, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 187, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 277, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 187, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:20,353] Trial 43 failed with parameters: {'n_neighbors': 187, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:20,353] Trial 43 failed with value np.float64(nan).\n",
      "[I 2025-11-03 08:36:20,479] Trial 44 finished with value: 0.7301318267419963 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 172, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 172, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 172, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:20,621] Trial 45 failed with parameters: {'n_neighbors': 172, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:20,621] Trial 45 failed with value np.float64(nan).\n",
      "[I 2025-11-03 08:36:20,770] Trial 46 finished with value: 0.7077212806026365 and parameters: {'n_neighbors': 10, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:20,899] Trial 47 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:21,029] Trial 48 finished with value: 0.6966101694915254 and parameters: {'n_neighbors': 6, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:21,159] Trial 49 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:21,286] Trial 50 finished with value: 0.7302259887005649 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 182, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 182, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 182, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:21,415] Trial 51 failed with parameters: {'n_neighbors': 182, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': None} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:21,416] Trial 51 failed with value np.float64(nan).\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 157, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 157, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 157, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:21,535] Trial 52 failed with parameters: {'n_neighbors': 157, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': None} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:21,535] Trial 52 failed with value np.float64(nan).\n",
      "[I 2025-11-03 08:36:21,673] Trial 53 finished with value: 0.6967043314500941 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:21,815] Trial 54 finished with value: 0.702165725047081 and parameters: {'n_neighbors': 12, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:21,966] Trial 55 finished with value: 0.713276836158192 and parameters: {'n_neighbors': 7, 'p': 1, 'weights': 'distance', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 7}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:22,108] Trial 56 finished with value: 0.7467043314500942 and parameters: {'n_neighbors': 1, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 191, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 191, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 191, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:22,250] Trial 57 failed with parameters: {'n_neighbors': 191, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 9} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:22,252] Trial 57 failed with value np.float64(nan).\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 145, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 145, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 145, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:22,391] Trial 58 failed with parameters: {'n_neighbors': 145, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 9} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:22,391] Trial 58 failed with value np.float64(nan).\n",
      "[I 2025-11-03 08:36:22,549] Trial 59 finished with value: 0.7358757062146891 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 9}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:22,686] Trial 60 finished with value: 0.7357815442561205 and parameters: {'n_neighbors': 9, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:22,816] Trial 61 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:22,953] Trial 62 finished with value: 0.6966101694915254 and parameters: {'n_neighbors': 6, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:23,082] Trial 63 finished with value: 0.7302259887005649 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:23,215] Trial 64 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:23,333] Trial 65 finished with value: 0.7020715630885123 and parameters: {'n_neighbors': 13, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 134, n_samples_fit = 118, n_samples = 60\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 134, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 789, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 134, n_samples_fit = 119, n_samples = 59\n",
      "\n",
      "  warnings.warn(\n",
      "[W 2025-11-03 08:36:23,464] Trial 66 failed with parameters: {'n_neighbors': 134, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-03 08:36:23,464] Trial 66 failed with value np.float64(nan).\n",
      "[I 2025-11-03 08:36:23,579] Trial 67 finished with value: 0.7303201506591336 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:23,697] Trial 68 finished with value: 0.7303201506591336 and parameters: {'n_neighbors': 22, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:23,843] Trial 69 finished with value: 0.6573446327683615 and parameters: {'n_neighbors': 189, 'p': 1, 'weights': 'uniform', 'normalization': None, 'treatment': 'pca', 'pca_components': 4}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:23,985] Trial 70 finished with value: 0.7133709981167607 and parameters: {'n_neighbors': 7, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:24,112] Trial 71 finished with value: 0.6740112994350281 and parameters: {'n_neighbors': 30, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:24,239] Trial 72 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:24,358] Trial 73 finished with value: 0.7302259887005649 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:24,553] Trial 74 finished with value: 0.6966101694915254 and parameters: {'n_neighbors': 6, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:24,683] Trial 75 finished with value: 0.7189265536723163 and parameters: {'n_neighbors': 9, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:24,798] Trial 76 finished with value: 0.7245762711864406 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:24,945] Trial 77 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 6}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:25,078] Trial 78 finished with value: 0.7020715630885123 and parameters: {'n_neighbors': 13, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:25,205] Trial 79 finished with value: 0.7412429378531074 and parameters: {'n_neighbors': 7, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:25,337] Trial 80 finished with value: 0.7415254237288136 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:25,488] Trial 81 finished with value: 0.6742937853107344 and parameters: {'n_neighbors': 9, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 2}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:25,626] Trial 82 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:25,761] Trial 83 finished with value: 0.6966101694915254 and parameters: {'n_neighbors': 6, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:25,880] Trial 84 finished with value: 0.7302259887005649 and parameters: {'n_neighbors': 4, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:26,015] Trial 85 finished with value: 0.7526365348399247 and parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:26,132] Trial 86 finished with value: 0.7134651600753296 and parameters: {'n_neighbors': 8, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:26,261] Trial 87 finished with value: 0.6911487758945386 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': None, 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:26,380] Trial 88 finished with value: 0.7133709981167607 and parameters: {'n_neighbors': 7, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:26,513] Trial 89 finished with value: 0.7191148775894538 and parameters: {'n_neighbors': 6, 'p': 2, 'weights': 'uniform', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 8}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:26,634] Trial 90 finished with value: 0.7189265536723163 and parameters: {'n_neighbors': 10, 'p': 2, 'weights': 'distance', 'normalization': 'standard', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:26,756] Trial 91 finished with value: 0.7527306967984936 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:26,866] Trial 92 finished with value: 0.7527306967984936 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:26,999] Trial 93 finished with value: 0.7527306967984936 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:27,111] Trial 94 finished with value: 0.7302259887005649 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:27,231] Trial 95 finished with value: 0.7527306967984936 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:27,358] Trial 96 finished with value: 0.7527306967984936 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:27,463] Trial 97 finished with value: 0.7527306967984936 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:27,589] Trial 98 finished with value: 0.7527306967984936 and parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n",
      "[I 2025-11-03 08:36:27,715] Trial 99 finished with value: 0.7302259887005649 and parameters: {'n_neighbors': 2, 'p': 2, 'weights': 'uniform', 'normalization': 'maxabs', 'treatment': None}. Best is trial 4 with value: 0.7807909604519775.\n"
     ]
    }
   ],
   "source": [
    "study_knn.optimize(parcial_knn, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07227716-336a-4a31-8476-4068c93b40c1",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "205f7562-1bfe-41dc-9b3c-ba714bf8f2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 4\n",
      "Parâmetros do melhor trial: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}\n"
     ]
    }
   ],
   "source": [
    "resultado_knn = study_knn.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_knn.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_knn.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b97c8-4b17-479e-95c4-d7668def0dae",
   "metadata": {},
   "source": [
    "## Otimizando um modelo Support Vector Machine Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d9f4b-c9fb-42cc-b928-25f84d57ce5c",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7750a047-ffdb-4071-a382-db842e5c4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_svc(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador SVC\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),  \n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "            \"gamma\": trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]),\n",
    "            \"degree\": trial.suggest_int(\"degree\", 1, 5), \n",
    "            \"coef0\": trial.suggest_float(\"coef0\", 0.0, 1.0), \n",
    "            \"max_iter\": 10000,\n",
    "        }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Instânciando o modelo\n",
    "    modelo = SVC(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db3cd2-dd5b-4d04-b8b4-af0db33116c5",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8490e3c2-09ee-4a2a-8d1a-5e7cac1e26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_svc(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_svc(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"accuracy\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afaf93a-ea28-4931-a801-371cc3bd8a94",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ef6ca8-c394-4a91-9d04-fbe5a0315041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:36:28,052] A new study created in RDB with name: Estudo SVC\n"
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_svc = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo SVC\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo SVC\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1fe31-375a-4a90-a15e-b98aa037954d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4fedd73-9c4b-4551-87ac-48452889cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": None,\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos \n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"minmax\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"maxabs\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_svc.enqueue_trial(\n",
    "    {\n",
    "        \"C\": 1,  \n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"degree\": 3, \n",
    "        \"coef0\": 0.0, \n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"pca\",\n",
    "        \"pca_components\": 9\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d0aa5-9182-48ce-b33d-08f1f96d008d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd4c3cf-9799-4ea6-8a95-e4855f2f289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_svc(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_svc(trial, x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53449ffd-1c08-447d-8926-66c2b93e3b06",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4a66071-3bc0-4c6d-882f-53d003097313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:36:28,310] Trial 0 finished with value: 0.6573446327683615 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.6573446327683615.\n",
      "[I 2025-11-03 08:36:28,445] Trial 1 finished with value: 0.8032956685499059 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': 'standard', 'treatment': None}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:28,588] Trial 2 finished with value: 0.7977401129943503 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': 'minmax', 'treatment': None}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:28,726] Trial 3 finished with value: 0.7751412429378531 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': 'maxabs', 'treatment': None}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:28,875] Trial 4 finished with value: 0.8032956685499059 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.0, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:29,031] Trial 5 finished with value: 0.8032956685499059 and parameters: {'C': 2.4493001571788646, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.5378217736616707, 'normalization': 'standard', 'treatment': None}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:29,176] Trial 6 finished with value: 0.7976459510357815 and parameters: {'C': 11.6606669307766, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 4, 'coef0': 0.03971795120464128, 'normalization': 'maxabs', 'treatment': None}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:29,333] Trial 7 finished with value: 0.7693032015065914 and parameters: {'C': 55.412653176159644, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2, 'coef0': 0.6569021750500857, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 4}. Best is trial 1 with value: 0.8032956685499059.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 08:36:29,492] Trial 8 finished with value: 0.6401129943502825 and parameters: {'C': 111.09636048614239, 'kernel': 'linear', 'gamma': 'auto', 'degree': 4, 'coef0': 0.32771582305087354, 'normalization': None, 'treatment': None}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:29,645] Trial 9 finished with value: 0.6573446327683615 and parameters: {'C': 0.006954236502141605, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.6662269588881862, 'normalization': 'maxabs', 'treatment': None}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:29,830] Trial 10 finished with value: 0.6573446327683615 and parameters: {'C': 0.02424699470800675, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 1, 'coef0': 0.9383570297257943, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 2}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:30,096] Trial 11 finished with value: 0.6573446327683615 and parameters: {'C': 0.07170438497435508, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 2, 'coef0': 0.25678981393408623, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 1 with value: 0.8032956685499059.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 08:36:30,266] Trial 12 finished with value: 0.7918079096045197 and parameters: {'C': 809.7830210241858, 'kernel': 'linear', 'gamma': 'scale', 'degree': 4, 'coef0': 0.22793365500325907, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:30,440] Trial 13 finished with value: 0.6797551789077213 and parameters: {'C': 0.11117177865975583, 'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 3, 'coef0': 0.14435530520684384, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:30,604] Trial 14 finished with value: 0.6573446327683615 and parameters: {'C': 0.0018875724352524787, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 1, 'coef0': 0.4123744434800423, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 6}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:30,764] Trial 15 finished with value: 0.8029190207156308 and parameters: {'C': 6.744411701907882, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 5, 'coef0': 0.15067478083878974, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:30,918] Trial 16 finished with value: 0.6629943502824859 and parameters: {'C': 0.1541954918017107, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 2, 'coef0': 0.9475183452123392, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 4}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:31,040] Trial 17 finished with value: 0.7301318267419963 and parameters: {'C': 0.28443772461072203, 'kernel': 'linear', 'gamma': 'scale', 'degree': 4, 'coef0': 0.15384087526943194, 'normalization': 'minmax', 'treatment': None}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:31,196] Trial 18 finished with value: 0.6573446327683615 and parameters: {'C': 16.432305829467847, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 4, 'coef0': 0.40166317343709484, 'normalization': None, 'treatment': 'pca', 'pca_components': 8}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:31,343] Trial 19 finished with value: 0.6573446327683615 and parameters: {'C': 0.02192665011127463, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 2, 'coef0': 0.8186413941510857, 'normalization': 'standard', 'treatment': None}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:31,494] Trial 20 finished with value: 0.7246704331450093 and parameters: {'C': 0.42073870117044315, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3, 'coef0': 0.11961122274472137, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 1 with value: 0.8032956685499059.\n",
      "[I 2025-11-03 08:36:31,627] Trial 21 finished with value: 0.8088512241054614 and parameters: {'C': 3.6115533822297543, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.5787200197898124, 'normalization': 'standard', 'treatment': None}. Best is trial 21 with value: 0.8088512241054614.\n",
      "[I 2025-11-03 08:36:31,770] Trial 22 finished with value: 0.8145009416195856 and parameters: {'C': 4.851946167429181, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.556912247132337, 'normalization': 'standard', 'treatment': None}. Best is trial 22 with value: 0.8145009416195856.\n",
      "[I 2025-11-03 08:36:31,913] Trial 23 finished with value: 0.803201506591337 and parameters: {'C': 5.6952996677420185, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.5760242296020768, 'normalization': 'standard', 'treatment': None}. Best is trial 22 with value: 0.8145009416195856.\n",
      "[I 2025-11-03 08:36:32,055] Trial 24 finished with value: 0.7974576271186441 and parameters: {'C': 42.08746149977072, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.7604339629700428, 'normalization': 'standard', 'treatment': None}. Best is trial 22 with value: 0.8145009416195856.\n",
      "[I 2025-11-03 08:36:32,193] Trial 25 finished with value: 0.7974576271186441 and parameters: {'C': 266.64264333249355, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.46625629371173544, 'normalization': 'standard', 'treatment': None}. Best is trial 22 with value: 0.8145009416195856.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 08:36:32,338] Trial 26 finished with value: 0.4831450094161958 and parameters: {'C': 3.490555298622557, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.6215931392489411, 'normalization': None, 'treatment': None}. Best is trial 22 with value: 0.8145009416195856.\n",
      "[I 2025-11-03 08:36:32,483] Trial 27 finished with value: 0.8145009416195857 and parameters: {'C': 23.692653341533042, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.7628535566544512, 'normalization': 'minmax', 'treatment': None}. Best is trial 27 with value: 0.8145009416195857.\n",
      "[I 2025-11-03 08:36:32,626] Trial 28 finished with value: 0.8201506591337101 and parameters: {'C': 29.534086463143247, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.75110030932828, 'normalization': 'minmax', 'treatment': None}. Best is trial 28 with value: 0.8201506591337101.\n",
      "[I 2025-11-03 08:36:32,783] Trial 29 finished with value: 0.8258003766478343 and parameters: {'C': 33.960116877665044, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.7569772055033507, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 08:36:32,933] Trial 30 finished with value: 0.803201506591337 and parameters: {'C': 242.7904086247145, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.8353040137606593, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:33,078] Trial 31 finished with value: 0.7975517890772128 and parameters: {'C': 19.2669594860397, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.7281945324751059, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:33,221] Trial 32 finished with value: 0.8201506591337101 and parameters: {'C': 35.810086119842694, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.8594002241433218, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:33,377] Trial 33 finished with value: 0.7862523540489642 and parameters: {'C': 37.47801338456369, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'coef0': 0.8556345249064128, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:33,506] Trial 34 finished with value: 0.7919020715630886 and parameters: {'C': 122.58364150855792, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.8941237880538582, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:33,665] Trial 35 finished with value: 0.803201506591337 and parameters: {'C': 89.64391097664274, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.7498877974053165, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 08:36:33,810] Trial 36 finished with value: 0.7919020715630886 and parameters: {'C': 660.7635051260486, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'coef0': 0.7763179076920717, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:33,957] Trial 37 finished with value: 0.8088512241054615 and parameters: {'C': 24.293680047837267, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.6959092982592398, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 08:36:34,100] Trial 38 finished with value: 0.7975517890772128 and parameters: {'C': 357.9293261587755, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'coef0': 0.9809402948472457, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:34,250] Trial 39 finished with value: 0.8145009416195857 and parameters: {'C': 1.3666643318023741, 'kernel': 'linear', 'gamma': 'auto', 'degree': 5, 'coef0': 0.8862284952891798, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:34,398] Trial 40 finished with value: 0.7862523540489642 and parameters: {'C': 11.477457549829632, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.8132582811053506, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:34,550] Trial 41 finished with value: 0.8145951035781543 and parameters: {'C': 1.5457453177124192, 'kernel': 'linear', 'gamma': 'auto', 'degree': 5, 'coef0': 0.9060028895869822, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:34,694] Trial 42 finished with value: 0.7974576271186441 and parameters: {'C': 69.89541679236706, 'kernel': 'linear', 'gamma': 'auto', 'degree': 5, 'coef0': 0.9930598105424436, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:34,868] Trial 43 finished with value: 0.7864406779661017 and parameters: {'C': 2.1010843615384016, 'kernel': 'linear', 'gamma': 'auto', 'degree': 5, 'coef0': 0.911291258914263, 'normalization': 'maxabs', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:35,118] Trial 44 finished with value: 0.7919962335216573 and parameters: {'C': 10.275794611589376, 'kernel': 'linear', 'gamma': 'auto', 'degree': 4, 'coef0': 0.7186988942220085, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:35,386] Trial 45 finished with value: 0.6573446327683615 and parameters: {'C': 0.4916949521963113, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 5, 'coef0': 0.6426741661683739, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:35,719] Trial 46 finished with value: 0.8031073446327683 and parameters: {'C': 148.38857044402852, 'kernel': 'linear', 'gamma': 'auto', 'degree': 4, 'coef0': 0.7895635714610167, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:35,999] Trial 47 finished with value: 0.8030131826741996 and parameters: {'C': 33.67268004181175, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5, 'coef0': 0.8616846028488728, 'normalization': 'maxabs', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:36,238] Trial 48 finished with value: 0.8087570621468926 and parameters: {'C': 63.76530115443777, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.6885427893960396, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:36,492] Trial 49 finished with value: 0.5567796610169492 and parameters: {'C': 9.551965825573573, 'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 4, 'coef0': 0.9417768041801513, 'normalization': None, 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:36,745] Trial 50 finished with value: 0.8145951035781543 and parameters: {'C': 1.8700651612994104, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.6089732695735914, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:37,014] Trial 51 finished with value: 0.8145009416195857 and parameters: {'C': 1.3662089469860683, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.6109888865820626, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:37,283] Trial 52 finished with value: 0.8031073446327683 and parameters: {'C': 23.99271900583932, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.49759977936092314, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:37,552] Trial 53 finished with value: 0.8145951035781543 and parameters: {'C': 2.3136528997415686, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.7987823013328796, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:37,817] Trial 54 finished with value: 0.792090395480226 and parameters: {'C': 0.6413884890432798, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.8018343495506284, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:38,055] Trial 55 finished with value: 0.8202448210922787 and parameters: {'C': 2.2670099177978726, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.6661318055746623, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:38,321] Trial 56 finished with value: 0.6909604519774012 and parameters: {'C': 0.2004025701655476, 'kernel': 'linear', 'gamma': 'scale', 'degree': 4, 'coef0': 0.6711646280989942, 'normalization': 'maxabs', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:38,555] Trial 57 finished with value: 0.6573446327683615 and parameters: {'C': 0.06285050518152326, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.5262109498102872, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:38,828] Trial 58 finished with value: 0.6799435028248587 and parameters: {'C': 5.403722241532571, 'kernel': 'linear', 'gamma': 'auto', 'degree': 1, 'coef0': 0.7211067935321717, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 2}. Best is trial 29 with value: 0.8258003766478343.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 08:36:39,110] Trial 59 finished with value: 0.6349340866290017 and parameters: {'C': 0.8387789669565676, 'kernel': 'linear', 'gamma': 'scale', 'degree': 3, 'coef0': 0.605688293989675, 'normalization': None, 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:39,411] Trial 60 finished with value: 0.6741054613935971 and parameters: {'C': 2.838056765450162, 'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 5, 'coef0': 0.8573916752021067, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:39,686] Trial 61 finished with value: 0.8145009416195857 and parameters: {'C': 1.404705668984066, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.8285074713533426, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:39,933] Trial 62 finished with value: 0.7919962335216573 and parameters: {'C': 7.409904494368002, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.6473385398170863, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:40,202] Trial 63 finished with value: 0.8145951035781543 and parameters: {'C': 2.1521232967791106, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.751148598250694, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:40,508] Trial 64 finished with value: 0.8031073446327683 and parameters: {'C': 13.943661488941103, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.9082638579433702, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:40,797] Trial 65 finished with value: 0.7301318267419963 and parameters: {'C': 0.2925993819528813, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.7053042655493029, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:41,102] Trial 66 finished with value: 0.6854048964218457 and parameters: {'C': 1.6629340354734785, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 5, 'coef0': 0.7940623182374116, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 3}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:41,377] Trial 67 finished with value: 0.8089453860640301 and parameters: {'C': 3.897856013142474, 'kernel': 'linear', 'gamma': 'scale', 'degree': 4, 'coef0': 0.950669625583687, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 08:36:41,657] Trial 68 finished with value: 0.5671374764595104 and parameters: {'C': 0.9794956243623006, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5, 'coef0': 0.8795225098840388, 'normalization': None, 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:41,928] Trial 69 finished with value: 0.8200564971751412 and parameters: {'C': 43.21460084456194, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.677211450591173, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:42,203] Trial 70 finished with value: 0.8145009416195856 and parameters: {'C': 49.518183888878276, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.5849440614639811, 'normalization': 'maxabs', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:42,459] Trial 71 finished with value: 0.8144067796610169 and parameters: {'C': 17.239385436253155, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.670269483078215, 'normalization': 'minmax', 'treatment': None}. Best is trial 29 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:36:42,726] Trial 72 finished with value: 0.8312617702448212 and parameters: {'C': 206.27614143507694, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.7403239728651216, 'normalization': 'minmax', 'treatment': None}. Best is trial 72 with value: 0.8312617702448212.\n",
      "[I 2025-11-03 08:36:42,965] Trial 73 finished with value: 0.8368173258003767 and parameters: {'C': 188.86917045678857, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.6328681631091934, 'normalization': 'minmax', 'treatment': None}. Best is trial 73 with value: 0.8368173258003767.\n",
      "[I 2025-11-03 08:36:43,219] Trial 74 finished with value: 0.8369114877589454 and parameters: {'C': 185.00662135271045, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.6473030721924317, 'normalization': 'minmax', 'treatment': None}. Best is trial 74 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:36:43,475] Trial 75 finished with value: 0.8257062146892656 and parameters: {'C': 494.8979283746556, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.74008471313536, 'normalization': 'minmax', 'treatment': None}. Best is trial 74 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:36:43,756] Trial 76 finished with value: 0.8087570621468926 and parameters: {'C': 464.3021780283088, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.7382400703643046, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 74 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:36:44,007] Trial 77 finished with value: 0.842467043314501 and parameters: {'C': 166.8503046225751, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.6379351844445164, 'normalization': 'minmax', 'treatment': None}. Best is trial 77 with value: 0.842467043314501.\n",
      "[I 2025-11-03 08:36:44,277] Trial 78 finished with value: 0.8087570621468926 and parameters: {'C': 184.23029504291833, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.5419399113632686, 'normalization': 'minmax', 'treatment': None}. Best is trial 77 with value: 0.842467043314501.\n",
      "[I 2025-11-03 08:36:44,554] Trial 79 finished with value: 0.8425612052730697 and parameters: {'C': 789.1080195648531, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.4160506093597419, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:44,785] Trial 80 finished with value: 0.8256120527306968 and parameters: {'C': 941.4110010313456, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.40944929018877013, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:45,049] Trial 81 finished with value: 0.8256120527306968 and parameters: {'C': 916.5024934391528, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.345355841890581, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:45,300] Trial 82 finished with value: 0.8256120527306968 and parameters: {'C': 977.5457137322605, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.3570064420157204, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:45,569] Trial 83 finished with value: 0.8087570621468926 and parameters: {'C': 596.8621010707723, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.297166593637732, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:45,855] Trial 84 finished with value: 0.8087570621468926 and parameters: {'C': 308.46626839651833, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.4272466550325895, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:46,129] Trial 85 finished with value: 0.8200564971751413 and parameters: {'C': 426.19141165156776, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.37531825961470383, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:46,440] Trial 86 finished with value: 0.8087570621468926 and parameters: {'C': 217.31568997563554, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.44672454902759184, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:46,696] Trial 87 finished with value: 0.8200564971751413 and parameters: {'C': 650.9093724340604, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.2896774498334648, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\joaquim25018\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-11-03 08:36:46,993] Trial 88 finished with value: 0.6064030131826742 and parameters: {'C': 90.66414539228128, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.49075849976938757, 'normalization': None, 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:47,294] Trial 89 finished with value: 0.8088512241054614 and parameters: {'C': 158.63664002606077, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.3940873974150465, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:47,563] Trial 90 finished with value: 0.8144067796610169 and parameters: {'C': 781.954143793283, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.3361185158232648, 'normalization': 'maxabs', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:47,847] Trial 91 finished with value: 0.8087570621468926 and parameters: {'C': 492.0550212945725, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.30614201816183173, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:48,094] Trial 92 finished with value: 0.8312617702448212 and parameters: {'C': 998.7987168188695, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.20624095521854194, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:48,349] Trial 93 finished with value: 0.8199623352165726 and parameters: {'C': 994.1447711630018, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.24789844657559654, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:48,616] Trial 94 finished with value: 0.8200564971751412 and parameters: {'C': 372.84552582124996, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.062352017736963306, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:48,875] Trial 95 finished with value: 0.8087570621468926 and parameters: {'C': 242.9295105758945, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2, 'coef0': 0.4649128440956013, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:49,155] Trial 96 finished with value: 0.8199623352165725 and parameters: {'C': 131.7088450890196, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3, 'coef0': 0.5214134255612994, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:49,420] Trial 97 finished with value: 0.8088512241054614 and parameters: {'C': 279.079056581745, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.21957382870917136, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:49,690] Trial 98 finished with value: 0.8258003766478343 and parameters: {'C': 555.402920033063, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.6294503510917316, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n",
      "[I 2025-11-03 08:36:49,972] Trial 99 finished with value: 0.8258003766478343 and parameters: {'C': 589.3046171330936, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.6271121792272779, 'normalization': 'minmax', 'treatment': None}. Best is trial 79 with value: 0.8425612052730697.\n"
     ]
    }
   ],
   "source": [
    "study_svc.optimize(parcial_svc, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77defc-89f8-4790-9e30-93c7d27c01e3",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f3cd1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3849ad86-53d0-44d5-8a09-4b8e2645dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 79\n",
      "Parâmetros do melhor trial: {'C': 789.1080195648531, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5, 'coef0': 0.4160506093597419, 'normalization': 'minmax', 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "resultado_svc = study_svc.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_svc.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_svc.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685e968-3a8e-4710-821f-ad41e0688f46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo de Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab93d6-efb1-4f8f-bbbf-d2982b4864a9",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b40cd75b-8030-40ca-99c5-e52a183a381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_lrc(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador por Regressão Logística\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "        \"C\": trial.suggest_float(\"C\", 0.01, 10.0, log=True),\n",
    "        \"class_weight\": trial.suggest_categorical(\"class_weight\", [\"balanced\", None]),\n",
    "        \"solver\":\"liblinear\",\n",
    "        \"max_iter\":5000,\n",
    "        \"random_state\":semente\n",
    "    }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\", \"rfe\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Adiciona tratamento RFE \n",
    "    elif treatment == \"rfe\": \n",
    "        # Definindo o estimador \n",
    "        estimator = LogisticRegression(**params)\n",
    "        # Definindo o número de atributos a serem mantidos\n",
    "        n_features_to_select = trial.suggest_int(\"rfe_features\", 2, 9)\n",
    "        steps.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "        \n",
    "    # Instânciando o modelo\n",
    "    modelo = LogisticRegression(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624a53c-a08a-4082-a23f-ab641655ba20",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fec90b1-1e1d-4d61-aa8b-c5915e784551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_lrc(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_lrc(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"accuracy\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133736b-3e5e-4435-8b09-e23719c5e8b9",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d27304a0-418e-437a-b0a1-b08a2a34e361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:36:50,516] A new study created in RDB with name: Estudo LRC\n"
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_lrc = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo LRC\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo LRC\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748ee444-879e-4583-85a4-25adce2dca42",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd38c992-f6a6-4668-91f7-44f3525a4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "        \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": None,\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Modelo base com normalização padrão\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "        \"penalty\": \"l2\",  \n",
    "        \"C\": 1, \n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos \n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "        \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None, \n",
    "        \"normalization\": \"minmax\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "       \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"maxabs\",\n",
    "        \"treatment\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "       \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"pca\",\n",
    "        \"pca_components\": 9\n",
    "    }\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e RFE\n",
    "study_lrc.enqueue_trial(\n",
    "    {\n",
    "       \"penalty\": \"l2\",  \n",
    "        \"C\": 1,\n",
    "        \"class_weight\": None,\n",
    "        \"normalization\": \"standard\",\n",
    "        \"treatment\": \"rfe\",\n",
    "        \"rfe_features\": 9\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93441716-6195-4888-9fd2-0b9e4ce579eb",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd0ca875-a854-400c-88dd-50e0455744ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_lrc(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_lrc(trial, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c5de3-69b3-4342-9b72-884bd4e6718e",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df458bda-0f0f-47f9-9e62-0fef8830dd45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:36:50,882] Trial 0 finished with value: 0.8029190207156308 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.8029190207156308.\n",
      "[I 2025-11-03 08:36:51,100] Trial 1 finished with value: 0.7974576271186441 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.8029190207156308.\n",
      "[I 2025-11-03 08:36:51,316] Trial 2 finished with value: 0.7975517890772128 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 0 with value: 0.8029190207156308.\n",
      "[I 2025-11-03 08:36:51,522] Trial 3 finished with value: 0.7918079096045197 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'maxabs', 'treatment': None}. Best is trial 0 with value: 0.8029190207156308.\n",
      "[I 2025-11-03 08:36:51,761] Trial 4 finished with value: 0.7974576271186441 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 0 with value: 0.8029190207156308.\n",
      "[I 2025-11-03 08:36:51,987] Trial 5 finished with value: 0.7974576271186441 and parameters: {'penalty': 'l2', 'C': 1, 'class_weight': None, 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 9}. Best is trial 0 with value: 0.8029190207156308.\n",
      "[I 2025-11-03 08:36:52,237] Trial 6 finished with value: 0.7694915254237289 and parameters: {'penalty': 'l1', 'C': 0.10135437013118884, 'class_weight': None, 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 9}. Best is trial 0 with value: 0.8029190207156308.\n",
      "[I 2025-11-03 08:36:52,426] Trial 7 finished with value: 0.7412429378531074 and parameters: {'penalty': 'l2', 'C': 0.4025432909183379, 'class_weight': None, 'normalization': 'maxabs', 'treatment': None}. Best is trial 0 with value: 0.8029190207156308.\n",
      "[I 2025-11-03 08:36:52,658] Trial 8 finished with value: 0.7977401129943503 and parameters: {'penalty': 'l2', 'C': 0.048563369418247244, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 0 with value: 0.8029190207156308.\n",
      "[I 2025-11-03 08:36:52,867] Trial 9 finished with value: 0.8087570621468926 and parameters: {'penalty': 'l2', 'C': 4.33630848035013, 'class_weight': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 9 with value: 0.8087570621468926.\n",
      "[I 2025-11-03 08:36:53,086] Trial 10 finished with value: 0.5563088512241054 and parameters: {'penalty': 'l1', 'C': 8.595935726165484, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 2}. Best is trial 9 with value: 0.8087570621468926.\n",
      "[I 2025-11-03 08:36:53,341] Trial 11 finished with value: 0.8031073446327683 and parameters: {'penalty': 'l1', 'C': 7.41860018002455, 'class_weight': 'balanced', 'normalization': None, 'treatment': None}. Best is trial 9 with value: 0.8087570621468926.\n",
      "[I 2025-11-03 08:36:53,613] Trial 12 finished with value: 0.8031073446327683 and parameters: {'penalty': 'l1', 'C': 9.607064276244454, 'class_weight': 'balanced', 'normalization': None, 'treatment': None}. Best is trial 9 with value: 0.8087570621468926.\n",
      "[I 2025-11-03 08:36:53,801] Trial 13 finished with value: 0.7974576271186441 and parameters: {'penalty': 'l1', 'C': 4.193083946758372, 'class_weight': 'balanced', 'normalization': None, 'treatment': None}. Best is trial 9 with value: 0.8087570621468926.\n",
      "[I 2025-11-03 08:36:54,126] Trial 14 finished with value: 0.7977401129943503 and parameters: {'penalty': 'l1', 'C': 3.371259051373558, 'class_weight': 'balanced', 'normalization': None, 'treatment': 'rfe', 'rfe_features': 2}. Best is trial 9 with value: 0.8087570621468926.\n",
      "[I 2025-11-03 08:36:54,352] Trial 15 finished with value: 0.6573446327683615 and parameters: {'penalty': 'l1', 'C': 0.015268913314869747, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 9 with value: 0.8087570621468926.\n",
      "[I 2025-11-03 08:36:54,571] Trial 16 finished with value: 0.7974576271186441 and parameters: {'penalty': 'l1', 'C': 3.6823165854330626, 'class_weight': 'balanced', 'normalization': None, 'treatment': None}. Best is trial 9 with value: 0.8087570621468926.\n",
      "[I 2025-11-03 08:36:54,761] Trial 17 finished with value: 0.814406779661017 and parameters: {'penalty': 'l1', 'C': 2.6359084854883403, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 17 with value: 0.814406779661017.\n",
      "[I 2025-11-03 08:36:54,999] Trial 18 finished with value: 0.7977401129943503 and parameters: {'penalty': 'l2', 'C': 0.2625404450385299, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 9}. Best is trial 17 with value: 0.814406779661017.\n",
      "[I 2025-11-03 08:36:55,253] Trial 19 finished with value: 0.7865348399246704 and parameters: {'penalty': 'l1', 'C': 2.9133188414030444, 'class_weight': None, 'normalization': 'minmax', 'treatment': 'rfe', 'rfe_features': 2}. Best is trial 17 with value: 0.814406779661017.\n",
      "[I 2025-11-03 08:36:55,481] Trial 20 finished with value: 0.7471751412429378 and parameters: {'penalty': 'l2', 'C': 0.38743049719170736, 'class_weight': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 17 with value: 0.814406779661017.\n",
      "[I 2025-11-03 08:36:55,700] Trial 21 finished with value: 0.8199623352165726 and parameters: {'penalty': 'l1', 'C': 1.9889331662468657, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 21 with value: 0.8199623352165726.\n",
      "[I 2025-11-03 08:36:55,900] Trial 22 finished with value: 0.8256120527306968 and parameters: {'penalty': 'l1', 'C': 2.125719379561687, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 22 with value: 0.8256120527306968.\n",
      "[I 2025-11-03 08:36:56,092] Trial 23 finished with value: 0.8256120527306968 and parameters: {'penalty': 'l1', 'C': 2.0367651392548587, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 22 with value: 0.8256120527306968.\n",
      "[I 2025-11-03 08:36:56,308] Trial 24 finished with value: 0.8256120527306968 and parameters: {'penalty': 'l1', 'C': 2.114333202695556, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 22 with value: 0.8256120527306968.\n",
      "[I 2025-11-03 08:36:56,550] Trial 25 finished with value: 0.8031073446327683 and parameters: {'penalty': 'l1', 'C': 1.6654143133793124, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': None}. Best is trial 22 with value: 0.8256120527306968.\n",
      "[I 2025-11-03 08:36:56,768] Trial 26 finished with value: 0.8257062146892654 and parameters: {'penalty': 'l1', 'C': 0.5563003981690311, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 26 with value: 0.8257062146892654.\n",
      "[I 2025-11-03 08:36:56,999] Trial 27 finished with value: 0.8088512241054614 and parameters: {'penalty': 'l1', 'C': 0.2144603880411522, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 26 with value: 0.8257062146892654.\n",
      "[I 2025-11-03 08:36:57,221] Trial 28 finished with value: 0.6177966101694915 and parameters: {'penalty': 'l1', 'C': 0.48976952694898784, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 2}. Best is trial 26 with value: 0.8257062146892654.\n",
      "[I 2025-11-03 08:36:57,490] Trial 29 finished with value: 0.5285310734463277 and parameters: {'penalty': 'l1', 'C': 0.14075335395578742, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 26 with value: 0.8257062146892654.\n",
      "[I 2025-11-03 08:36:57,681] Trial 30 finished with value: 0.8031073446327683 and parameters: {'penalty': 'l1', 'C': 0.599603601295671, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': None}. Best is trial 26 with value: 0.8257062146892654.\n",
      "[I 2025-11-03 08:36:57,903] Trial 31 finished with value: 0.8256120527306968 and parameters: {'penalty': 'l1', 'C': 1.650096316756639, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 26 with value: 0.8257062146892654.\n",
      "[I 2025-11-03 08:36:58,108] Trial 32 finished with value: 0.8199623352165725 and parameters: {'penalty': 'l1', 'C': 1.4841988831976793, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 26 with value: 0.8257062146892654.\n",
      "[I 2025-11-03 08:36:58,303] Trial 33 finished with value: 0.8257062146892654 and parameters: {'penalty': 'l1', 'C': 0.676660564305496, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 26 with value: 0.8257062146892654.\n",
      "[I 2025-11-03 08:36:58,522] Trial 34 finished with value: 0.8369114877589453 and parameters: {'penalty': 'l1', 'C': 0.6959163806033626, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 34 with value: 0.8369114877589453.\n",
      "[I 2025-11-03 08:36:58,743] Trial 35 finished with value: 0.831261770244821 and parameters: {'penalty': 'l1', 'C': 0.7697880806613723, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 34 with value: 0.8369114877589453.\n",
      "[I 2025-11-03 08:36:58,948] Trial 36 finished with value: 0.814406779661017 and parameters: {'penalty': 'l1', 'C': 0.7434853458237597, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8369114877589453.\n",
      "[I 2025-11-03 08:36:59,155] Trial 37 finished with value: 0.8369114877589453 and parameters: {'penalty': 'l1', 'C': 0.7391832332819428, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 34 with value: 0.8369114877589453.\n",
      "[I 2025-11-03 08:36:59,369] Trial 38 finished with value: 0.8313559322033898 and parameters: {'penalty': 'l1', 'C': 0.2165455904214367, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8369114877589453.\n",
      "[I 2025-11-03 08:36:59,638] Trial 39 finished with value: 0.7975517890772128 and parameters: {'penalty': 'l1', 'C': 0.08239080600358564, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 6}. Best is trial 34 with value: 0.8369114877589453.\n",
      "[I 2025-11-03 08:36:59,892] Trial 40 finished with value: 0.837005649717514 and parameters: {'penalty': 'l1', 'C': 0.18354553587797304, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:00,110] Trial 41 finished with value: 0.837005649717514 and parameters: {'penalty': 'l1', 'C': 0.17655672858844917, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:00,316] Trial 42 finished with value: 0.8369114877589454 and parameters: {'penalty': 'l1', 'C': 0.1635846038597857, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:00,523] Trial 43 finished with value: 0.7919020715630886 and parameters: {'penalty': 'l1', 'C': 0.06886531316943016, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:00,730] Trial 44 finished with value: 0.8144067796610169 and parameters: {'penalty': 'l2', 'C': 0.13299031359660402, 'class_weight': None, 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:00,968] Trial 45 finished with value: 0.6573446327683615 and parameters: {'penalty': 'l1', 'C': 0.034162815532621876, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 6}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:01,189] Trial 46 finished with value: 0.8257062146892654 and parameters: {'penalty': 'l1', 'C': 0.14108651088283605, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:01,412] Trial 47 finished with value: 0.8031073446327683 and parameters: {'penalty': 'l1', 'C': 0.34548035594707627, 'class_weight': None, 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:01,626] Trial 48 finished with value: 0.8144067796610169 and parameters: {'penalty': 'l2', 'C': 0.17357247654419944, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:01,913] Trial 49 finished with value: 0.7919020715630886 and parameters: {'penalty': 'l1', 'C': 0.04814636140206121, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'rfe', 'rfe_features': 5}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:02,135] Trial 50 finished with value: 0.8201506591337099 and parameters: {'penalty': 'l1', 'C': 0.26121030548590235, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:02,341] Trial 51 finished with value: 0.8257062146892654 and parameters: {'penalty': 'l1', 'C': 0.202415960271386, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:02,543] Trial 52 finished with value: 0.8201506591337099 and parameters: {'penalty': 'l1', 'C': 0.2634941635207179, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:02,721] Trial 53 finished with value: 0.8088512241054614 and parameters: {'penalty': 'l1', 'C': 0.10892614775398715, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:02,914] Trial 54 finished with value: 0.8144067796610169 and parameters: {'penalty': 'l1', 'C': 0.4433937337780647, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:03,141] Trial 55 finished with value: 0.7921845574387948 and parameters: {'penalty': 'l1', 'C': 0.9889401423751453, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 5}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:03,331] Trial 56 finished with value: 0.8087570621468926 and parameters: {'penalty': 'l2', 'C': 0.34572220919289803, 'class_weight': None, 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:03,521] Trial 57 finished with value: 0.8086629001883239 and parameters: {'penalty': 'l1', 'C': 0.09028438844697981, 'class_weight': 'balanced', 'normalization': None, 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:03,693] Trial 58 finished with value: 0.7919020715630886 and parameters: {'penalty': 'l1', 'C': 0.06096276382222412, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:03,885] Trial 59 finished with value: 0.8200564971751412 and parameters: {'penalty': 'l1', 'C': 0.1926358786300024, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:04,170] Trial 60 finished with value: 0.7748587570621468 and parameters: {'penalty': 'l1', 'C': 0.2816802059969154, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': 'rfe', 'rfe_features': 7}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:04,392] Trial 61 finished with value: 0.7862523540489642 and parameters: {'penalty': 'l1', 'C': 0.8841116749912534, 'class_weight': 'balanced', 'normalization': None, 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:04,613] Trial 62 finished with value: 0.814406779661017 and parameters: {'penalty': 'l1', 'C': 0.8262958972729282, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:04,832] Trial 63 finished with value: 0.8256120527306967 and parameters: {'penalty': 'l1', 'C': 1.3267115482832894, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:05,023] Trial 64 finished with value: 0.831261770244821 and parameters: {'penalty': 'l1', 'C': 1.1897365449829351, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:05,246] Trial 65 finished with value: 0.8087570621468926 and parameters: {'penalty': 'l1', 'C': 0.4845591409702558, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:05,468] Trial 66 finished with value: 0.7134651600753296 and parameters: {'penalty': 'l2', 'C': 0.22420034371533787, 'class_weight': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:05,676] Trial 67 finished with value: 0.689924670433145 and parameters: {'penalty': 'l1', 'C': 0.16446606391211627, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:05,897] Trial 68 finished with value: 0.5499999999999999 and parameters: {'penalty': 'l1', 'C': 0.11974548739027055, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:06,100] Trial 69 finished with value: 0.8145009416195856 and parameters: {'penalty': 'l1', 'C': 0.37169045700707776, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:06,332] Trial 70 finished with value: 0.8257062146892654 and parameters: {'penalty': 'l1', 'C': 0.5832365971747429, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:06,541] Trial 71 finished with value: 0.831261770244821 and parameters: {'penalty': 'l1', 'C': 1.1387813745896391, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:06,762] Trial 72 finished with value: 0.8256120527306967 and parameters: {'penalty': 'l1', 'C': 1.2392630741707429, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:07,001] Trial 73 finished with value: 0.8369114877589453 and parameters: {'penalty': 'l1', 'C': 0.7325665964963092, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:07,207] Trial 74 finished with value: 0.8313559322033898 and parameters: {'penalty': 'l1', 'C': 0.6834279220872159, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:07,415] Trial 75 finished with value: 0.8200564971751412 and parameters: {'penalty': 'l1', 'C': 0.6467445031021762, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:07,625] Trial 76 finished with value: 0.7919020715630886 and parameters: {'penalty': 'l1', 'C': 0.4480674305427646, 'class_weight': 'balanced', 'normalization': None, 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:07,848] Trial 77 finished with value: 0.6573446327683615 and parameters: {'penalty': 'l1', 'C': 0.010708770788096221, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:08,165] Trial 78 finished with value: 0.8033898305084746 and parameters: {'penalty': 'l1', 'C': 0.30042152617279283, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': 'rfe', 'rfe_features': 4}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:08,409] Trial 79 finished with value: 0.8143126177024481 and parameters: {'penalty': 'l2', 'C': 5.789540229813593, 'class_weight': None, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 4}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:08,624] Trial 80 finished with value: 0.8313559322033898 and parameters: {'penalty': 'l1', 'C': 0.5115190119103314, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:08,847] Trial 81 finished with value: 0.8257062146892654 and parameters: {'penalty': 'l1', 'C': 0.5306134878573567, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:09,078] Trial 82 finished with value: 0.8088512241054614 and parameters: {'penalty': 'l1', 'C': 0.22910735398862123, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:09,300] Trial 83 finished with value: 0.7027306967984934 and parameters: {'penalty': 'l1', 'C': 0.16367900679755548, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:09,538] Trial 84 finished with value: 0.8369114877589453 and parameters: {'penalty': 'l1', 'C': 0.7190155935520399, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:09,744] Trial 85 finished with value: 0.814406779661017 and parameters: {'penalty': 'l1', 'C': 0.7131581063476865, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:09,980] Trial 86 finished with value: 0.8256120527306967 and parameters: {'penalty': 'l1', 'C': 0.9252484112916092, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:10,188] Trial 87 finished with value: 0.8145009416195856 and parameters: {'penalty': 'l1', 'C': 0.33334334999331455, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:10,418] Trial 88 finished with value: 0.8256120527306967 and parameters: {'penalty': 'l1', 'C': 0.4200869868716335, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:10,625] Trial 89 finished with value: 0.814406779661017 and parameters: {'penalty': 'l1', 'C': 1.5767678719405054, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:10,832] Trial 90 finished with value: 0.4426553672316384 and parameters: {'penalty': 'l1', 'C': 0.12619795749946477, 'class_weight': 'balanced', 'normalization': 'maxabs', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:11,022] Trial 91 finished with value: 0.8257062146892654 and parameters: {'penalty': 'l1', 'C': 0.596399603267321, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:11,229] Trial 92 finished with value: 0.8256120527306967 and parameters: {'penalty': 'l1', 'C': 1.0469454042922666, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:11,435] Trial 93 finished with value: 0.8369114877589453 and parameters: {'penalty': 'l1', 'C': 0.7483695043287342, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:11,626] Trial 94 finished with value: 0.8369114877589453 and parameters: {'penalty': 'l1', 'C': 0.765992901655217, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:11,832] Trial 95 finished with value: 0.8200564971751412 and parameters: {'penalty': 'l1', 'C': 0.8337233641813776, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:12,093] Trial 96 finished with value: 0.8029190207156308 and parameters: {'penalty': 'l1', 'C': 0.15179834326839473, 'class_weight': None, 'normalization': None, 'treatment': 'rfe', 'rfe_features': 7}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:12,320] Trial 97 finished with value: 0.8144067796610169 and parameters: {'penalty': 'l2', 'C': 0.19590508866150247, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:12,569] Trial 98 finished with value: 0.6573446327683615 and parameters: {'penalty': 'l1', 'C': 0.09230429782162042, 'class_weight': 'balanced', 'normalization': 'minmax', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n",
      "[I 2025-11-03 08:37:12,823] Trial 99 finished with value: 0.8201506591337099 and parameters: {'penalty': 'l1', 'C': 0.24787897577640522, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}. Best is trial 40 with value: 0.837005649717514.\n"
     ]
    }
   ],
   "source": [
    "study_lrc.optimize(parcial_lrc, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c68dc-b533-4193-b524-3d11cee31a47",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a745ea7-5274-4bbe-85ba-b79e7e357abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 40\n",
      "Parâmetros do melhor trial: {'penalty': 'l1', 'C': 0.18354553587797304, 'class_weight': 'balanced', 'normalization': 'standard', 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "resultado_lrc = study_lrc.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_lrc.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_lrc.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab9a40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo de DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c569a36",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09d7cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_DecisionTree(trial): \n",
    "    \"\"\"Recebe um trial do optuna e retorna uma instância de um modelo com classificador por DecisionTree\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros do modelo \n",
    "    params = {\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\",\"entropy\",\"log_loss\"]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 32),\n",
    "        \"min_samples_split\": trial.suggest_float(\"min_samples_split\", 0.01, 1.0),\n",
    "        \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "        \"random_state\": semente\n",
    "    }\n",
    "\n",
    "    # Lista de etapas para o pipeline \n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "\n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade\n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Adiciona tratamento RFE \n",
    "    elif treatment == \"rfe\": \n",
    "        # Definindo o estimador \n",
    "        estimator = DecisionTreeClassifier(**params)\n",
    "        # Definindo o número de atributos a serem mantidos\n",
    "        n_features_to_select = trial.suggest_int(\"rfe_features\", 2, 9)\n",
    "        steps.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "        \n",
    "    # Instanciando o modelo\n",
    "    modelo = DecisionTreeClassifier(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3534cd1",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28f4799f-c3bd-4308-b4c4-fd3ec9e53bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_DecisionTree(trial, X_treino, Y_treino): \n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    # Instânciando o modelo \n",
    "    modelo = instanciador_DecisionTree(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    # Avaliando o modelo por Validação cruzada \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"accuracy\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b681b8d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e00b3e93-1eb6-44b5-8908-c2adc9717ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:37:13,330] A new study created in RDB with name: Estudo DecisionTree\n"
     ]
    }
   ],
   "source": [
    "# Criando o estudo\n",
    "study_DecisionTree = create_study(\n",
    "    # Tipo de otimização\n",
    "    direction=\"maximize\",\n",
    "    # Nome do estudo \n",
    "    study_name=\"Estudo DecisionTree\",\n",
    "    # Salvando o estudo em um arquivo\n",
    "    storage=f\"sqlite:///{\"Estudo DTC\"}.db\",\n",
    "    # Recupera o progresso salvo do estudo\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269fade3",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86da30fc-19cc-45c3-81c8-9eebb38c6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"treatment\": None\n",
    "}\n",
    ")\n",
    "\n",
    "# Modelo base com normalização padrão e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"normalization\": \"standard\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"normalization\": \"minmax\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"normalization\": \"maxabs\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675329b",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19b9addf-bec2-4bf4-919a-6b3a01ad35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_DecisionTree(trial): \n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_DecisionTree(trial, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1a913",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75c10ac9-758b-43b8-959f-21d36018f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:37:13,705] Trial 0 finished with value: 0.7195856873822976 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.7195856873822976.\n",
      "[I 2025-11-03 08:37:13,943] Trial 1 finished with value: 0.7073446327683616 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 0 with value: 0.7195856873822976.\n",
      "[I 2025-11-03 08:37:14,148] Trial 2 finished with value: 0.757909604519774 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 9}. Best is trial 2 with value: 0.757909604519774.\n",
      "[I 2025-11-03 08:37:14,354] Trial 3 finished with value: 0.7243879472693031 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 9}. Best is trial 2 with value: 0.757909604519774.\n",
      "[I 2025-11-03 08:37:14,544] Trial 4 finished with value: 0.6573446327683615 and parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 0.2149044589518982, 'min_samples_leaf': 0.4050803222798775, 'max_features': 'sqrt', 'normalization': 'maxabs', 'treatment': None}. Best is trial 2 with value: 0.757909604519774.\n",
      "[I 2025-11-03 08:37:14,772] Trial 5 finished with value: 0.6573446327683615 and parameters: {'criterion': 'log_loss', 'max_depth': 26, 'min_samples_split': 0.6128767205483338, 'min_samples_leaf': 0.30081213072981017, 'max_features': 'sqrt', 'normalization': None, 'treatment': 'pca', 'pca_components': 2}. Best is trial 2 with value: 0.757909604519774.\n",
      "[I 2025-11-03 08:37:14,981] Trial 6 finished with value: 0.6573446327683615 and parameters: {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 0.9480795417477764, 'min_samples_leaf': 0.3503435867897064, 'max_features': 'sqrt', 'normalization': 'maxabs', 'treatment': None}. Best is trial 2 with value: 0.757909604519774.\n",
      "[I 2025-11-03 08:37:15,157] Trial 7 finished with value: 0.6573446327683615 and parameters: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 0.24420772418961995, 'min_samples_leaf': 0.43960246746329806, 'max_features': 'sqrt', 'normalization': 'minmax', 'treatment': None}. Best is trial 2 with value: 0.757909604519774.\n",
      "[I 2025-11-03 08:37:15,364] Trial 8 finished with value: 0.8028248587570621 and parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 0.30231341837698583, 'min_samples_leaf': 0.02973070532787235, 'max_features': 'log2', 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:15,601] Trial 9 finished with value: 0.6290960451977402 and parameters: {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 0.8478922344122662, 'min_samples_leaf': 0.18110275754389105, 'max_features': 'sqrt', 'normalization': None, 'treatment': 'pca', 'pca_components': 6}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:15,815] Trial 10 finished with value: 0.6351224105461394 and parameters: {'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.43232182130669217, 'min_samples_leaf': 0.19591880961815955, 'max_features': 'log2', 'normalization': 'standard', 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:16,045] Trial 11 finished with value: 0.6573446327683615 and parameters: {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 0.38000021107526416, 'min_samples_leaf': 0.1640809346545236, 'max_features': 'log2', 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 6}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:16,267] Trial 12 finished with value: 0.7080037664783427 and parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 0.3039402938363824, 'min_samples_leaf': 0.12640647922405931, 'max_features': None, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 3}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:16,480] Trial 13 finished with value: 0.6796610169491526 and parameters: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 0.5767417804758128, 'min_samples_leaf': 0.02193298722905882, 'max_features': 'log2', 'normalization': 'minmax', 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:16,689] Trial 14 finished with value: 0.7748587570621468 and parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 0.03217756132108046, 'min_samples_leaf': 0.11437641733347978, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:16,893] Trial 15 finished with value: 0.7974576271186441 and parameters: {'criterion': 'log_loss', 'max_depth': 17, 'min_samples_split': 0.014966880055870213, 'min_samples_leaf': 0.10368540782207122, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:17,147] Trial 16 finished with value: 0.7297551789077213 and parameters: {'criterion': 'log_loss', 'max_depth': 19, 'min_samples_split': 0.6820700887829141, 'min_samples_leaf': 0.22353518153437288, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:17,401] Trial 17 finished with value: 0.6295668549905838 and parameters: {'criterion': 'log_loss', 'max_depth': 30, 'min_samples_split': 0.468052387618681, 'min_samples_leaf': 0.11718134477587319, 'max_features': 'log2', 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:17,655] Trial 18 finished with value: 0.7804143126177024 and parameters: {'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 0.30628328788960013, 'min_samples_leaf': 0.2666513913318088, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:17,908] Trial 19 finished with value: 0.7865348399246704 and parameters: {'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.1989387896780759, 'min_samples_leaf': 0.09538034406965121, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:18,252] Trial 20 finished with value: 0.6573446327683615 and parameters: {'criterion': 'log_loss', 'max_depth': 18, 'min_samples_split': 0.012645195265242284, 'min_samples_leaf': 0.49520842501284573, 'max_features': 'log2', 'normalization': 'standard', 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:18,505] Trial 21 finished with value: 0.7974576271186441 and parameters: {'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.1873854956366918, 'min_samples_leaf': 0.10251017194974445, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:18,774] Trial 22 finished with value: 0.7918079096045197 and parameters: {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.33618872609739486, 'min_samples_leaf': 0.018034919837461513, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:19,011] Trial 23 finished with value: 0.7865348399246704 and parameters: {'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.17809326540589612, 'min_samples_leaf': 0.09115390611164263, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:19,264] Trial 24 finished with value: 0.7918079096045197 and parameters: {'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 0.17202998741111203, 'min_samples_leaf': 0.15104802531782127, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:19,533] Trial 25 finished with value: 0.6295668549905838 and parameters: {'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.2736853214987583, 'min_samples_leaf': 0.08575835850775018, 'max_features': 'log2', 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:19,768] Trial 26 finished with value: 0.7695856873822976 and parameters: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 0.3864679347208916, 'min_samples_leaf': 0.010940481959424743, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:19,989] Trial 27 finished with value: 0.769114877589454 and parameters: {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.15912935375630896, 'min_samples_leaf': 0.23788601071792184, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:20,227] Trial 28 finished with value: 0.6295668549905838 and parameters: {'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 0.021488622093599807, 'min_samples_leaf': 0.14162281927736597, 'max_features': 'log2', 'normalization': 'maxabs', 'treatment': None}. Best is trial 8 with value: 0.8028248587570621.\n",
      "[I 2025-11-03 08:37:20,464] Trial 29 finished with value: 0.803201506591337 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.0797197576873463, 'min_samples_leaf': 0.07020156718599041, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 29 with value: 0.803201506591337.\n",
      "[I 2025-11-03 08:37:20,727] Trial 30 finished with value: 0.6513182674199623 and parameters: {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 0.06634149542534509, 'min_samples_leaf': 0.06526376159938435, 'max_features': 'log2', 'normalization': 'standard', 'treatment': None}. Best is trial 29 with value: 0.803201506591337.\n",
      "[I 2025-11-03 08:37:20,981] Trial 31 finished with value: 0.7865348399246704 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.13392866653464663, 'min_samples_leaf': 0.08598476963280563, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 29 with value: 0.803201506591337.\n",
      "[I 2025-11-03 08:37:21,228] Trial 32 finished with value: 0.803201506591337 and parameters: {'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.09471143403407402, 'min_samples_leaf': 0.05910812810018959, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 29 with value: 0.803201506591337.\n",
      "[I 2025-11-03 08:37:21,474] Trial 33 finished with value: 0.8200564971751413 and parameters: {'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 0.10104079421090238, 'min_samples_leaf': 0.05796652728353858, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 33 with value: 0.8200564971751413.\n",
      "[I 2025-11-03 08:37:21,758] Trial 34 finished with value: 0.8258003766478343 and parameters: {'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.11822332932827617, 'min_samples_leaf': 0.0530684395557626, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:22,015] Trial 35 finished with value: 0.8200564971751413 and parameters: {'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 0.10135540984374206, 'min_samples_leaf': 0.0532197488698204, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:22,298] Trial 36 finished with value: 0.7748587570621469 and parameters: {'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 0.12214647352150779, 'min_samples_leaf': 0.06113276896369324, 'max_features': None, 'normalization': 'maxabs', 'treatment': 'pca', 'pca_components': 4}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:22,592] Trial 37 finished with value: 0.8257062146892656 and parameters: {'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.07306896911420328, 'min_samples_leaf': 0.043725022752356506, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:22,863] Trial 38 finished with value: 0.6452919020715631 and parameters: {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.24500508636316726, 'min_samples_leaf': 0.04610983179297326, 'max_features': None, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 7}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:23,108] Trial 39 finished with value: 0.7297551789077213 and parameters: {'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.7443017317709878, 'min_samples_leaf': 0.3502712224241382, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:23,339] Trial 40 finished with value: 0.7974576271186441 and parameters: {'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.07000567117361041, 'min_samples_leaf': 0.03828783767577821, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:23,577] Trial 41 finished with value: 0.803201506591337 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.08640217587564002, 'min_samples_leaf': 0.07351416307544452, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:23,847] Trial 42 finished with value: 0.814406779661017 and parameters: {'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 0.13404063862816606, 'min_samples_leaf': 0.035108018136270694, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:24,078] Trial 43 finished with value: 0.6800376647834274 and parameters: {'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.22121640189637448, 'min_samples_leaf': 0.037801437395390214, 'max_features': 'sqrt', 'normalization': 'maxabs', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:24,333] Trial 44 finished with value: 0.814406779661017 and parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.12737875233122906, 'min_samples_leaf': 0.04134663571952289, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:24,599] Trial 45 finished with value: 0.6629943502824859 and parameters: {'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.15368033437088752, 'min_samples_leaf': 0.19207647752220042, 'max_features': None, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 4}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:24,837] Trial 46 finished with value: 0.6295668549905838 and parameters: {'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.24946675581210584, 'min_samples_leaf': 0.13652673399536464, 'max_features': 'sqrt', 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:25,076] Trial 47 finished with value: 0.7748587570621468 and parameters: {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.5561967618789476, 'min_samples_leaf': 0.010459839325649228, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:25,315] Trial 48 finished with value: 0.7918079096045197 and parameters: {'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 0.059001205118850535, 'min_samples_leaf': 0.16324288163342357, 'max_features': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:25,609] Trial 49 finished with value: 0.6735404896421846 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 0.9817643724143543, 'min_samples_leaf': 0.1226925814404814, 'max_features': None, 'normalization': None, 'treatment': 'pca', 'pca_components': 7}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:25,879] Trial 50 finished with value: 0.6573446327683615 and parameters: {'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 0.3676502168074579, 'min_samples_leaf': 0.307047686871364, 'max_features': 'sqrt', 'normalization': 'maxabs', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:26,118] Trial 51 finished with value: 0.814406779661017 and parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.127197200415985, 'min_samples_leaf': 0.03440575123235606, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:26,357] Trial 52 finished with value: 0.8257062146892656 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 0.12478046478013423, 'min_samples_leaf': 0.05025052411766037, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:26,627] Trial 53 finished with value: 0.803201506591337 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 0.2245692380848292, 'min_samples_leaf': 0.07244080101248367, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:26,914] Trial 54 finished with value: 0.7808851224105462 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 0.045141573631201026, 'min_samples_leaf': 0.05086368798214702, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:27,172] Trial 55 finished with value: 0.8257062146892656 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 0.11955417245756397, 'min_samples_leaf': 0.026783881720139402, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:27,410] Trial 56 finished with value: 0.7974576271186441 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 0.10722939668977985, 'min_samples_leaf': 0.11225597114842731, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:27,696] Trial 57 finished with value: 0.7918079096045197 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 0.1962686451585146, 'min_samples_leaf': 0.0258223535156389, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:27,950] Trial 58 finished with value: 0.7865348399246704 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 0.041499453689329335, 'min_samples_leaf': 0.09180954060824176, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:28,204] Trial 59 finished with value: 0.6966101694915254 and parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 0.27846732551879705, 'min_samples_leaf': 0.05591051835378177, 'max_features': None, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 2}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:28,465] Trial 60 finished with value: 0.6573446327683615 and parameters: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 0.8649719761754044, 'min_samples_leaf': 0.08266741290757196, 'max_features': 'sqrt', 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:28,701] Trial 61 finished with value: 0.814406779661017 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 0.15324314967697605, 'min_samples_leaf': 0.024981737156528915, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:28,955] Trial 62 finished with value: 0.8200564971751413 and parameters: {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.09451960543806835, 'min_samples_leaf': 0.05164228635884811, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:29,209] Trial 63 finished with value: 0.8200564971751413 and parameters: {'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.011465786690576837, 'min_samples_leaf': 0.050708522546749506, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:29,468] Trial 64 finished with value: 0.7918079096045197 and parameters: {'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 0.0918569621698162, 'min_samples_leaf': 0.1053467816094465, 'max_features': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:29,699] Trial 65 finished with value: 0.814406779661017 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.18407992927158856, 'min_samples_leaf': 0.013588083254142964, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:29,941] Trial 66 finished with value: 0.803201506591337 and parameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 0.10565523397256925, 'min_samples_leaf': 0.0771779149578753, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:30,190] Trial 67 finished with value: 0.8200564971751413 and parameters: {'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 0.059977802169767024, 'min_samples_leaf': 0.05751080135963013, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:30,442] Trial 68 finished with value: 0.7974576271186441 and parameters: {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.15038744900128764, 'min_samples_leaf': 0.13124741450842148, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:30,679] Trial 69 finished with value: 0.6573446327683615 and parameters: {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.2184659618971061, 'min_samples_leaf': 0.43814775914157944, 'max_features': 'log2', 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:30,858] Trial 70 finished with value: 0.7695856873822976 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 0.44411336068938934, 'min_samples_leaf': 0.025536615445299192, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:31,060] Trial 71 finished with value: 0.8257062146892656 and parameters: {'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.026632811137426875, 'min_samples_leaf': 0.04990340891378837, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:31,314] Trial 72 finished with value: 0.8087570621468926 and parameters: {'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 0.04151903217491601, 'min_samples_leaf': 0.06634239201806638, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:31,576] Trial 73 finished with value: 0.7974576271186441 and parameters: {'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.07997652629019092, 'min_samples_leaf': 0.10329705158800637, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:31,831] Trial 74 finished with value: 0.8257062146892656 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.10684657158534376, 'min_samples_leaf': 0.04573654229963181, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:32,085] Trial 75 finished with value: 0.803201506591337 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.033082739807783854, 'min_samples_leaf': 0.08051225299156287, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:32,354] Trial 76 finished with value: 0.8145951035781543 and parameters: {'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.11499262539206306, 'min_samples_leaf': 0.02675643675529215, 'max_features': None, 'normalization': 'maxabs', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:32,592] Trial 77 finished with value: 0.7973634651600753 and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 0.1606220132399803, 'min_samples_leaf': 0.04388727161825055, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:32,862] Trial 78 finished with value: 0.6962335216572505 and parameters: {'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.1863932053393928, 'min_samples_leaf': 0.0940555096937631, 'max_features': None, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 4}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:33,109] Trial 79 finished with value: 0.6295668549905838 and parameters: {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.6616202535103737, 'min_samples_leaf': 0.06543607956792677, 'max_features': 'log2', 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:33,366] Trial 80 finished with value: 0.8032956685499059 and parameters: {'criterion': 'log_loss', 'max_depth': 16, 'min_samples_split': 0.06088328867299238, 'min_samples_leaf': 0.010417483911748904, 'max_features': None, 'normalization': 'minmax', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:33,600] Trial 81 finished with value: 0.8257062146892656 and parameters: {'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 0.09296553293448111, 'min_samples_leaf': 0.0491079878652436, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:33,870] Trial 82 finished with value: 0.814406779661017 and parameters: {'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 0.1342734263490712, 'min_samples_leaf': 0.037090748613238106, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:34,123] Trial 83 finished with value: 0.803201506591337 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.07946539607106756, 'min_samples_leaf': 0.07150117900558303, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:34,448] Trial 84 finished with value: 0.8257062146892656 and parameters: {'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 0.0107486734614574, 'min_samples_leaf': 0.04679294268272536, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:34,704] Trial 85 finished with value: 0.7865348399246704 and parameters: {'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 0.031765740954762325, 'min_samples_leaf': 0.02153469635925628, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:34,957] Trial 86 finished with value: 0.7472693032015066 and parameters: {'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 0.013781430919765313, 'min_samples_leaf': 0.04348525871342592, 'max_features': 'sqrt', 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:35,218] Trial 87 finished with value: 0.7691148775894537 and parameters: {'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.052403334070289784, 'min_samples_leaf': 0.2791990639341004, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:35,466] Trial 88 finished with value: 0.8145951035781543 and parameters: {'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 0.11510984632614307, 'min_samples_leaf': 0.032533374601571644, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:35,736] Trial 89 finished with value: 0.8087570621468926 and parameters: {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.06859655542606764, 'min_samples_leaf': 0.06207671001414974, 'max_features': None, 'normalization': 'maxabs', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:36,023] Trial 90 finished with value: 0.7638418079096044 and parameters: {'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 0.17009494500707567, 'min_samples_leaf': 0.087180909512617, 'max_features': None, 'normalization': None, 'treatment': 'pca', 'pca_components': 8}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:36,252] Trial 91 finished with value: 0.814406779661017 and parameters: {'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 0.14212969793848193, 'min_samples_leaf': 0.05001902441465588, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:36,520] Trial 92 finished with value: 0.803201506591337 and parameters: {'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.10100972228424607, 'min_samples_leaf': 0.0769197592110013, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:36,793] Trial 93 finished with value: 0.8200564971751413 and parameters: {'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.010834047018413083, 'min_samples_leaf': 0.058095183038271485, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:37,027] Trial 94 finished with value: 0.7695856873822976 and parameters: {'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 0.5106429176492215, 'min_samples_leaf': 0.02058189430973705, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:37,231] Trial 95 finished with value: 0.769114877589454 and parameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 0.0749861796159036, 'min_samples_leaf': 0.22298437114524183, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:37,442] Trial 96 finished with value: 0.7974576271186441 and parameters: {'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.050927281356044685, 'min_samples_leaf': 0.03587420202055057, 'max_features': None, 'normalization': None, 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:37,656] Trial 97 finished with value: 0.8257062146892656 and parameters: {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.1187175503101364, 'min_samples_leaf': 0.04566395268562774, 'max_features': None, 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:37,862] Trial 98 finished with value: 0.6860640301318267 and parameters: {'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 0.2617747094029033, 'min_samples_leaf': 0.044853405233107366, 'max_features': 'log2', 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n",
      "[I 2025-11-03 08:37:38,044] Trial 99 finished with value: 0.6295668549905838 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 0.1965207989271845, 'min_samples_leaf': 0.09824787063099288, 'max_features': 'sqrt', 'normalization': 'standard', 'treatment': None}. Best is trial 34 with value: 0.8258003766478343.\n"
     ]
    }
   ],
   "source": [
    "study_DecisionTree.optimize(parcial_DecisionTree, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc2e06-cc2d-4de7-aa0f-58081b6c213a",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6346a64c-bd39-4b66-9178-e284977c5f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 34\n",
      "Parâmetros do melhor trial: {'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.11822332932827617, 'min_samples_leaf': 0.0530684395557626, 'max_features': None, 'normalization': None, 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "resultado_DecisionTree = study_DecisionTree.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_DecisionTree.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_DecisionTree.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01e1bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Otimizando um modelo de RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b225e9",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função para Instanciar o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb4570-58f0-451d-8cf5-aa42dff162d4",
   "metadata": {},
   "source": [
    "Os parâmetros que precisamos considerar para uma floresta aleatória são muito parecidos com o de uma árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d961337-0e23-4f05-a137-58a2f9dc7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciador_RandomForest(trial):\n",
    "    \"\"\" Recebe um trial do optuna e retorna uma instância do modelo\"\"\"\n",
    "\n",
    "    # Definindo os parâmetros\n",
    "    params = {\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "    \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"]),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 32),\n",
    "    \"min_samples_split\": trial.suggest_float(\"min_samples_split\", 0.01, 1.0),\n",
    "    \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
    "    \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "    \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "    \"random_state\": semente\n",
    "    }\n",
    "\n",
    "    # Passos a serem seguidos pela pipeline\n",
    "    steps = []\n",
    "\n",
    "    # Definindo a estratégia de normalização \n",
    "    normalization = trial.suggest_categorical(\"normalization\", [None, \"standard\", \"minmax\", \"maxabs\"])\n",
    "    \n",
    "    # Adiciona normalização padrão\n",
    "    if normalization == \"standard\": \n",
    "        steps.append(StandardScaler())\n",
    "    # Adiciona normalização por máximos e mínimos\n",
    "    elif normalization == \"minmax\": \n",
    "        steps.append(MinMaxScaler())\n",
    "    # Adiciona normalização por máximo absoluto\n",
    "    elif normalization == \"maxabs\": \n",
    "        steps.append(MaxAbsScaler())\n",
    "\n",
    "    # Definindo estratégia de redução de dimensionalidade\n",
    "    treatment = trial.suggest_categorical(\"treatment\", [None, \"pca\"])\n",
    "\n",
    "    # Adiciona tratamento PCA \n",
    "    if treatment == \"pca\": \n",
    "        # Definindo o número de componentes a serem mantidas pelo pca\n",
    "        components = trial.suggest_int(\"pca_components\", 2, 9)\n",
    "        steps.append(PCA(n_components=components))\n",
    "\n",
    "    # Adiciona tratamento RFE \n",
    "    elif treatment == \"rfe\": \n",
    "        # Definindo o estimador \n",
    "        estimator = RandomForestClassifier(**params)\n",
    "        # Definindo o número de atributos a serem mantidos\n",
    "        n_features_to_select = trial.suggest_int(\"rfe_features\", 2, 9)\n",
    "        steps.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "        \n",
    "    # Instanciando o modelo\n",
    "    modelo = RandomForestClassifier(**params)\n",
    "    steps.append(modelo)\n",
    "\n",
    "    # Criando o pipeline\n",
    "    pipeline = make_pipeline(*steps)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e0584",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a função objetivo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "538b0e95-afe2-4853-9f99-30453bb31b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo_RandomForest(trial, X_treino, Y_treino):\n",
    "    \"\"\"Função a ser otimizada pelo Optuna\"\"\"\n",
    "    modelo = instanciador_RandomForest(trial)\n",
    "\n",
    "    kf = StratifiedKFold(3, shuffle=True, random_state=semente)\n",
    "    \n",
    "    metrica = cross_val_score(\n",
    "        modelo, \n",
    "        X_treino, \n",
    "        Y_treino, \n",
    "        scoring=\"accuracy\", \n",
    "        cv=kf\n",
    "    )\n",
    "\n",
    "    return metrica.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8916f",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando um estudo do optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e4875a4-94af-40f0-8825-17f26fcac616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:37:38,482] A new study created in RDB with name: Estudo Random Forest\n"
     ]
    }
   ],
   "source": [
    "study_RandomForest = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"Estudo Random Forest\", \n",
    "    storage=f\"sqlite:///{\"Estudo RFC\"}.db\",\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584d13c",
   "metadata": {},
   "source": [
    "### $\\bullet$ Determinando testes desejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1031e3b-6cba-47a5-8dbd-e9fac9edb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sem tratamentos\n",
    "study_RandomForest.enqueue_trial({\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"treatment\": None\n",
    "})\n",
    "\n",
    "# Modelo base com PCA\n",
    "study_RandomForest.enqueue_trial({\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"normalization\": \"standard\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "})\n",
    "\n",
    "# Modelo base com normalização por mínimos e máximos e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"normalization\": \"minmax\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")\n",
    "\n",
    "# Modelo base com normalização por máximo absoluto e PCA\n",
    "study_DecisionTree.enqueue_trial(\n",
    "{\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 0.1,\n",
    "    \"min_samples_leaf\": 0.05, \n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"normalization\": \"maxabs\",\n",
    "    \"treatment\": \"pca\",\n",
    "    \"pca_components\": 9\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e3405",
   "metadata": {},
   "source": [
    "### $\\bullet$ Criando a Função Objetivo Parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ac05b02-cd55-41c8-9bfd-d80a4237338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcial_RandomForest(trial):\n",
    "    \"\"\"Função que retorna a função objetivo\"\"\"\n",
    "    return funcao_objetivo_RandomForest(trial, x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a51ad",
   "metadata": {},
   "source": [
    "### $\\bullet$ Otimizando os parâmetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f6152f8-8f0c-4297-9f5c-5f4143c08467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 08:37:39,531] Trial 0 finished with value: 0.825517890772128 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:40,520] Trial 1 finished with value: 0.78060263653484 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.1, 'min_samples_leaf': 0.05, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 9}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:41,120] Trial 2 finished with value: 0.7695856873822976 and parameters: {'n_estimators': 64, 'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 0.4142572985886295, 'min_samples_leaf': 0.04075733570932291, 'max_features': None, 'bootstrap': False, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:42,366] Trial 3 finished with value: 0.7413370998116761 and parameters: {'n_estimators': 143, 'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 0.23573343413089215, 'min_samples_leaf': 0.17094422402360027, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 4}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:43,910] Trial 4 finished with value: 0.7695856873822976 and parameters: {'n_estimators': 262, 'criterion': 'log_loss', 'max_depth': 23, 'min_samples_split': 0.37396986829035855, 'min_samples_leaf': 0.0251177079858442, 'max_features': None, 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:44,877] Trial 5 finished with value: 0.7127118644067797 and parameters: {'n_estimators': 124, 'criterion': 'log_loss', 'max_depth': 24, 'min_samples_split': 0.10677599588414315, 'min_samples_leaf': 0.2262182972761903, 'max_features': None, 'bootstrap': False, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 5}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:45,834] Trial 6 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 0.9029142640982091, 'min_samples_leaf': 0.023539398721866167, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'minmax', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:46,688] Trial 7 finished with value: 0.6629943502824859 and parameters: {'n_estimators': 171, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 0.13435869543322873, 'min_samples_leaf': 0.41693930125602274, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 4}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:47,259] Trial 8 finished with value: 0.6508474576271186 and parameters: {'n_estimators': 50, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.48475571249498084, 'min_samples_leaf': 0.44058953221326946, 'max_features': None, 'bootstrap': False, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 8}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:48,045] Trial 9 finished with value: 0.7015065913370999 and parameters: {'n_estimators': 92, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 0.82290354406355, 'min_samples_leaf': 0.3878536750993795, 'max_features': None, 'bootstrap': False, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:49,577] Trial 10 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 243, 'criterion': 'gini', 'max_depth': 16, 'min_samples_split': 0.6784917375536288, 'min_samples_leaf': 0.14732117043024698, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'maxabs', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:51,220] Trial 11 finished with value: 0.7975517890772128 and parameters: {'n_estimators': 218, 'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 0.07170823417509828, 'min_samples_leaf': 0.12624493741878015, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:52,725] Trial 12 finished with value: 0.7975517890772128 and parameters: {'n_estimators': 216, 'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 0.26488933471780507, 'min_samples_leaf': 0.1262465520833695, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:54,725] Trial 13 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 298, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 0.023020887404087184, 'min_samples_leaf': 0.31416052706197806, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:56,291] Trial 14 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 205, 'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 0.6337645030748726, 'min_samples_leaf': 0.1121394190031429, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'maxabs', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:57,775] Trial 15 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 186, 'criterion': 'log_loss', 'max_depth': 18, 'min_samples_split': 0.26723231699523126, 'min_samples_leaf': 0.23215544509724742, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:37:59,560] Trial 16 finished with value: 0.8088512241054614 and parameters: {'n_estimators': 247, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 0.20150028659123098, 'min_samples_leaf': 0.08946801037325408, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:38:01,593] Trial 17 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 294, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 0.2112165843258351, 'min_samples_leaf': 0.2886466882428534, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:38:03,441] Trial 18 finished with value: 0.786346516007533 and parameters: {'n_estimators': 256, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 0.3453142325094153, 'min_samples_leaf': 0.0783967725121156, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': None, 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:38:04,131] Trial 19 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 90, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.5641935212973138, 'min_samples_leaf': 0.1713999988376681, 'max_features': 'sqrt', 'bootstrap': True, 'normalization': 'maxabs', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:38:05,466] Trial 20 finished with value: 0.8144067796610169 and parameters: {'n_estimators': 169, 'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 0.17661408804279516, 'min_samples_leaf': 0.08167374836938085, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:38:06,743] Trial 21 finished with value: 0.8144067796610169 and parameters: {'n_estimators': 169, 'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 0.013077165215801795, 'min_samples_leaf': 0.07775802021668367, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:38:08,005] Trial 22 finished with value: 0.6742937853107344 and parameters: {'n_estimators': 165, 'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 0.015071649271662074, 'min_samples_leaf': 0.19403121061712153, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:38:09,023] Trial 23 finished with value: 0.8199623352165725 and parameters: {'n_estimators': 124, 'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 0.15859468884867423, 'min_samples_leaf': 0.0744393364470006, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:38:09,866] Trial 24 finished with value: 0.8199623352165725 and parameters: {'n_estimators': 115, 'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 0.1632011683143222, 'min_samples_leaf': 0.07122292431644942, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 0 with value: 0.825517890772128.\n",
      "[I 2025-11-03 08:38:10,479] Trial 25 finished with value: 0.8369114877589454 and parameters: {'n_estimators': 118, 'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 0.2868462324931307, 'min_samples_leaf': 0.010489576520869064, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:11,241] Trial 26 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 128, 'criterion': 'gini', 'max_depth': 28, 'min_samples_split': 0.32336318725486457, 'min_samples_leaf': 0.4977531858493208, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:11,804] Trial 27 finished with value: 0.786346516007533 and parameters: {'n_estimators': 74, 'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 0.43412422133515266, 'min_samples_leaf': 0.013164898952507316, 'max_features': 'log2', 'bootstrap': True, 'normalization': None, 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:12,633] Trial 28 finished with value: 0.803201506591337 and parameters: {'n_estimators': 104, 'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.2883559888870253, 'min_samples_leaf': 0.05228261947705714, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'maxabs', 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:13,814] Trial 29 finished with value: 0.7076271186440678 and parameters: {'n_estimators': 146, 'criterion': 'log_loss', 'max_depth': 21, 'min_samples_split': 0.1019049144927973, 'min_samples_leaf': 0.013088458283148528, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 2}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:14,545] Trial 30 finished with value: 0.8256120527306967 and parameters: {'n_estimators': 75, 'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 0.08366466756646285, 'min_samples_leaf': 0.05153064059534634, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:15,235] Trial 31 finished with value: 0.8367231638418078 and parameters: {'n_estimators': 70, 'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 0.08061570430116788, 'min_samples_leaf': 0.05690388042874173, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:15,932] Trial 32 finished with value: 0.825517890772128 and parameters: {'n_estimators': 75, 'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 0.07177783074175084, 'min_samples_leaf': 0.047865945719103686, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:16,455] Trial 33 finished with value: 0.8256120527306967 and parameters: {'n_estimators': 50, 'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 0.09364370816954701, 'min_samples_leaf': 0.05187493041342855, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:16,908] Trial 34 finished with value: 0.7862523540489642 and parameters: {'n_estimators': 59, 'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 0.090979708014228, 'min_samples_leaf': 0.10999775889697122, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:17,640] Trial 35 finished with value: 0.8087570621468926 and parameters: {'n_estimators': 75, 'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 0.22317610858068893, 'min_samples_leaf': 0.05373763232273366, 'max_features': 'log2', 'bootstrap': True, 'normalization': 'standard', 'treatment': None}. Best is trial 25 with value: 0.8369114877589454.\n",
      "[I 2025-11-03 08:38:18,076] Trial 36 finished with value: 0.8538606403013183 and parameters: {'n_estimators': 51, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.3881089405676145, 'min_samples_leaf': 0.17116941549360815, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'standard', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:18,775] Trial 37 finished with value: 0.651789077212806 and parameters: {'n_estimators': 87, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 0.4509519691102311, 'min_samples_leaf': 0.15827118701560883, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 2}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:19,379] Trial 38 finished with value: 0.8369114877589454 and parameters: {'n_estimators': 69, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.3866709236025752, 'min_samples_leaf': 0.18771862990021018, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:20,100] Trial 39 finished with value: 0.7804143126177024 and parameters: {'n_estimators': 101, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.542899308170494, 'min_samples_leaf': 0.20179475986743733, 'max_features': None, 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:20,704] Trial 40 finished with value: 0.7189265536723163 and parameters: {'n_estimators': 62, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 0.3848305009783582, 'min_samples_leaf': 0.2315619952102052, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 7}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:21,282] Trial 41 finished with value: 0.6968926553672317 and parameters: {'n_estimators': 79, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.32915009184519034, 'min_samples_leaf': 0.2974301505968426, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:22,027] Trial 42 finished with value: 0.8201506591337101 and parameters: {'n_estimators': 108, 'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 0.4947196830841858, 'min_samples_leaf': 0.1896720499899519, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:22,591] Trial 43 finished with value: 0.7864406779661017 and parameters: {'n_estimators': 64, 'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 0.37254658591499, 'min_samples_leaf': 0.26293309343878346, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:23,511] Trial 44 finished with value: 0.7918079096045197 and parameters: {'n_estimators': 87, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 0.4040312027965676, 'min_samples_leaf': 0.14241763477424602, 'max_features': None, 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:24,023] Trial 45 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 0.596207689157491, 'min_samples_leaf': 0.3410539626319288, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:24,980] Trial 46 finished with value: 0.7413370998116761 and parameters: {'n_estimators': 135, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.6948578112494831, 'min_samples_leaf': 0.10614660019545137, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'standard', 'treatment': 'pca', 'pca_components': 6}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:25,561] Trial 47 finished with value: 0.7305084745762711 and parameters: {'n_estimators': 68, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.2810341439082138, 'min_samples_leaf': 0.03345908291633239, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:26,211] Trial 48 finished with value: 0.7862523540489642 and parameters: {'n_estimators': 111, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 0.45785080651324356, 'min_samples_leaf': 0.13330905076182087, 'max_features': None, 'bootstrap': False, 'normalization': 'standard', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:26,927] Trial 49 finished with value: 0.8481167608286252 and parameters: {'n_estimators': 91, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.2462114458577122, 'min_samples_leaf': 0.174427802960061, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'standard', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:27,632] Trial 50 finished with value: 0.8312617702448212 and parameters: {'n_estimators': 95, 'criterion': 'log_loss', 'max_depth': 22, 'min_samples_split': 0.24475740637205506, 'min_samples_leaf': 0.21278790570846806, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:28,282] Trial 51 finished with value: 0.814406779661017 and parameters: {'n_estimators': 92, 'criterion': 'log_loss', 'max_depth': 26, 'min_samples_split': 0.2460327466747051, 'min_samples_leaf': 0.21553992102500896, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:28,988] Trial 52 finished with value: 0.8088512241054615 and parameters: {'n_estimators': 97, 'criterion': 'log_loss', 'max_depth': 30, 'min_samples_split': 0.3020265395174015, 'min_samples_leaf': 0.25367182288691176, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:29,686] Trial 53 finished with value: 0.8481167608286252 and parameters: {'n_estimators': 83, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.34235055386871666, 'min_samples_leaf': 0.17368627500128608, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:30,251] Trial 54 finished with value: 0.848210922787194 and parameters: {'n_estimators': 57, 'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.3597616557555166, 'min_samples_leaf': 0.1682624023320169, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:30,852] Trial 55 finished with value: 0.848210922787194 and parameters: {'n_estimators': 58, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.35782315443221346, 'min_samples_leaf': 0.17252627683678248, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:31,407] Trial 56 finished with value: 0.848210922787194 and parameters: {'n_estimators': 58, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.35050116143636967, 'min_samples_leaf': 0.16275503864233543, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:32,098] Trial 57 finished with value: 0.7353107344632769 and parameters: {'n_estimators': 60, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.3583381571629471, 'min_samples_leaf': 0.16801618135510105, 'max_features': None, 'bootstrap': False, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 9}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:32,669] Trial 58 finished with value: 0.8425612052730697 and parameters: {'n_estimators': 53, 'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.42030385048062, 'min_samples_leaf': 0.15989758619797448, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:33,327] Trial 59 finished with value: 0.8425612052730697 and parameters: {'n_estimators': 82, 'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.47316547512318524, 'min_samples_leaf': 0.1770804970862807, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:33,883] Trial 60 finished with value: 0.7808851224105462 and parameters: {'n_estimators': 61, 'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 0.5316529228232655, 'min_samples_leaf': 0.24723431315332897, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:34,452] Trial 61 finished with value: 0.8481167608286252 and parameters: {'n_estimators': 56, 'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.3268110134158097, 'min_samples_leaf': 0.1483503558847898, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:35,018] Trial 62 finished with value: 0.8481167608286252 and parameters: {'n_estimators': 57, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.326554897983782, 'min_samples_leaf': 0.14674197953935358, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:35,701] Trial 63 finished with value: 0.8369114877589454 and parameters: {'n_estimators': 82, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.3490715263225757, 'min_samples_leaf': 0.12043943605310276, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:36,298] Trial 64 finished with value: 0.8425612052730697 and parameters: {'n_estimators': 65, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.41740016293798043, 'min_samples_leaf': 0.1755982548037734, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:36,840] Trial 65 finished with value: 0.6573446327683615 and parameters: {'n_estimators': 50, 'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 0.9480163477614255, 'min_samples_leaf': 0.09790306027042003, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:37,531] Trial 66 finished with value: 0.848210922787194 and parameters: {'n_estimators': 84, 'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.19389655266932365, 'min_samples_leaf': 0.13317884586919815, 'max_features': 'log2', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:38,178] Trial 67 finished with value: 0.8087570621468926 and parameters: {'n_estimators': 83, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.19641950179975354, 'min_samples_leaf': 0.21104434666513178, 'max_features': 'log2', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:40,106] Trial 68 finished with value: 0.8368173258003767 and parameters: {'n_estimators': 286, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 0.15155311061001914, 'min_samples_leaf': 0.13762577553770722, 'max_features': 'log2', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:41,021] Trial 69 finished with value: 0.8425612052730697 and parameters: {'n_estimators': 158, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.26247317480457677, 'min_samples_leaf': 0.1810221474727433, 'max_features': 'log2', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:42,264] Trial 70 finished with value: 0.7582862523540489 and parameters: {'n_estimators': 195, 'criterion': 'log_loss', 'max_depth': 16, 'min_samples_split': 0.30762895715960975, 'min_samples_leaf': 0.12203688439782998, 'max_features': 'log2', 'bootstrap': False, 'normalization': None, 'treatment': 'pca', 'pca_components': 4}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:42,880] Trial 71 finished with value: 0.8481167608286252 and parameters: {'n_estimators': 69, 'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.3556136042717074, 'min_samples_leaf': 0.1660205069706075, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:43,437] Trial 72 finished with value: 0.8537664783427495 and parameters: {'n_estimators': 56, 'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.12995302043759022, 'min_samples_leaf': 0.15392578747610441, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:44,066] Trial 73 finished with value: 0.842467043314501 and parameters: {'n_estimators': 76, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.12778223878067377, 'min_samples_leaf': 0.15465529515954748, 'max_features': 'log2', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:44,718] Trial 74 finished with value: 0.8199623352165726 and parameters: {'n_estimators': 69, 'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.18304707528584427, 'min_samples_leaf': 0.19492244850702609, 'max_features': 'log2', 'bootstrap': False, 'normalization': None, 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:45,266] Trial 75 finished with value: 0.8537664783427495 and parameters: {'n_estimators': 59, 'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.1232194519214112, 'min_samples_leaf': 0.1285073472898035, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 36 with value: 0.8538606403013183.\n",
      "[I 2025-11-03 08:38:45,835] Trial 76 finished with value: 0.8706214689265538 and parameters: {'n_estimators': 57, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.1331748059009833, 'min_samples_leaf': 0.10086962486020104, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:46,391] Trial 77 finished with value: 0.8649717514124294 and parameters: {'n_estimators': 57, 'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.03537744853017889, 'min_samples_leaf': 0.09658843275240296, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:46,943] Trial 78 finished with value: 0.8649717514124294 and parameters: {'n_estimators': 58, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.04503711827691284, 'min_samples_leaf': 0.09055362359103294, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:47,494] Trial 79 finished with value: 0.8649717514124294 and parameters: {'n_estimators': 55, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.0348724637510486, 'min_samples_leaf': 0.08791621869467689, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:48,054] Trial 80 finished with value: 0.8593220338983051 and parameters: {'n_estimators': 63, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.05493655382968657, 'min_samples_leaf': 0.0916995237574405, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:48,568] Trial 81 finished with value: 0.8649717514124294 and parameters: {'n_estimators': 50, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.04277094690600389, 'min_samples_leaf': 0.09274224402075643, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:49,075] Trial 82 finished with value: 0.8649717514124294 and parameters: {'n_estimators': 50, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.055286321045174565, 'min_samples_leaf': 0.09083998512238346, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:49,627] Trial 83 finished with value: 0.8593220338983052 and parameters: {'n_estimators': 51, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.04010091273031972, 'min_samples_leaf': 0.0934572432487823, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:50,035] Trial 84 finished with value: 0.8649717514124294 and parameters: {'n_estimators': 50, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.04584399271501177, 'min_samples_leaf': 0.08691332743854807, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:50,621] Trial 85 finished with value: 0.842467043314501 and parameters: {'n_estimators': 65, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.043653353744141477, 'min_samples_leaf': 0.06422993267369434, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:51,282] Trial 86 finished with value: 0.8425612052730697 and parameters: {'n_estimators': 73, 'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.04784193875847376, 'min_samples_leaf': 0.0858280066915842, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:51,869] Trial 87 finished with value: 0.8649717514124294 and parameters: {'n_estimators': 64, 'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.049984914822124527, 'min_samples_leaf': 0.0983226567644131, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:52,376] Trial 88 finished with value: 0.7025423728813559 and parameters: {'n_estimators': 50, 'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.02800982740435558, 'min_samples_leaf': 0.10152226327984559, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': 'pca', 'pca_components': 3}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:53,726] Trial 89 finished with value: 0.8425612052730697 and parameters: {'n_estimators': 236, 'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.014157609319621879, 'min_samples_leaf': 0.06620517087201994, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:54,332] Trial 90 finished with value: 0.7191148775894538 and parameters: {'n_estimators': 73, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.06752194297766936, 'min_samples_leaf': 0.03526778643963292, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:54,804] Trial 91 finished with value: 0.8593220338983051 and parameters: {'n_estimators': 65, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.052309960872577436, 'min_samples_leaf': 0.08727550076615474, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:55,361] Trial 92 finished with value: 0.8593220338983051 and parameters: {'n_estimators': 65, 'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.06271891312129418, 'min_samples_leaf': 0.09532322046355388, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:55,844] Trial 93 finished with value: 0.8479284369114878 and parameters: {'n_estimators': 54, 'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.09628408489580348, 'min_samples_leaf': 0.07607742076593245, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:56,479] Trial 94 finished with value: 0.8426553672316385 and parameters: {'n_estimators': 76, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.03342535201184794, 'min_samples_leaf': 0.1159588509509393, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:56,955] Trial 95 finished with value: 0.8706214689265538 and parameters: {'n_estimators': 63, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.1123867788018281, 'min_samples_leaf': 0.1073329534873094, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:57,503] Trial 96 finished with value: 0.8594161958568738 and parameters: {'n_estimators': 50, 'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.10587012020354401, 'min_samples_leaf': 0.10397630763185328, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:58,124] Trial 97 finished with value: 0.8593220338983052 and parameters: {'n_estimators': 70, 'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 0.10883564515005316, 'min_samples_leaf': 0.10978028818098705, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'maxabs', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:58,715] Trial 98 finished with value: 0.8537664783427495 and parameters: {'n_estimators': 62, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.08339741722417222, 'min_samples_leaf': 0.025418704284977597, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n",
      "[I 2025-11-03 08:38:59,441] Trial 99 finished with value: 0.8368173258003767 and parameters: {'n_estimators': 78, 'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.15564476785344056, 'min_samples_leaf': 0.06300430392438724, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}. Best is trial 76 with value: 0.8706214689265538.\n"
     ]
    }
   ],
   "source": [
    "study_RandomForest.optimize(parcial_RandomForest, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cffa46-c202-487f-8abb-d2a4fbfe6b68",
   "metadata": {},
   "source": [
    "### $\\bullet$ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fddb150a-2aa8-41a9-86a8-c9e2ba5d2664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 76\n",
      "Parâmetros do melhor trial: {'n_estimators': 57, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.1331748059009833, 'min_samples_leaf': 0.10086962486020104, 'max_features': 'sqrt', 'bootstrap': False, 'normalization': 'minmax', 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "resultado_RandomForest = study_RandomForest.best_trial\n",
    "print(f\"Número do melhor trial: {resultado_RandomForest.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {resultado_RandomForest.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416e230-69a2-4cd1-af9f-36f15895f0b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Teste dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d26a7",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "565f3884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       0.65      1.00      0.79        13\n",
      "      Tóxico       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.33      0.50      0.39        20\n",
      "weighted avg       0.42      0.65      0.51        20\n",
      "\n",
      "Valor de accuracy = 0.65\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_baseline = DummyClassifier()\n",
    "modelo_baseline.fit(x_treino, y_treino)\n",
    "y_previsao = modelo_baseline.predict(x_teste)\n",
    "\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "accuracy_baseline = accuracy_score(y_teste, y_previsao)\n",
    "\n",
    "print(f\"Valor de accuracy = {accuracy_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b0efd",
   "metadata": {},
   "source": [
    "## Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d62bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5,\n",
      " 'normalization': 'standard',\n",
      " 'p': 2,\n",
      " 'pca_components': 9,\n",
      " 'treatment': 'pca',\n",
      " 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_knn = resultado_knn.params.copy()\n",
    "pprint(parametros_otimizados_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1d5eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_knn = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_knn = parametros_otimizados_knn[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_knn == \"standard\": \n",
    "    steps_knn.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_knn == \"minmax\": \n",
    "    steps_knn.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_knn == \"maxabs\": \n",
    "    steps_knn.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_knn[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_knn.append(PCA(n_components=parametros_otimizados_knn[\"pca_components\"]))\n",
    "\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\"]\n",
    "for param in parametros_remover:\n",
    "    parametros_otimizados_knn.pop(param, None)\n",
    "\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_knn = KNeighborsClassifier(**parametros_otimizados_knn)\n",
    "steps_knn.append(modelo_knn)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_knn = make_pipeline(*steps_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd1e2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de accuracy = [0.75       0.77777778 0.86111111 0.68571429 0.71428571]\n",
      "Valor médio de accuracy = 0.7577777777777778\n"
     ]
    }
   ],
   "source": [
    "kf_knn = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "accuracy_knn = cross_val_score(\n",
    "    pipeline_knn, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"accuracy\", \n",
    "    cv=kf_knn\n",
    "    )\n",
    "\n",
    "media_accuracy_knn = accuracy_knn.mean()\n",
    "\n",
    "print(f\"Valores de accuracy = {accuracy_knn}\")\n",
    "print(f\"Valor médio de accuracy = {media_accuracy_knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8b984df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       0.93      1.00      0.96        13\n",
      "      Tóxico       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.93      0.94        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_knn.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_knn.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd45b7",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6cda8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 789.1080195648531,\n",
      " 'coef0': 0.4160506093597419,\n",
      " 'degree': 5,\n",
      " 'gamma': 'auto',\n",
      " 'kernel': 'poly',\n",
      " 'normalization': 'minmax',\n",
      " 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_svc = resultado_svc.params.copy()\n",
    "pprint(parametros_otimizados_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16e8b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_svc = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_svc = parametros_otimizados_svc[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_svc == \"standard\": \n",
    "    steps_svc.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_svc == \"minmax\": \n",
    "    steps_svc.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_svc == \"maxabs\": \n",
    "    steps_svc.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_svc[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_svc.append(PCA(n_components=parametros_otimizados_svc[\"pca_components\"]))\n",
    "\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\"]\n",
    "for param in parametros_remover:\n",
    "    parametros_otimizados_svc.pop(param, None)\n",
    "\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_svc = SVC(**parametros_otimizados_svc)\n",
    "steps_svc.append(modelo_svc)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_svc = make_pipeline(*steps_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34857eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de accuracy = [0.77777778 0.88888889 0.88888889 0.85714286 0.85714286]\n",
      "Valor médio de accuracy = 0.8539682539682539\n"
     ]
    }
   ],
   "source": [
    "kf_svc = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "accuracy_svc = cross_val_score(\n",
    "    pipeline_svc, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"accuracy\", \n",
    "    cv=kf_svc\n",
    "    )\n",
    "\n",
    "media_accuracy_svc = accuracy_svc.mean()\n",
    "\n",
    "print(f\"Valores de accuracy = {accuracy_svc}\")\n",
    "print(f\"Valor médio de accuracy = {media_accuracy_svc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "906d81da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       0.93      1.00      0.96        13\n",
      "      Tóxico       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.93      0.94        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_svc.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_svc.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b26639b",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d1c0ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.18354553587797304,\n",
      " 'class_weight': 'balanced',\n",
      " 'max_iter': 5000,\n",
      " 'normalization': 'standard',\n",
      " 'penalty': 'l1',\n",
      " 'random_state': 3931421,\n",
      " 'solver': 'liblinear',\n",
      " 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_lrc = resultado_lrc.params.copy()\n",
    "parametros_otimizados_lrc[\"solver\"] =\"liblinear\"\n",
    "parametros_otimizados_lrc[\"max_iter\"] = 5000\n",
    "parametros_otimizados_lrc[\"random_state\"] = semente\n",
    "\n",
    "pprint(parametros_otimizados_lrc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afb31332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_lrc = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_lrc = parametros_otimizados_lrc[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_lrc == \"standard\": \n",
    "    steps_lrc.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_lrc == \"minmax\": \n",
    "    steps_lrc.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_lrc == \"maxabs\": \n",
    "    steps_lrc.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_lrc[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_lrc.append(PCA(n_components=parametros_otimizados_lrc[\"pca_components\"]))\n",
    "\n",
    "# Adiciona tratamento RFE \n",
    "elif treatment == \"rfe\": \n",
    "\n",
    "    # Definindo o número de atributos a serem mantidos\n",
    "    n_features_to_select = parametros_otimizados_lrc[\"rfe_features\"]\n",
    "\n",
    "    # Tratamento da lista de parametros\n",
    "    parametros_remover = [\"normalization\", \"treatment\", \"pca_components\", \"rfe_features\"]\n",
    "    for param in parametros_remover:\n",
    "        parametros_otimizados_lrc.pop(param, None)\n",
    "\n",
    "    # Definindo o estimador \n",
    "    estimator = LogisticRegression(**parametros_otimizados_lrc)\n",
    "    \n",
    "    steps_lrc.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\", \"rfe_features\"]\n",
    "for param in parametros_remover:\n",
    "    parametros_otimizados_lrc.pop(param, None)\n",
    "\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_lrc = LogisticRegression(**parametros_otimizados_lrc)\n",
    "steps_lrc.append(modelo_lrc)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_lrc = make_pipeline(*steps_lrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "036160ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de accuracy = [0.86111111 0.83333333 0.94444444 0.8        0.77142857]\n",
      "Valor médio de accuracy = 0.8420634920634921\n"
     ]
    }
   ],
   "source": [
    "kf_lrc = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "accuracy_lrc = cross_val_score(\n",
    "    pipeline_lrc, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"accuracy\", \n",
    "    cv=kf_lrc\n",
    "    )\n",
    "\n",
    "media_accuracy_lrc = accuracy_lrc.mean()\n",
    "\n",
    "print(f\"Valores de accuracy = {accuracy_lrc}\")\n",
    "print(f\"Valor médio de accuracy = {media_accuracy_lrc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44d028c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       1.00      1.00      1.00        13\n",
      "      Tóxico       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGdCAYAAAAczXrvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAALUJJREFUeJzt3QmczeX+wPHvGGaMiTFDlrFvXbtkqcYSEUm26xIpSlSI0LVMN4XKIGRJKrculcQtWnQp195w7aNEiAxZyzLDTMaY8/u/nkcz/zlnZjRn/M4yv9/nfV+/1znnd7bH7Zz5nuf7fJ/nCTAMwxAAAGAbBXzdAAAA4F0EfwAAbIbgDwCAzRD8AQCwGYI/AAA2Q/AHAMBmCP4AANgMwR8AAJsh+AMAYDMFxU+k/nbE100A/E5IZAtfNwHwS9eunsg3MalQyarib/wm+AMA4DccaWJlpP0BALAZev4AALgyHGJlBH8AAFw5CP4AANiKYfGeP2P+AADYDD1/AABckfYHAMBmDGsHf9L+AADYDD1/AABstsgPwR8AAFek/QEAgJXQ8wcAwBXV/gAA2ItB2h8AAFgJPX8AAFyR9gcAwGYMgj8AAPbisPY8f8b8AQCwGXr+AAC4Iu0PAIDNOKwd/En7AwBgM/T8AQCwWdqfnj8AANml/c063LBx40bp1KmTREZGSkBAgHz22WcZ96WmpsqYMWOkXr16Ehoaqh/Tt29fOXnypLiL4A8AgJ9ISkqSBg0ayNy5c7Pcl5ycLLt27ZJx48bpy2XLlsmBAwekc+fObr8PaX8AAFwYhm/m+Xfo0EEf2QkLC5PVq1c7nXvjjTekadOmcuzYMalYsWKu34fgDwCAB8f8U1JS9JFZcHCwPm5WQkKCHh4oXry4W88j7Q8AgAfFxMToXnvmQ527WVeuXNE1AL1795ZixYq59Vx6/gAAeHCef3R0tIwcOdLp3M32+lXxX8+ePcUwDJk3b57bzyf4AwDgwbS/WSl+18AfHx8va9eudbvXrxD8AQDIJxv7pAf+Q4cOybp166REiRJ5eh2CPwAAfuLy5cvy008/Zdz++eefJS4uTiIiIqRs2bLyt7/9TU/zW7FihaSlpcnp06f149T9QUFBuX6fAEMNGPiB1N+O+LoJgN8JiWzh6yYAfuna1RMeff0r2/5t2msVbtoj149dv369tG7dOsv5fv36yfjx46VKlSrZPk9lAVq1apXr96HnDwCAn2zsowL4jfrkZvXXmeoHAIDN0PMHAMBmG/sQ/AEA8JO0v7eQ9gcAwGbo+QMAYLOeP8EfAAA/2dXPW0j7AwBgM/T8AQBwRdofAACbMQj+AADYi8PawZ8xfwAAbIaePwAArkj7AwBgMw5rB3/S/gAA2Aw9fwAAXJH2BwDAZhzWDv6k/QEAsBl6/gAA2KznT/AHAMBmY/6k/QEAsBl6/gAAuCLtDwCAzRjWDv55Svtv2LBBOnXqJNWrV9dH586dZdOmTea3DgAAX/X8HSYdVgj+H374obRt21aKFCkiw4YN00dISIi0adNGPvroI8+0EgAAmCbAMAzDnSfUqlVLnnzySRkxYoTT+RkzZsj8+fNl//79eWpI6m9H8vQ8wMpCIlv4ugmAX7p29YRHX//3ZZNMe62Qvz4v+b7nf+TIEZ3yd6VS/z///LNZ7QIAwHccpP2dVKhQQdasWZPl/H//+199HwAAsFi1/3PPPafH+ePi4iQqKkqfi42NlQULFsisWbM80UYAALzL4Z89dp8F/0GDBkmZMmVk+vTpsnTp0ow6gCVLlkiXLl080UYAALzLcKsczh7z/Lt166YPAABgg+C/fft2cTgccueddzqd37p1qwQGBkrjxo3NbB8AAN7nsHba3+2CvyFDhsjx48eznD9x4oS+DwCAfM9Btb+Tffv2yR133JHlfMOGDfV9AADAv7kd/IODg+XMmTNZzp86dUoKFmSrAACARdb2N0w6rBD827VrJ9HR0ZKQkJBx7uLFi/L888/LfffdZ3b7AADwPoe10/5ud9WnTZsmLVu2lEqVKulUv6Lm/JcuXVo++OADT7QRAADvMpjq56RcuXLy3XffyaJFi2TPnj16U5/HH39cevfuLYUKFfJMKwEAgGnyNEgfGhqqN/cBAMCSHP6Zrvdq8P/iiy+kQ4cOumevrt+I2uAHAIB8zUHwl65du8rp06elVKlS+npOAgICJC0tzcz2AQAAXwR/taJfdtcBALAkw9qxztSJ+cnJyVKkSBEzXxIAAK8zHNau9nd7nn+bNm30Ur6u1Nr+t99+u1ntAgAA/hL8CxcuLPXr19db+KYPA4wfP15atGghDzzwgCfaCACAdzlY5MfJV199JXPnzpX+/fvL559/LkePHpX4+HhZsWKFXv0PAIB8z/DPoO3TMX+1e98vv/wiU6ZM0ev5r1+/XqKiosxvHQAA8H3a/8KFC9K9e3eZN2+evP3229KzZ0/d43/zzTfNbx0AAL7gMMw73LBx40bp1KmTREZG6unzn332mdP9hmHIiy++KGXLltUr7LZt21YOHTrk+Z5/3bp1pUqVKrJ79259OXDgQD3+P3jwYD0koA74l5/jf5HN23bKvgM/6eNI/DFJS3PI0IF95anHemf7nE1btsvq9bHy46Ejcva33yQh8ZIUKlhIKpQrKy3ubiL9enWT8OJhXv+3AN7WvfuDMvjpflK/fm0JCgqSnw4flcWLl8nMWfPl2rVrvm4ePMXhm7R/UlKSNGjQQA+t//Wvf81y/9SpU2X27NmycOFCHYPHjRsn7du3l3379umaPI8F/6efflr+8Y9/SIEC/580eOihh6RZs2Z6jX/4nyXLV8iH//7crees+GadfPXNOqlYPlKqV6ksEeFhcjEhUfbuPyj//GCJLFvxtbw3e7JUr1rJY+0GfG36tAny7LABkpqaKuvWxcrlpCRp3aqZTI55QR7seJ/c/8DDcuXKFV83ExYK/h06dNBHdlSvf+bMmfLCCy9Ily5d9Ln3339fb6ynMgS9evXyXPBXvzIyN0RRqYny5cvL6tWr3X05eEH1qpXlsd7dpdZt1aTWX6rL/PeXyJer1tzwOY/37i6jnhkgJUtEOJ1PTv5dxsW8Ll+v3SQvTZ4pi9553cOtB3yjc+f2OvBfunRZ7m3TXXbH7dXnS5QIl9XfLJXmze+UieNHyeixL/u6qfBzKSkp+sgsODhYH+74+eef9Wq7KtWfLiwsTO68807ZsmWLW8Hf7TH/9F8a9erV0+MN6lBT/9jO13/9rfP98vdnBkjHdq2laqUKUiAg4E+fU/O2alkCv1KkSIj8/ZmB+vqeH37UPSHAiqLHDNWXU1+bmxH4lXPnLsjQoc/r64MHPybFihX1WRvhQYZh2hETE6ODdOZDnXOXCvyK6ulnpm6n32da8F+2bJmcPHky4/aMGTNk0KBBek7/0qVL9XH//ffr4YDXX6cXaAcFAwP1pRr6UbM9AKuJjCwjTZo01NcXf7w8y/2xm7fLsWMn9Bhrhw73+qCFyE/z/KOjoyUhIcHpUOd86U+Dv0rtN2/eXH744Qd9e86cObrSX03zUzv4qUMVIKhqf1WEAGu7evWqzHp7gb5+d5OGUtjNtBWQHzS8vW5GL//o0ePZPmbnrj1OjwVyotL7xYoVczrcTfkrZcqU0ZdnzpxxOq9up9+XW3/abVPT+tRufmpKn/oBcOrUqWzn9Ktz6j5Yi5odsOjfn+sfgRcuJsjeHw/KhYuJUrfWbTIxerivmwd4ROXKFfTlseNZlzJPd/z49Yxo5coVvdYueJHD/9b2V9X9KsivWbMmYzn9xMREvby+ysi7I1c5W7V074YNG/T16tWr61T/889fH/NKp6b71ahRw603h/87deasfL7yv07n7mrcUF4aPVRK31rSZ+0CPKlo0Vv0ZXJSco6PSfrjvmJ/PBYWY/im2v/y5cvy008/ORX5xcXFSUREhFSsWFGGDx8ur7zyio636VP91JoAXbt2det9cj1gW7Lk9T/0EyZM0FP71EIEanqfEhsbq3+JqB8FsJY2LaNkb+xKSUtLkzO//iZbtsfJm+9+IN0eHSSTxj0n7Vq38HUTAcAyduzYIa1bt864PXLkSH3Zr18/WbBggYwePVqvBfDkk0/KxYsX9bD8qlWr3Jrjr7hdraWGAVSKQRX3pa88VKtWLdm2bZs0bHi9QCYv0x4KpKTkaQwE3hEYGCiRZUpL907t5a7Gt0vXR56SF159Xe6oXyfbWQFAfqam9ylFQnPeojz0j/sS/3gsLMbhm7R/q1atMqbRZ0dNrZ84caI+bkaepvo1atRIPvzwQ9m5c6c+1PXcBn4lu2kPU2a9lZemwAfKlS0tTe5oIMm//y6bt+/2dXMA08XH/6IvK5SPzPExFSpcvy8+h4JA5G+Gw2Ha4Y8K5KUHePbs2Sznz507p+/LjeymPYx59ml3mwIfCvkjxXT+wkVfNwUwXfq8/pIlIzKK/1w1uqOBvtwV971X2wb4JPjnlI5QaXy17rU3pz3Ad9P9dn93fepn5QrlfN0cwHQnTpyS7X9ktXr36pbl/mZRTaRixXJ6ad+VK9f6oIWw6sY+3pLrMf/0OfxqvOGf//yn3HLL/1e4qmIwVQBYs2ZNz7QSXnXuwkVZvf5bebBda7klNNTpPlX0N3X2O3L2t3M6/X93kzt81k7Ak2KmzJFln7wno0cNkVWr1mZkAyIiwmXOnEn6+ptvLpDExEs+bimsVO3vLQHGjSoLMlFTCpT4+Hi9jn/mFL/q8VeuXFkXIKg1hvMi9bcjeXoecjdX/5Vpb2TcPn7ylJ6rX7pUSSldskTG+VkxL8qtJSPkxKkz0v5vj0mhQgWlZo1qutBPxJDTZ36VfQd/ktTUa1KqZAl5c9pEqVmjqo/+VfYQEslsCl+aMX2CDBs6QGe71q79VpKSf5d7WzeT8PDiEhu7Tdp36M3GPj5y7WrOazCYIWliH9NeK/TFRZJve/5qrqGipiCoJX/Dw8M92S6Y6HJSsny370CW82fO/qaPdFdTU/Wl2sFv1NCBsjNurxw6clSOHD0mKSlXpWjRUGlQp6bc0+xO6dGlQ5asAGA1I597STZv2aG39L377sZSqFAhOXzkqF7vX23pq3b7Ayzd8/c0ev5AVvT8AR/1/Mf3Nu21QscvFn/DriwAALjy00I9s+Rpnj8AAMi/6PkDAGCzan+CPwAANkv75yn4q80E3n33Xdm/f7++XadOHenfv79ephcAAFhszF/tOFStWjW9sc/58+f1MWPGDH1u165dnmklAABeZFh8bX+3e/4jRoyQzp07y/z586VgwetPv3btmgwYMEDvM6xW+gMAIF9zkPbP0vPPHPj1ixQsqPcYbty4sdntAwAAvk77q014jh07luX88ePHpWjRoma1CwAA33GwsY+Thx56SJ544gmZNm2aREVF6XOxsbEyatQo6d3bvBWRAADwGcM/x+p9FvxV0Fc7+/Xt21eP9StqvetBgwbJ5MmTPdFGAAC8y+GfPXafr+2fnJwshw8f1tdVpX+RIkVuqiGs7Q9kxdr+gG/W9r88srNpr3XLjC/EMov8qGBfr149c1sDAIAfMCze889T8FcV/0uXLtWFf2qf68zUdr8AAORrDmsH/1xV+z/zzDOyc+dOff3jjz/WhX5qdb/ly5fr/ax/+OEHWbt2LSv8AQBgleDftWvXjEr+SZMm6dX9vvzySwkKCpJZs2bJjz/+KD179pSKFSt6ur0AAHiew2HekV+D/6ZNm+See+7R11WRX8eOHfV1FfyTkpJ09b9a+e+dd97xbGsBAPAGh7Xn+ecq+M+ePVu6deumr4eHh8ulS5f09XLlysnevXszNvtRMwAAAIB/y1XwVzv4qbF+pWXLlrJ69Wp9vUePHvLss8/KwIED9bBAmzZtPNtaAAC8wWHtnr/b8/zVLn5XrlyRyMhIcTgcMnXqVNm8ebPUqFFDXnjhBZ0ZyAvm+QNZMc8f8M08/8Sn2pv2WsXe/lry/VS/iIiIjOsFChSQsWPHmt0mAADgj4v8AABgWQ7/TNd7PfirXr6q6r8RdX/6ev8AAORbDoK/phb0ycmWLVv0jABVAwAAQH5nEPyv69KlS5ZzBw4c0GP+asGfPn36yMSJE81uHwAA8MVUP1cnT57U0/vUxj4qzR8XFycLFy6USpUqmd0+AAC8z2HtqX5uBf+EhAQZM2aMVK9eXa/nv2bNGt3rr1u3rudaCACAtzlMPPJz2l/N558yZYqUKVNGFi9enO0wAAAA8H+5XuRHVfuHhIRI27ZtJTAwMMfH5XVLXxb5AbJikR/AN4v8XOxzr2mvVXzRWsm3Pf++ffv+6VQ/AAAsweGfY/VeD/4LFizwbEsAAIBXsMIfAACu/LRQzywEfwAAbLbIT57m+QMAgPyLnj8AAK5I+wMAYC+GxdP+BH8AAGzW82fMHwAAm6HnDwCAC4OePwAANuPwzcY+aWlpMm7cOKlSpYpeUr9atWry8ssvSy5X4s81ev4AAPgJtYHevHnzZOHChVKnTh3ZsWOHPP744xIWFibDhg0z7X0I/gAA+Enaf/PmzXrX3I4dO+rblStX1jvpbtu2zdT3Ie0PAIAH0/4pKSmSmJjodKhz2YmKipI1a9bIwYMH9e09e/bIt99+Kx06dBAzEfwBAPCgmJgYnbbPfKhz2Rk7dqz06tVLatasKYUKFZKGDRvK8OHDpU+fPqa2ibQ/AAAeTPtHR0fLyJEjnc4FBwdn+9ilS5fKokWL5KOPPtJj/nFxcTr4R0ZGSr9+/UxrE8EfAAAPBn8V6HMK9q5GjRqV0ftX6tWrJ/Hx8TpTQPAHAMCCBX/JyclSoIDziHxgYKA4HOY2iOAPAICf6NSpk7z66qtSsWJFnfbfvXu3zJgxQ/r372/q+xD8AQBwZQSIL8yZM0cv8jN48GA5e/asHut/6qmn5MUXXzT1fQIMs5cNyqPU3474ugmA3wmJbOHrJgB+6drVEx59/dMtW5n2WmU2rhd/w1Q/AABshrQ/AAAuDIdv0v7eQvAHAMAFu/oBAABLoecPAIALw0fV/t5C8AcAwAVpfwAAYCn0/AEAcEG1PwAANmP4xfJ3nkPwBwDAZj1/xvwBALAZev4AANis50/wBwDAZmP+pP0BALAZev4AALgg7Q8AgM0YFl/el7Q/AAA2Q88fAACbre1P8AcAwIWDtD8AALASev4AANis4I/gDwCAC6b6AQBgMwYr/AEAACuh5w8AgAvS/gAA2IzD4gV/pP0BALAZev4AALhgqh8AADZjUO0PAACshJ4/AAA2K/gj+AMAYLMxf9L+AADYDD1/AABsVvBH8AcAwAVj/l4SEtnC100A/M7eyg183QTAlgyLB3/G/AEAsBm/6fkDAOAvHBbv+RP8AQBwYfF6P9L+AADYDT1/AABckPYHAMBmDIsHf9L+AADYDD1/AABcOMTaCP4AALgwhLQ/AACwEII/AAAuHIZ5h7tOnDghjzzyiJQoUUJCQkKkXr16smPHDjETaX8AAFw4fJT2v3DhgjRr1kxat24tK1eulFtvvVUOHTok4eHhpr4PwR8AAD8Z858yZYpUqFBB/vWvf2Wcq1KliunvQ9ofAAAPSklJkcTERKdDncvOF198IY0bN5YePXpIqVKlpGHDhjJ//nzT20TwBwAgm6l+Zh0xMTESFhbmdKhz2Tly5IjMmzdPatSoIV9//bUMGjRIhg0bJgsXLhQzBRiG4Rf7FxQMKufrJgB+Z2/lBr5uAuCXah78j0df/5vSvUx7rXuOLczS0w8ODtaHq6CgIN3z37x5c8Y5Ffy3b98uW7ZsMa1NjPkDAOBBOQX67JQtW1Zq167tdK5WrVry6aefmtomgj8AAH6ywp+q9D9w4IDTuYMHD0qlSpVMfR+CPwAAfhL8R4wYIVFRUTJp0iTp2bOnbNu2Td555x19mImCPwAA/ESTJk1k+fLlsnjxYqlbt668/PLLMnPmTOnTp4+p70PPHwAAP1rb/8EHH9SHJxH8AQBw4bD2vj6k/QEAsBt6/gAA+Mna/t5C8AcAwIVfrH7nQQR/AAD8ZKqftzDmDwCAzdDzBwDAhSOAMX8AAGzFEGsj7Q8AgM3Q8wcAwGYFfwR/AABcsMIfAACwFHr+AAC4YIU/AABsxhBrI+0PAIDN0PMHAMBmBX8EfwAAXDDVDwAAmzHE2hjzBwDAZuj5AwDggjF/AABsxiHWRtofAACboecPAIDNev4EfwAAXBgWH/Mn7Q8AgM3Q8wcAwAVpfwAAbMYh1kbaHwAAm6HnDwCAzZb3JfgDAOCCFf4AALAZh1gbY/4AANgMPX8AAGzW8yf4AwBgs4I/0v4AANgMPX8AAFxQ7Q8AgM04xNpI+wMAYDP0/AEAsFnBH8EfAAAXDouHf9L+AADYDD1/AABsVvBH8AcAwIW1k/4EfwAAbNfzZ8wfAACbIfgDAJDNCn9mHXk1efJkCQgIkOHDh4vZSPsDAOBnU/22b98ub7/9ttSvX98jr0/PHwAAP3L58mXp06ePzJ8/X8LDwz3yHgR/AABcGCYe7hoyZIh07NhR2rZtK55C2h8AAA9W+6ekpOgjs+DgYH24+vjjj2XXrl067e9J9PwBAPCgmJgYCQsLczrUOVfHjx+XZ599VhYtWiSFCxf2ZJMkwDAMt7MSFy9elHfffVf279+vb9epU0f69++v/0F5VTCoXJ6fC1jV3soNfN0EwC/VPPgfj77+mMq9TXutiQcW5Krn/9lnn0m3bt0kMDAw41xaWpqu+C9QoIB+jcz3eTXtv2PHDmnfvr2EhIRI06ZN9bkZM2bIq6++Kt98843ccccdpjQMAABfMUx8rZxS/K7atGkj33//vdO5xx9/XGrWrCljxowxLfDnKfiPGDFCOnfurKsQCxa8/vRr167JgAED9FzEjRs3mtY4AADsomjRolK3bl2nc6GhoVKiRIks533S888c+PWLFCwoo0ePlsaNG5vaOAAAfMEh1uZ28C9WrJgcO3ZMpyFcCxXUrxYAAPI7h59s7bN+/Xr/qPZ/6KGH5IknnpAlS5bogK8ONTVBpf179zavQAIAADvO8/fLnv+0adN05WHfvn31WL9SqFAhGTRokF6HGAAA+De3g39QUJDMmjVLz1E8fPiwPletWjUpUqSIJ9oHAIDXOcTa3A7+CQkJet5hRESE1KtXL+P8+fPndeGfqgkAACA/M/w2Ye+jMf9evXrpMX5XS5cu1fcBAACL9fy3bt2qF/Vx1apVK/nHP/5hVrvgZd27PyiDn+4n9evX1kM7Px0+KosXL5OZs+Zn1HYAdlGoXCmptm5Brh4b//Bo+X3HXo+3Cd7lEGtzO/ir5QWzCwapqany+++/m9UueNH0aRPk2WED9H/Ddeti5XJSkrRu1Uwmx7wgD3a8T+5/4GG5cuWKr5sJeI0j+YokLFud4/1B1StKSP2/SNrlZLnywyGvtg32murnN8FfLen7zjvvyJw5c5zOv/XWW9KoUSMz2wYv6Ny5vQ78ly5dlnvbdJfdcdd7MCVKhMvqb5ZK8+Z3ysTxo2T02Jd93VTAa9IuJMqpsa/neH/5+RP05aWvNojxu/Oa7YAlg/8rr7yi9xjes2ePXodYWbNmjd5+UK3tj/wlesxQfTn1tbkZgV85d+6CDB36vGxY/5kMHvyYvDJppiQmXvJhSwH/ULB0CQltfn0Pk4v/5m+eVRlibW4X/DVr1ky2bNkiFSpU0EV+X375pVSvXl2+++47adGihWdaCY+IjCwjTZo01NcXf7w8y/2xm7fLsWMn9NaSHTrc64MWAv4nrFtbCQgMlJSDR+XKdwd83Rx4MO3vMOmwRM9fuf322/V+w8jfGt5eN6OXf/To8Wwfs3PXHqlYsZx+7JIln3u5hYD/CftrW3158RN6/ci/chX8ExMTM+bvq+s3wjz//KNy5Qr68tjxEzk+5vjxk388tqLX2gX4q5AmdSWocjlxXE2VxM/X+ro58CCHWFuugn94eLicOnVKSpUqJcWLF9fL+7oyDEOfVwsAIX8oWvQWfZmclJzjY5L+uK/YH48F7Kz439rpy8tr/qeLAmFdhp+m670a/NeuXatX9Eu/nl3wBwArKxAaIkXbN9fXEz7NeRogrMEh1par4H/PPfc4LeZzs9RaAerILnMA71HT+5QioTnvyxD6x32JfzwWsKuiD94jBYoUltRTv0rSpp2+bg7g3Wr/8ePHi8PhyHbN/9xu6as2BQoLC3M6DAfTyLwtPv4XfVmhfGSOj6lQ4fp98TkUBAJ2Ubz79ZR/wrL/qt6Kr5sDL6T9DZP+Z4ng/+6770rz5s3lyJEjGefWr1+vN/lJ3+Xvz0RHR+sfC5mPgAJF3W0KblL6vP6SJSMyiv9cNbqjgb7cFfe9V9sG+JOgahUk5PaaYjgcN1z5D9bhMPGwRPBX8/nLly+vp/vNnz9fRo0aJe3atZNHH31UNm/enKvXCA4O1rMCMh+k/L3vxIlTsn37bn29d69uWe5vFtVET/NTS/uuXEllM+yreI/2+jJ563eSevy0r5sDeH+ev6r8V4v7PP/88/LUU0/pbXxXrlyZsdof8peYKXNk2SfvyehRQ2TVqrUZ2YCIiHCZM2eSvv7mmwtY3Q/2VTBQinVura8msKKfbTgsPrTjds9fUev6z5o1S4/xV61aVYYNG6aX+0X+88UXX8vsOf/U0/5iv/1SVnzxgSz5+B05sP9bqV+vtsTGbpMXx7/m62YCPnNL66ZSsGS4pCVckkvfxPq6OfASw8TDEsH//vvvlwkTJsjChQv1Kn+7d++Wli1byl133SVTp071TCvhUSOfe0l6Pfy0/O9/O+XuuxtLh/vvlV9OnJLo51+Vtu16sqMfbC290C9xxQYxrqb6ujmAKQIMNcfODffdd58O/JGRzhXiX331lQwYMEAvBpQXBYPK5el5gJXtrXy94BKAs5oH/+PR13+4UtY6qLz6KD7r3in5bsx/9ersK107duwo339PRTgAIP8z/DZh78ONfdSUvpkzZ8r+/fv17dq1a8vw4cP1+D8AAPBvfzrmv2vXLqf1+r/++msd7Ldt2yb169fXx9atW/W5nLICAADkJw6Lz/P/057/hg0b9LS+Tz/9VEJDQ2Xs2LEyYsQImTx5stPj1PkxY8bomgAAAPIzh8XT/n/a81eBXlXzp6/vr1L9TzzxRJbH9e/fX/bt2+eZVgIA4EWGxZf3zdWYv+r5t2jRQl+/9dZbJS4uTmrUqOH0GHVObfkLAAAsUvC3bt06adSokQwcOFCefPJJvbZ/VFSUvi82NlamTJkiI0eO9GRbAQDwCodYW67n+QcGBuo5/Krnryr9p0+fLidPntT3qTn/ao1/tdJfXtfoZ54/kBXz/AHfzPPvVrGTaa+1/NiXkm97/um/EVRwV3UA6rh06fp670WLsiMfAACWnOfv2qsn6AMArMjhp4V6Pgn+t91225+m9c+fP3+zbQIAwKccYm1uBX+1oU9YWJjnWgMAAPwr+Pfq1YvpfAAAyzNI+1+X1yp+AADyG4fdV/hL5+bOvwAAIL/3/B0Oq5c/AABgjw5vnrb0BQDAyhxibQR/AABsVvCX6zF/AABgDfT8AQCwWbU/wR8AAJsV/JH2BwDAZuj5AwDggrQ/AAA2Y1g8+JP2BwDAT8TExEiTJk2kaNGiei+drl27yoEDB0x/H4I/AAAuHIZh2uGODRs2yJAhQ+R///ufrF69WlJTU6Vdu3aSlJQkZiLtDwCAC18l/VetWuV0e8GCBToDsHPnTmnZsqVp70PwBwDAg1JSUvSRWXBwsD7+TEJCgr6MiIgwtU2k/QEAyKba36xDjeOHhYU5HepcbjbUGz58uDRr1kzq1q0rZqLnDwCAB6f6RUdHy8iRI53O5abXr8b+9+7dK99++62YjeAPAIAHV/jLbYo/s2eeeUZWrFghGzdulPLly4vZCP4AAPjRj46hQ4fK8uXLZf369VKlShWPvA/BHwAAP1nhT6X6P/roI/n888/1XP/Tp0/r86pOICQkxLT3oeAPAIBsVvgz63/umDdvnq7wb9WqlZQtWzbjWLJkiZiJnj8AADbbTZDgDwCAzbb0JfgDAGCzXf0Y8wcAwGbo+QMA4IK0PwAANuMg7Q8AAKyEnj8AAC7cnZ+f3xD8AQBw4WDMHwAAezEs3vNnzB8AAJuh5w8AgAvS/gAA2IxB2h8AAFgJPX8AAFyQ9gcAwGYM0v4AAMBK6PkDAOCCtD8AADZjkPYHAABWQs8fAAAXhuEQKyP4AwDgwmHxtD/BHwAAF4bFC/4Y8wcAwGbo+QMA4IK0PwAANmOQ9gcAAFZCzx8AABes8AcAgM0YFh/zJ+0PAIDN0PMHAMBmBX8EfwAAbDbVj7Q/AAA2Q88fAAAXpP0BALAZB8EfAAB7MSwe/BnzBwDAZuj5AwBgs2p/gj8AAC5I+wMAAEuh5w8AgAuq/QEAsBnD4mP+pP0BALAZev4AALgg7Q8AgM0YFg/+pP0BALAZev4AALig4A8AABum/Q2TDnfNnTtXKleuLIULF5Y777xTtm3bZvq/j+APAICfBP8lS5bIyJEj5aWXXpJdu3ZJgwYNpH379nL27FkxE8EfAAA/MWPGDBk4cKA8/vjjUrt2bXnrrbekSJEi8t5775n6PgR/AABcGCYeKSkpkpiY6HSoc66uXr0qO3fulLZt22acK1CggL69ZcsWsWTB37WrJ3zdBPzxIY2JiZHo6GgJDg72dXMAv8D3wn6umRiTxo8fLxMmTHA6p9L66nxmv/32m6SlpUnp0qWdzqvbP/74o5gpwLD6ZEa4Rf0iDQsLk4SEBClWrJivmwP4Bb4XuNkfj649ffUj0vWH5MmTJ6VcuXKyefNmufvuuzPOjx49WjZs2CBbt24Vy/X8AQCwouBsAn12SpYsKYGBgXLmzBmn8+p2mTJlTG0TY/4AAPiBoKAgadSokaxZsybjnMPh0LczZwLMQM8fAAA/oab59evXTxo3bixNmzaVmTNnSlJSkq7+NxPBH05UakoVolDUBPw/vhfwloceekh+/fVXefHFF+X06dNy++23y6pVq7IUAd4sCv4AALAZxvwBALAZgj8AADZD8EeufPLJJ/oArESNeqrlVHfs2OHrpgBeRfDPZ5YtWybFixeXcePGyerVq2XIkCEef89NmzbJ3//+d7nrrrvcel5AQIB89tlnHmsXcLPUqn2qmEptnpJb69ev15/tixcverRtgCcR/P3AY489pv+YTJ482em8CpzqvGvw/+CDD/RKUIMGDdJTQm6W2jpSTSfJjqo6ffLJJ+WLL76Q8uXLu/W6p06dkg4dOtx0+wB3qe/NjQ61rOrGjRszMlqFChXK9WtHRUXpz7Za8Q/Ir5jq5yfUvs1TpkyRp556SsLDw3N83IcffqgvO3Xq5JV23XrrrbJ///48PdfsFamA3FLBOfMWqWra1IEDBzLO3XLLLfpQW6bmZSEWPtvI7+j5+wm1a5P6g6LSkDk5d+6c9O7dW6/9rLZ4rFevnixevNjpMWr96GHDhkmpUqX0D4rmzZvL9u3bc3zNVq1aSXx8vIwYMSKjV5Tu008/lTp16ui5zSo7MH369Iz7Jk6cKJGRkbpN6Tp27CitW7fWK1Jll/b/5ZdfdPsjIiIkNDRUL2KRea3qefPmSbVq1fQf17/85S86wwHkhfoupR+qh64+i+m31XdDjfOrTJb6bKfPo06vAVDfRbV/evos6PPnz+vHqh8QOaX9Y2Nj9XdJfS/Vj3f1/AsXLuTpOwl4hZrnD9/q16+f0aVLF2PZsmVG4cKFjePHj+vzy5cv1ztCpvvll1+M1157zdi9e7dx+PBhY/bs2UZgYKCxdevWjMcMGzbMiIyMNP7zn/8YP/zwg37t8PBw49y5c9m+tzpfvnx5Y+LEicapU6f0oezYscMoUKCAPn/gwAHjX//6lxESEqIvlWvXrhl333230bVrV337jTfeMIoXL27Ex8dnvLZqu/o3KJcuXTKqVq1qtGjRwti0aZNx6NAhY8mSJcbmzZv1/erfXqhQIWPu3Ln6/aZPn67/bWvXrvXA/+OwE/WZDQsLy7g9Y8YMo1ixYsbixYuNH3/80Rg9erT+7B08eDDje6a+MzNnztS3e/ToYTRt2tRITU3Vt9etW6c/2xcuXNC31fcxODjYGDRokBEXF2fs3bvXmDNnjvHrr7/m6TsJeAPB34+Cv3LXXXcZ/fv3zzb4Z6djx47Gc889p69fvnxZ/xFbtGhRxv1Xr17Vf3imTp2a42tUqlTJeP31153OPfzww8Z9993ndG7UqFFG7dq1M26rHyBFixY1xowZo38YZH5f1+D/9ttv68fm9AcvKirKGDhwoNM59Uf3gQceuOG/H3A3+Kvvw6uvvur0mCZNmhiDBw/OuL106VL9Q3zs2LFGaGhoxg+D7IJ/7969jWbNmmX73nn9TgKeRtrfz6hx/4ULF2Y7zq72eX755Zd1ul+lztWY5ddffy3Hjh3T9x8+fFhSU1OlWbNmGc9RhUxqfWh3x+3V4zO/jqJuHzp0SLdDqVq1qkybNk23uXPnzvLwww/n+HpxcXHSsGFD3W533i+v9QZATlvzqmLZP/us9ejRQ7p166aLcNVnvEaNGjf8bLdp0ybb+8z8TgJmIvj7mZYtW+rxwujo6Cz3vfbaazJr1iwZM2aMrFu3Tv/RUY+9evWq+IqqmFZbUB49elSuXbuW4+NCQkK82i7gZiQnJ8vOnTv1Z1v94L0RPtvIjwj+fkj1Nr788kvZsmWL03lVVNSlSxd55JFH9Lxk1fM+ePBgxv3pxXLqcelUr0MVF9WuXTvH91PPSe/Np6tVq5bT66S//2233ab/IKZXUauph6oASmUfVFYiJ/Xr19c/VlTxVHZyer8btRtwV7FixXSh6p991p577jkpUKCArFy5UmbPni1r16694Wc78xasmeX1Owl4nMcHFuDWmH+6Rx99VI85Zv5PNGLECKNChQpGbGyssW/fPmPAgAG6cCnzc5999lk9nrhy5Uqn4qLz58/n+P5qbL9z58660Cm9SGnnzp1OBX8LFixwKvhTRYnqdVXRobJq1SqjYMGCxpYtW7Id809JSTFuu+02XfD37bff6nqBTz75JKPgTz1OjY2++eabenw1veBPja8CZo75q/oW9b35+OOPdcGfqlnJXPC3YsUKIygoSH8HlOjoaF0Um/4dch3zV98P9XhV8Ldnzx5j//79+nOc/l3Ky3cS8DSCv58G/59//ln/Qckc/FWxnHrcLbfcYpQqVcp44YUXjL59+zo99/fffzeGDh1qlCxZUlcgq0Kkbdu23fD9VcCuX7++fnzm91PBWRX4qT+MFStW1DMNFIfDYbRp08Zo3769vp5OvW+1atV0Zb9r8FeOHj1qdO/eXf/hLVKkiNG4cWOnmQrqD6aaEaDeT/1QeP/99/P4/yiQc/BPS0szxo8fb5QrV05/1ho0aKADs3L27FmjdOnSxqRJk5wK9Bo1amT07Nkz2+CvrF+/Xhetqu+QmvWivhvp9+flOwl4Glv6AgBgM4z5AwBgMwR/AABshuAPAIDNEPwBALAZgj8AADZD8AcAwGYI/gAA2AzBHwAAmyH4AwBgMwR/AABshuAPAIDNEPwBABB7+T/swh7xZdQCwwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_lrc.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_lrc.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6838c",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1c270dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'log_loss',\n",
      " 'max_depth': 4,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 0.0530684395557626,\n",
      " 'min_samples_split': 0.11822332932827617,\n",
      " 'normalization': None,\n",
      " 'random_state': 3931421,\n",
      " 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_dtc = resultado_DecisionTree.params.copy()\n",
    "parametros_otimizados_dtc[\"random_state\"] = semente\n",
    "\n",
    "pprint(parametros_otimizados_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8169b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_dtc = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_dtc = parametros_otimizados_dtc[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_dtc == \"standard\": \n",
    "    steps_dtc.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_dtc == \"minmax\": \n",
    "    steps_dtc.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_dtc == \"maxabs\": \n",
    "    steps_dtc.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_dtc[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_dtc.append(PCA(n_components=parametros_otimizados_dtc[\"pca_components\"]))\n",
    "\n",
    "# Adiciona tratamento RFE \n",
    "elif treatment == \"rfe\": \n",
    "\n",
    "    # Definindo o número de atributos a serem mantidos\n",
    "    n_features_to_select = parametros_otimizados_lrc[\"rfe_features\"]\n",
    "\n",
    "    # Tratamento da lista de parametros\n",
    "    parametros_remover = [\"normalization\", \"treatment\", \"pca_components\", \"rfe_features\"]\n",
    "    for param in parametros_remover:\n",
    "        parametros_otimizados_lrc.pop(param, None)\n",
    "\n",
    "    # Definindo o estimador \n",
    "    estimator = DecisionTreeClassifier(**parametros_otimizados_dtc)\n",
    "    \n",
    "    steps_lrc.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\"]\n",
    "for param in parametros_remover:\n",
    "    parametros_otimizados_dtc.pop(param, None)\n",
    "\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_dtc = DecisionTreeClassifier(**parametros_otimizados_dtc)\n",
    "steps_dtc.append(modelo_dtc)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_dtc = make_pipeline(*steps_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "927860c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de accuracy = [0.69444444 0.94444444 0.88888889 0.74285714 0.8       ]\n",
      "Valor médio de accuracy = 0.814126984126984\n"
     ]
    }
   ],
   "source": [
    "kf_dtc = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "accuracy_dtc = cross_val_score(\n",
    "    pipeline_dtc, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"accuracy\", \n",
    "    cv=kf_dtc\n",
    "    )\n",
    "\n",
    "media_accuracy_dtc = accuracy_dtc.mean()\n",
    "\n",
    "print(f\"Valores de accuracy = {accuracy_dtc}\")\n",
    "print(f\"Valor médio de accuracy = {media_accuracy_dtc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "654704f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       0.93      1.00      0.96        13\n",
      "      Tóxico       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.93      0.94        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_dtc.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_dtc.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8db49",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a198e8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'log_loss',\n",
      " 'max_depth': 4,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 0.0530684395557626,\n",
      " 'min_samples_split': 0.11822332932827617,\n",
      " 'normalization': None,\n",
      " 'random_state': 3931421,\n",
      " 'treatment': None}\n"
     ]
    }
   ],
   "source": [
    "parametros_otimizados_rfc = resultado_DecisionTree.params.copy()\n",
    "parametros_otimizados_rfc[\"random_state\"] = semente\n",
    "\n",
    "pprint(parametros_otimizados_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21d72111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de etapas para o pipeline \n",
    "steps_rfc = []\n",
    "\n",
    "# Definindo a estratégia de normalização \n",
    "normalization_rfc = parametros_otimizados_rfc[\"normalization\"]\n",
    "# Adiciona normalização padrão\n",
    "if normalization_rfc == \"standard\": \n",
    "    steps_rfc.append(StandardScaler())\n",
    "# Adiciona normalização por máximos e mínimos\n",
    "elif normalization_rfc == \"minmax\": \n",
    "    steps_rfc.append(MinMaxScaler())\n",
    "# Adiciona normalização por máximo absoluto\n",
    "elif normalization_rfc == \"maxabs\": \n",
    "    steps_rfc.append(MaxAbsScaler())\n",
    "\n",
    "# Definindo estratégia de redução de dimensionalidade ou seleção de atributos \n",
    "treatment = parametros_otimizados_rfc[\"treatment\"]\n",
    "\n",
    "# Adiciona tratamento PCA \n",
    "if treatment == \"pca\": \n",
    "    # Definindo o número de componentes a serem mantidas pelo pca\n",
    "    steps_rfc.append(PCA(n_components=parametros_otimizados_rfc[\"pca_components\"]))\n",
    "\n",
    "# Adiciona tratamento RFE \n",
    "elif treatment == \"rfe\": \n",
    "    # CORREÇÃO: Usar parametros_otimizados_rfc em vez de parametros_otimizados_lrc\n",
    "    n_features_to_select = parametros_otimizados_rfc[\"rfe_features\"]\n",
    "\n",
    "    # Fazer uma cópia dos parâmetros para não modificar o original\n",
    "    params_rfc_copy = parametros_otimizados_rfc.copy()\n",
    "    \n",
    "    # Tratamento da lista de parametros\n",
    "    parametros_remover = [\"normalization\", \"treatment\", \"pca_components\", \"rfe_features\"]\n",
    "    for param in parametros_remover:\n",
    "        params_rfc_copy.pop(param, None)\n",
    "\n",
    "    # Definindo o estimador \n",
    "    estimator = RandomForestClassifier(**params_rfc_copy)\n",
    "    \n",
    "    steps_rfc.append(RFE(estimator=estimator, n_features_to_select=n_features_to_select))\n",
    "\n",
    "# Fazer uma cópia dos parâmetros para o modelo final\n",
    "params_final_rfc = parametros_otimizados_rfc.copy()\n",
    "\n",
    "# Tratamento da lista de parametros\n",
    "parametros_remover = [\"normalization\", \"treatment\", \"pca_components\", \"rfe_features\"]\n",
    "for param in parametros_remover:\n",
    "    params_final_rfc.pop(param, None)\n",
    "\n",
    "# Instânciando o modelo\n",
    "modelo_rfc = RandomForestClassifier(**params_final_rfc)\n",
    "steps_rfc.append(modelo_rfc)\n",
    "\n",
    "# Criando o pipeline\n",
    "pipeline_rfc = make_pipeline(*steps_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bff70d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de accuracy = [0.83333333 0.88888889 0.86111111 0.82857143 0.82857143]\n",
      "Valor médio de accuracy = 0.8480952380952381\n"
     ]
    }
   ],
   "source": [
    "kf_rfc = StratifiedKFold(5, shuffle=True, random_state=semente)\n",
    "    \n",
    "accuracy_rfc = cross_val_score(\n",
    "    pipeline_rfc, \n",
    "    x_treino, \n",
    "    y_treino, \n",
    "    scoring=\"accuracy\", \n",
    "    cv=kf_rfc\n",
    ")\n",
    "\n",
    "media_accuracy_rfc = accuracy_rfc.mean()\n",
    "\n",
    "print(f\"Valores de accuracy = {accuracy_rfc}\")\n",
    "print(f\"Valor médio de accuracy = {media_accuracy_rfc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7efac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não tóxico       0.93      1.00      0.96        13\n",
      "      Tóxico       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.93      0.94        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_rfc.fit(x_treino, y_treino)\n",
    "y_previsao = pipeline_rfc.predict(x_teste)\n",
    "\n",
    "matriz_conf = confusion_matrix(y_teste, y_previsao, labels=[0, 1])\n",
    "df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "sns.heatmap(df_conf, annot=True, annot_kws={\"size\": 16})\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_teste,\n",
    "        y_previsao,\n",
    "        target_names=ordem_labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a2a10-e951-4514-abfe-0f183729fea4",
   "metadata": {},
   "source": [
    "# Resultados e Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82707f99-8633-4b32-bdb5-0bdaf8fc946c",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952381c-4759-4dc4-90be-758fd40cc3c6",
   "metadata": {},
   "source": [
    "- Documentação DecisionTree:https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "- Documentação RandomForest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
